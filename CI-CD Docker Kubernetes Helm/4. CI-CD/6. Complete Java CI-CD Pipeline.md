# Complete Java CI/CD Pipeline - End-to-End Guide

## Overview

This guide provides a production-ready CI/CD pipeline for Java applications, covering everything from code commit to production deployment with monitoring.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPLETE CI/CD PIPELINE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Git Push â†’ Build â†’ Test â†’ Analyze â†’ Package â†’ Scan â†’ Deploy      â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Code â”‚ â†’ â”‚ Buildâ”‚ â†’ â”‚ Test â”‚ â†’ â”‚ Analyzeâ”‚ â†’ â”‚ Packageâ”‚ â†’     â”‚
â”‚  â”‚Commitâ”‚   â”‚Maven â”‚   â”‚ Unit â”‚   â”‚SonarQube  â”‚ Docker â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜   â”‚Gradleâ”‚   â”‚ IT   â”‚   â”‚  SAST â”‚   â”‚ Image  â”‚       â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                      â†“             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Smoke   â”‚ â† â”‚Productionâ”‚ â† â”‚ Staging  â”‚ â† â”‚  Scan  â”‚       â”‚
â”‚  â”‚  Tests   â”‚   â”‚ (Manual) â”‚   â”‚  (Auto)  â”‚   â”‚ Trivy  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚       â†“              â†“              â†“                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚      Monitoring & Observability         â”‚                     â”‚
â”‚  â”‚  Prometheus | Grafana | ELK | Jaeger   â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. End-to-End Pipeline Example

### Complete GitHub Actions Workflow

This example shows a production-ready pipeline for a Spring Boot application.

```yaml
# .github/workflows/complete-pipeline.yml
name: Complete Java CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  JAVA_VERSION: '17'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

jobs:
  # ==========================================
  # STAGE 1: BUILD & TEST
  # ==========================================
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Shallow clones should be disabled for SonarQube
      
      - name: Set up JDK
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'temurin'
          cache: 'maven'
      
      - name: Build with Maven
        run: |
          mvn clean compile -B -U
          echo "BUILD_TIME=$(date -u +'%Y-%m-%dT%H:%M:%SZ')" >> $GITHUB_ENV
      
      - name: Run Unit Tests
        run: mvn test -B
      
      - name: Run Integration Tests
        run: mvn verify -B -Pintegration-tests
      
      - name: Generate Code Coverage Report
        run: mvn jacoco:report
      
      - name: Upload Coverage Report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: target/site/jacoco/
      
      - name: Check Coverage Threshold
        run: |
          mvn jacoco:check -Djacoco.minimum.coverage=0.80
      
      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            target/surefire-reports/
            target/failsafe-reports/
      
      - name: Publish Test Report
        if: always()
        uses: dorny/test-reporter@v1
        with:
          name: Test Results
          path: 'target/surefire-reports/*.xml'
          reporter: java-junit

  # ==========================================
  # STAGE 2: STATIC ANALYSIS
  # ==========================================
  static-analysis:
    name: Static Code Analysis
    runs-on: ubuntu-latest
    needs: build-and-test
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up JDK
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'temurin'
          cache: 'maven'
      
      - name: SonarQube Scan
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        run: |
          mvn sonar:sonar \
            -Dsonar.projectKey=my-java-app \
            -Dsonar.organization=my-org \
            -Dsonar.host.url=https://sonarcloud.io \
            -Dsonar.coverage.jacoco.xmlReportPaths=target/site/jacoco/jacoco.xml
      
      - name: Check Quality Gate
        run: |
          # Wait for SonarQube analysis to complete
          sleep 30
          
          # Check quality gate status
          QUALITY_GATE=$(curl -s -u ${{ secrets.SONAR_TOKEN }}: \
            "https://sonarcloud.io/api/qualitygates/project_status?projectKey=my-java-app" \
            | jq -r '.projectStatus.status')
          
          if [ "$QUALITY_GATE" != "OK" ]; then
            echo "Quality gate failed: $QUALITY_GATE"
            exit 1
          fi
      
      - name: OWASP Dependency Check
        run: |
          mvn dependency-check:check -B \
            -Dformats=HTML,JSON \
            -DfailBuildOnCVSS=7
      
      - name: Upload OWASP Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: owasp-report
          path: target/dependency-check-report.*

  # ==========================================
  # STAGE 3: BUILD DOCKER IMAGE
  # ==========================================
  build-image:
    name: Build and Push Docker Image
    runs-on: ubuntu-latest
    needs: [build-and-test, static-analysis]
    permissions:
      contents: read
      packages: write
    
    outputs:
      image-digest: ${{ steps.build.outputs.digest }}
      image-tag: ${{ steps.meta.outputs.tags }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up JDK
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'temurin'
          cache: 'maven'
      
      - name: Build JAR
        run: mvn package -DskipTests -B
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
      
      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            BUILD_DATE=${{ env.BUILD_TIME }}
            VCS_REF=${{ github.sha }}
            VERSION=${{ github.ref_name }}

  # ==========================================
  # STAGE 4: SECURITY SCANNING
  # ==========================================
  scan-image:
    name: Scan Docker Image for Vulnerabilities
    runs-on: ubuntu-latest
    needs: build-image
    
    steps:
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ needs.build-image.outputs.image-tag }}
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
          exit-code: '1'  # Fail on vulnerabilities
      
      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'
      
      - name: Run Snyk Container Scan
        uses: snyk/actions/docker@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          image: ${{ needs.build-image.outputs.image-tag }}
          args: --severity-threshold=high
      
      - name: Generate SBOM
        uses: anchore/sbom-action@v0
        with:
          image: ${{ needs.build-image.outputs.image-tag }}
          format: spdx-json
          output-file: sbom.spdx.json
      
      - name: Upload SBOM
        uses: actions/upload-artifact@v4
        with:
          name: sbom
          path: sbom.spdx.json

  # ==========================================
  # STAGE 5: DEPLOY TO DEV
  # ==========================================
  deploy-dev:
    name: Deploy to Development
    runs-on: ubuntu-latest
    needs: [build-image, scan-image]
    environment:
      name: development
      url: https://dev.myapp.com
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'
      
      - name: Configure kubectl
        run: |
          echo "${{ secrets.KUBE_CONFIG_DEV }}" | base64 -d > kubeconfig
          export KUBECONFIG=kubeconfig
      
      - name: Deploy to Kubernetes
        run: |
          export KUBECONFIG=kubeconfig
          
          # Update image in deployment
          kubectl set image deployment/myapp \
            myapp=${{ needs.build-image.outputs.image-tag }} \
            -n dev
          
          # Wait for rollout to complete
          kubectl rollout status deployment/myapp -n dev --timeout=5m
          
          # Verify deployment
          kubectl get pods -n dev -l app=myapp
      
      - name: Run Health Check
        run: |
          # Wait for service to be ready
          sleep 30
          
          # Health check
          response=$(curl -s -o /dev/null -w "%{http_code}" https://dev.myapp.com/actuator/health)
          
          if [ "$response" != "200" ]; then
            echo "Health check failed with status: $response"
            exit 1
          fi
          
          echo "Health check passed!"
      
      - name: Notify Deployment
        if: always()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Deployment to DEV ${{ job.status }}'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}

  # ==========================================
  # STAGE 6: DEPLOY TO STAGING
  # ==========================================
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: deploy-dev
    if: github.ref == 'refs/heads/main'
    environment:
      name: staging
      url: https://staging.myapp.com
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
      
      - name: Configure kubectl
        run: |
          echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > kubeconfig
          export KUBECONFIG=kubeconfig
      
      - name: Deploy with Helm
        run: |
          export KUBECONFIG=kubeconfig
          
          helm upgrade --install myapp ./helm/myapp \
            --namespace staging \
            --set image.tag=${{ needs.build-image.outputs.image-tag }} \
            --set replicaCount=3 \
            --set resources.requests.memory=512Mi \
            --set resources.limits.memory=1Gi \
            --wait --timeout 5m
      
      - name: Run Integration Tests
        run: |
          # Wait for all pods to be ready
          kubectl wait --for=condition=ready pod \
            -l app=myapp -n staging --timeout=5m
          
          # Run integration test suite
          ./scripts/run-integration-tests.sh staging
      
      - name: Run Performance Tests
        run: |
          # Run k6 load tests
          docker run --rm -i grafana/k6 run - < tests/load-test.js \
            --env BASE_URL=https://staging.myapp.com

  # ==========================================
  # STAGE 7: DEPLOY TO PRODUCTION
  # ==========================================
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [build-image, deploy-staging]
    if: github.ref == 'refs/heads/main'
    environment:
      name: production
      url: https://myapp.com
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
      
      - name: Configure kubectl
        run: |
          echo "${{ secrets.KUBE_CONFIG_PROD }}" | base64 -d > kubeconfig
          export KUBECONFIG=kubeconfig
      
      - name: Create Backup
        run: |
          export KUBECONFIG=kubeconfig
          
          # Backup current deployment
          kubectl get deployment myapp -n production -o yaml > backup-deployment.yaml
          
          # Upload backup
          aws s3 cp backup-deployment.yaml \
            s3://myapp-backups/deployments/$(date +%Y%m%d-%H%M%S).yaml
      
      - name: Deploy with Blue-Green Strategy
        run: |
          export KUBECONFIG=kubeconfig
          
          # Deploy new version (green)
          helm upgrade myapp-green ./helm/myapp \
            --install \
            --namespace production \
            --set image.tag=${{ needs.build-image.outputs.image-tag }} \
            --set service.selector.version=green \
            --set replicaCount=5 \
            --wait --timeout 10m
          
          # Wait for green deployment to be ready
          kubectl rollout status deployment/myapp-green -n production
      
      - name: Run Smoke Tests
        id: smoke-tests
        run: |
          # Test green deployment
          GREEN_URL="https://green.myapp.com"
          
          # Health check
          response=$(curl -s -o /dev/null -w "%{http_code}" $GREEN_URL/actuator/health)
          if [ "$response" != "200" ]; then
            echo "smoke_passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # Critical endpoints test
          ./scripts/smoke-tests.sh $GREEN_URL
          
          echo "smoke_passed=true" >> $GITHUB_OUTPUT
      
      - name: Switch Traffic to Green
        if: steps.smoke-tests.outputs.smoke_passed == 'true'
        run: |
          export KUBECONFIG=kubeconfig
          
          # Update service to point to green
          kubectl patch service myapp -n production \
            -p '{"spec":{"selector":{"version":"green"}}}'
          
          echo "Traffic switched to green deployment"
      
      - name: Monitor Metrics
        run: |
          # Monitor for 5 minutes
          sleep 300
          
          # Check error rate
          ERROR_RATE=$(curl -s "http://prometheus:9090/api/v1/query?query=rate(http_requests_total{status=~\"5..\"}[5m])" \
            | jq -r '.data.result[0].value[1]')
          
          if (( $(echo "$ERROR_RATE > 0.01" | bc -l) )); then
            echo "Error rate too high: $ERROR_RATE"
            exit 1
          fi
      
      - name: Scale Down Blue Deployment
        if: success()
        run: |
          export KUBECONFIG=kubeconfig
          
          # Scale down old version
          kubectl scale deployment myapp-blue -n production --replicas=0
          
          # Rename deployments for next cycle
          kubectl label deployment myapp-green -n production version=blue --overwrite
          kubectl label deployment myapp-blue -n production version=green --overwrite
      
      - name: Rollback on Failure
        if: failure()
        run: |
          export KUBECONFIG=kubeconfig
          
          echo "Deployment failed! Rolling back..."
          
          # Switch traffic back to blue
          kubectl patch service myapp -n production \
            -p '{"spec":{"selector":{"version":"blue"}}}'
          
          # Delete failed green deployment
          kubectl delete deployment myapp-green -n production
          
          # Notify team
          curl -X POST ${{ secrets.SLACK_WEBHOOK }} \
            -H 'Content-Type: application/json' \
            -d '{"text":"ðŸš¨ Production deployment FAILED and rolled back!"}'
      
      - name: Tag Release
        if: success()
        run: |
          git tag -a "v${{ github.run_number }}" -m "Release v${{ github.run_number }}"
          git push origin "v${{ github.run_number }}"
      
      - name: Create GitHub Release
        if: success()
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: v${{ github.run_number }}
          release_name: Release v${{ github.run_number }}
          body: |
            ## Changes in this Release
            - Image: ${{ needs.build-image.outputs.image-tag }}
            - Commit: ${{ github.sha }}
            - Build Time: ${{ env.BUILD_TIME }}
          draft: false
          prerelease: false
      
      - name: Notify Success
        if: success()
        uses: 8398a7/action-slack@v3
        with:
          status: success
          text: 'ðŸš€ Production deployment successful!'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

---

### Supporting Files

#### Dockerfile (Multi-stage for Java)

```dockerfile
# Build stage
FROM maven:3.9-eclipse-temurin-17 AS build
WORKDIR /app

# Copy pom.xml and download dependencies (cached layer)
COPY pom.xml .
RUN mvn dependency:go-offline -B

# Copy source and build
COPY src ./src
RUN mvn package -DskipTests -B

# Extract layers for better caching
RUN mkdir -p target/dependency && \
    cd target/dependency && \
    jar -xf ../*.jar

# Runtime stage
FROM eclipse-temurin:17-jre-alpine

# Add non-root user
RUN addgroup -g 1001 -S appuser && \
    adduser -u 1001 -S appuser -G appuser

# Install curl for health checks
RUN apk add --no-cache curl

WORKDIR /app

# Copy layers from build stage
COPY --from=build /app/target/dependency/BOOT-INF/lib ./lib
COPY --from=build /app/target/dependency/META-INF ./META-INF
COPY --from=build /app/target/dependency/BOOT-INF/classes ./

# JVM tuning for containers
ENV JAVA_OPTS="-XX:+UseContainerSupport \
    -XX:MaxRAMPercentage=75.0 \
    -XX:InitialRAMPercentage=50.0 \
    -XX:+UseG1GC \
    -XX:MaxGCPauseMillis=100 \
    -XX:+UseStringDeduplication"

# Add build info as labels
ARG BUILD_DATE
ARG VCS_REF
ARG VERSION
LABEL org.opencontainers.image.created=$BUILD_DATE \
      org.opencontainers.image.revision=$VCS_REF \
      org.opencontainers.image.version=$VERSION

# Switch to non-root user
USER appuser

EXPOSE 8080

HEALTHCHECK --interval=30s --timeout=3s --start-period=40s --retries=3 \
  CMD curl -f http://localhost:8080/actuator/health || exit 1

ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -cp /app org.springframework.boot.loader.launch.JarLauncher"]
```

#### Smoke Tests Script

```bash
#!/bin/bash
# scripts/smoke-tests.sh

BASE_URL=$1

echo "Running smoke tests against $BASE_URL"

# Test 1: Health check
echo "Test 1: Health check"
response=$(curl -s -o /dev/null -w "%{http_code}" $BASE_URL/actuator/health)
if [ "$response" != "200" ]; then
  echo "âŒ Health check failed"
  exit 1
fi
echo "âœ… Health check passed"

# Test 2: Readiness
echo "Test 2: Readiness check"
response=$(curl -s $BASE_URL/actuator/health/readiness | jq -r '.status')
if [ "$response" != "UP" ]; then
  echo "âŒ Readiness check failed"
  exit 1
fi
echo "âœ… Readiness check passed"

# Test 3: Critical API endpoint
echo "Test 3: API endpoint"
response=$(curl -s -o /dev/null -w "%{http_code}" $BASE_URL/api/v1/users)
if [ "$response" != "200" ]; then
  echo "âŒ API endpoint failed"
  exit 1
fi
echo "âœ… API endpoint passed"

# Test 4: Database connectivity
echo "Test 4: Database connectivity"
response=$(curl -s $BASE_URL/actuator/health/db | jq -r '.status')
if [ "$response" != "UP" ]; then
  echo "âŒ Database connectivity failed"
  exit 1
fi
echo "âœ… Database connectivity passed"

# Test 5: Response time
echo "Test 5: Response time"
response_time=$(curl -s -o /dev/null -w "%{time_total}" $BASE_URL/api/v1/users)
if (( $(echo "$response_time > 1.0" | bc -l) )); then
  echo "âŒ Response time too slow: ${response_time}s"
  exit 1
fi
echo "âœ… Response time acceptable: ${response_time}s"

echo "ðŸŽ‰ All smoke tests passed!"
```

#### Integration Tests Script

```bash
#!/bin/bash
# scripts/run-integration-tests.sh

ENVIRONMENT=$1
BASE_URL="https://$ENVIRONMENT.myapp.com"

echo "Running integration tests against $BASE_URL"

# Run Postman collection
newman run tests/integration-tests.postman_collection.json \
  --environment tests/environments/$ENVIRONMENT.postman_environment.json \
  --reporters cli,json \
  --reporter-json-export results/newman-results.json

# Run REST-assured tests
mvn verify -Pintegration-tests \
  -Dtest.base.url=$BASE_URL \
  -Dtest.timeout=30s

# Check results
if [ $? -eq 0 ]; then
  echo "âœ… Integration tests passed"
else
  echo "âŒ Integration tests failed"
  exit 1
fi
```

---

## 2. Infrastructure as Code (IaC)

### Terraform for Cloud Resources

#### Main Terraform Configuration

```hcl
# terraform/main.tf
terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
  
  backend "s3" {
    bucket         = "myapp-terraform-state"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-state-lock"
  }
}

provider "aws" {
  region = var.aws_region
  
  default_tags {
    tags = {
      Environment = var.environment
      Project     = "myapp"
      ManagedBy   = "terraform"
    }
  }
}

# VPC and Networking
module "vpc" {
  source  = "terraform-aws-modules/vpc/aws"
  version = "~> 5.0"
  
  name = "${var.project_name}-${var.environment}-vpc"
  cidr = var.vpc_cidr
  
  azs             = var.availability_zones
  private_subnets = var.private_subnet_cidrs
  public_subnets  = var.public_subnet_cidrs
  
  enable_nat_gateway = true
  enable_vpn_gateway = false
  enable_dns_hostnames = true
  
  tags = {
    "kubernetes.io/cluster/${var.cluster_name}" = "shared"
  }
  
  public_subnet_tags = {
    "kubernetes.io/role/elb" = "1"
  }
  
  private_subnet_tags = {
    "kubernetes.io/role/internal-elb" = "1"
  }
}

# EKS Cluster
module "eks" {
  source  = "terraform-aws-modules/eks/aws"
  version = "~> 19.0"
  
  cluster_name    = var.cluster_name
  cluster_version = "1.28"
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  cluster_endpoint_public_access = true
  
  eks_managed_node_groups = {
    main = {
      min_size     = 2
      max_size     = 10
      desired_size = 3
      
      instance_types = ["t3.large"]
      capacity_type  = "ON_DEMAND"
      
      labels = {
        Environment = var.environment
        NodeGroup   = "main"
      }
      
      tags = {
        NodeGroup = "main"
      }
    }
  }
  
  # Cluster access entry
  enable_cluster_creator_admin_permissions = true
  
  tags = {
    Environment = var.environment
  }
}

# RDS Database
resource "aws_db_instance" "main" {
  identifier     = "${var.project_name}-${var.environment}-db"
  engine         = "postgres"
  engine_version = "15.4"
  instance_class = var.db_instance_class
  
  allocated_storage     = 100
  max_allocated_storage = 1000
  storage_encrypted     = true
  
  db_name  = var.db_name
  username = var.db_username
  password = var.db_password
  
  vpc_security_group_ids = [aws_security_group.rds.id]
  db_subnet_group_name   = aws_db_subnet_group.main.name
  
  backup_retention_period = 7
  backup_window          = "03:00-04:00"
  maintenance_window     = "Mon:04:00-Mon:05:00"
  
  skip_final_snapshot = var.environment != "production"
  final_snapshot_identifier = var.environment == "production" ? "${var.project_name}-final-snapshot" : null
  
  enabled_cloudwatch_logs_exports = ["postgresql", "upgrade"]
  
  tags = {
    Name = "${var.project_name}-${var.environment}-db"
  }
}

# ElastiCache Redis
resource "aws_elasticache_cluster" "redis" {
  cluster_id           = "${var.project_name}-${var.environment}-redis"
  engine               = "redis"
  engine_version       = "7.0"
  node_type            = var.redis_node_type
  num_cache_nodes      = 1
  parameter_group_name = "default.redis7"
  port                 = 6379
  
  subnet_group_name    = aws_elasticache_subnet_group.main.name
  security_group_ids   = [aws_security_group.redis.id]
  
  snapshot_retention_limit = 5
  snapshot_window          = "03:00-05:00"
  
  tags = {
    Name = "${var.project_name}-${var.environment}-redis"
  }
}

# S3 Bucket for application data
resource "aws_s3_bucket" "app_data" {
  bucket = "${var.project_name}-${var.environment}-data"
  
  tags = {
    Name = "${var.project_name}-${var.environment}-data"
  }
}

resource "aws_s3_bucket_versioning" "app_data" {
  bucket = aws_s3_bucket.app_data.id
  
  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_s3_bucket_server_side_encryption_configuration" "app_data" {
  bucket = aws_s3_bucket.app_data.id
  
  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

# CloudWatch Log Group
resource "aws_cloudwatch_log_group" "app" {
  name              = "/aws/eks/${var.cluster_name}/application"
  retention_in_days = 30
  
  tags = {
    Application = var.project_name
    Environment = var.environment
  }
}

# Outputs
output "cluster_endpoint" {
  description = "EKS cluster endpoint"
  value       = module.eks.cluster_endpoint
}

output "cluster_name" {
  description = "EKS cluster name"
  value       = module.eks.cluster_name
}

output "db_endpoint" {
  description = "RDS instance endpoint"
  value       = aws_db_instance.main.endpoint
  sensitive   = true
}

output "redis_endpoint" {
  description = "Redis endpoint"
  value       = aws_elasticache_cluster.redis.cache_nodes[0].address
  sensitive   = true
}
```

#### Variables

```hcl
# terraform/variables.tf
variable "aws_region" {
  description = "AWS region"
  type        = string
  default     = "us-east-1"
}

variable "environment" {
  description = "Environment name"
  type        = string
}

variable "project_name" {
  description = "Project name"
  type        = string
  default     = "myapp"
}

variable "cluster_name" {
  description = "EKS cluster name"
  type        = string
}

variable "vpc_cidr" {
  description = "VPC CIDR block"
  type        = string
  default     = "10.0.0.0/16"
}

variable "availability_zones" {
  description = "Availability zones"
  type        = list(string)
  default     = ["us-east-1a", "us-east-1b", "us-east-1c"]
}

variable "private_subnet_cidrs" {
  description = "Private subnet CIDR blocks"
  type        = list(string)
  default     = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]
}

variable "public_subnet_cidrs" {
  description = "Public subnet CIDR blocks"
  type        = list(string)
  default     = ["10.0.101.0/24", "10.0.102.0/24", "10.0.103.0/24"]
}

variable "db_instance_class" {
  description = "RDS instance class"
  type        = string
  default     = "db.t3.medium"
}

variable "db_name" {
  description = "Database name"
  type        = string
}

variable "db_username" {
  description = "Database username"
  type        = string
  sensitive   = true
}

variable "db_password" {
  description = "Database password"
  type        = string
  sensitive   = true
}

variable "redis_node_type" {
  description = "Redis node type"
  type        = string
  default     = "cache.t3.micro"
}
```

#### Environment-specific Variables

```hcl
# terraform/environments/production.tfvars
environment    = "production"
cluster_name   = "myapp-prod-cluster"
db_instance_class = "db.r5.xlarge"
redis_node_type   = "cache.r5.large"

# terraform/environments/staging.tfvars
environment    = "staging"
cluster_name   = "myapp-staging-cluster"
db_instance_class = "db.t3.medium"
redis_node_type   = "cache.t3.small"
```

#### Terraform Workflow in CI/CD

```yaml
# GitHub Actions for Terraform
name: Terraform

on:
  push:
    branches: [ main ]
    paths:
      - 'terraform/**'
  pull_request:
    paths:
      - 'terraform/**'

jobs:
  terraform:
    name: Terraform Plan/Apply
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
      
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Terraform Init
        working-directory: terraform
        run: terraform init
      
      - name: Terraform Format Check
        working-directory: terraform
        run: terraform fmt -check
      
      - name: Terraform Validate
        working-directory: terraform
        run: terraform validate
      
      - name: Terraform Plan
        working-directory: terraform
        run: |
          terraform plan \
            -var-file="environments/${{ github.ref == 'refs/heads/main' && 'production' || 'staging' }}.tfvars" \
            -out=tfplan
      
      - name: Terraform Apply
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        working-directory: terraform
        run: terraform apply -auto-approve tfplan
```

---

### ArgoCD for GitOps

#### Installing ArgoCD

```bash
# Create namespace
kubectl create namespace argocd

# Install ArgoCD
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# Expose ArgoCD server
kubectl patch svc argocd-server -n argocd -p '{"spec": {"type": "LoadBalancer"}}'

# Get initial admin password
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d
```

#### ArgoCD Application Manifest

```yaml
# argocd/application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp
  namespace: argocd
spec:
  project: default
  
  # Source repository
  source:
    repoURL: https://github.com/myorg/myapp-manifests
    targetRevision: main
    path: k8s/overlays/production
    
    # Use Kustomize
    kustomize:
      version: v5.0.0
  
  # Destination cluster
  destination:
    server: https://kubernetes.default.svc
    namespace: production
  
  # Sync policy
  syncPolicy:
    automated:
      prune: true      # Delete resources not in Git
      selfHeal: true   # Sync when cluster state differs
      allowEmpty: false
    
    syncOptions:
      - CreateNamespace=true
      - PruneLast=true
    
    retry:
      limit: 5
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 3m
  
  # Health assessment
  ignoreDifferences:
    - group: apps
      kind: Deployment
      jsonPointers:
        - /spec/replicas  # Ignore HPA-managed replicas
  
  # Notifications
  notifications:
    - when: sync.failed
      destinations:
        - slack:myapp-deployments
```

#### ArgoCD App of Apps Pattern

```yaml
# argocd/app-of-apps.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: apps
  namespace: argocd
spec:
  project: default
  
  source:
    repoURL: https://github.com/myorg/infrastructure
    targetRevision: main
    path: argocd/applications
  
  destination:
    server: https://kubernetes.default.svc
    namespace: argocd
  
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
```

```yaml
# argocd/applications/myapp-dev.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp-dev
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/myorg/myapp-manifests
    targetRevision: develop
    path: k8s/overlays/dev
  destination:
    server: https://kubernetes.default.svc
    namespace: dev
  syncPolicy:
    automated:
      prune: true
      selfHeal: true

---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp-staging
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/myorg/myapp-manifests
    targetRevision: main
    path: k8s/overlays/staging
  destination:
    server: https://kubernetes.default.svc
    namespace: staging
  syncPolicy:
    automated:
      prune: true
      selfHeal: true

---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp-prod
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/myorg/myapp-manifests
    targetRevision: main
    path: k8s/overlays/production
  destination:
    server: https://kubernetes.default.svc
    namespace: production
  syncPolicy:
    # Manual sync for production
    syncOptions:
      - CreateNamespace=true
```

#### GitOps Workflow with ArgoCD

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GitOps with ArgoCD                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  1. Developer pushes code                           â”‚
â”‚     â†“                                                â”‚
â”‚  2. CI builds image & pushes to registry            â”‚
â”‚     â†“                                                â”‚
â”‚  3. CI updates image tag in Git repo                â”‚
â”‚     â†“                                                â”‚
â”‚  4. ArgoCD detects Git change                       â”‚
â”‚     â†“                                                â”‚
â”‚  5. ArgoCD syncs cluster state with Git             â”‚
â”‚     â†“                                                â”‚
â”‚  6. Application deployed to Kubernetes              â”‚
â”‚                                                      â”‚
â”‚  Git Repository (Source of Truth)                   â”‚
â”‚  â”œâ”€â”€ k8s/                                           â”‚
â”‚  â”‚   â”œâ”€â”€ base/                                      â”‚
â”‚  â”‚   â”‚   â”œâ”€â”€ deployment.yaml                       â”‚
â”‚  â”‚   â”‚   â”œâ”€â”€ service.yaml                          â”‚
â”‚  â”‚   â”‚   â””â”€â”€ kustomization.yaml                    â”‚
â”‚  â”‚   â””â”€â”€ overlays/                                  â”‚
â”‚  â”‚       â”œâ”€â”€ dev/                                   â”‚
â”‚  â”‚       â”œâ”€â”€ staging/                               â”‚
â”‚  â”‚       â””â”€â”€ production/                            â”‚
â”‚  â””â”€â”€ argocd/                                        â”‚
â”‚      â””â”€â”€ applications/                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Update Image Tag via CI/CD

```bash
# scripts/update-image-tag.sh
#!/bin/bash

NEW_TAG=$1
ENVIRONMENT=$2

# Clone manifests repo
git clone https://github.com/myorg/myapp-manifests.git
cd myapp-manifests

# Update image tag using kustomize
cd k8s/overlays/$ENVIRONMENT
kustomize edit set image myapp=ghcr.io/myorg/myapp:$NEW_TAG

# Commit and push
git add .
git commit -m "Update $ENVIRONMENT image to $NEW_TAG"
git push origin main

echo "Image tag updated. ArgoCD will sync automatically."
```

---

### Flux for Continuous Deployment

#### Installing Flux

```bash
# Install Flux CLI
curl -s https://fluxcd.io/install.sh | sudo bash

# Bootstrap Flux
flux bootstrap github \
  --owner=myorg \
  --repository=fleet-infra \
  --branch=main \
  --path=clusters/production \
  --personal

# Verify installation
flux check
```

#### Flux GitRepository

```yaml
# clusters/production/flux-system/gitrepository.yaml
apiVersion: source.toolkit.fluxcd.io/v1
kind: GitRepository
metadata:
  name: myapp-source
  namespace: flux-system
spec:
  interval: 1m
  url: https://github.com/myorg/myapp-manifests
  ref:
    branch: main
  secretRef:
    name: flux-system
```

#### Flux Kustomization

```yaml
# clusters/production/myapp/kustomization.yaml
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: myapp
  namespace: flux-system
spec:
  interval: 10m
  targetNamespace: production
  sourceRef:
    kind: GitRepository
    name: myapp-source
  path: ./k8s/overlays/production
  prune: true
  wait: true
  timeout: 5m
  
  # Health checks
  healthChecks:
    - apiVersion: apps/v1
      kind: Deployment
      name: myapp
      namespace: production
  
  # Post-deployment actions
  postBuild:
    substitute:
      cluster_name: "production"
      region: "us-east-1"
```

#### Flux Image Automation

```yaml
# clusters/production/myapp/image-update-automation.yaml
apiVersion: image.toolkit.fluxcd.io/v1beta1
kind: ImageRepository
metadata:
  name: myapp
  namespace: flux-system
spec:
  image: ghcr.io/myorg/myapp
  interval: 1m
  secretRef:
    name: ghcr-credentials

---
apiVersion: image.toolkit.fluxcd.io/v1beta1
kind: ImagePolicy
metadata:
  name: myapp
  namespace: flux-system
spec:
  imageRepositoryRef:
    name: myapp
  policy:
    semver:
      range: '>=1.0.0'

---
apiVersion: image.toolkit.fluxcd.io/v1beta1
kind: ImageUpdateAutomation
metadata:
  name: myapp
  namespace: flux-system
spec:
  interval: 1m
  sourceRef:
    kind: GitRepository
    name: myapp-source
  git:
    checkout:
      ref:
        branch: main
    commit:
      author:
        email: fluxbot@myorg.com
        name: Flux Bot
      messageTemplate: |
        Automated image update
        
        Automation name: {{ .AutomationObject }}
        
        Files:
        {{ range $filename, $_ := .Updated.Files -}}
        - {{ $filename }}
        {{ end -}}
        
        Objects:
        {{ range $resource, $_ := .Updated.Objects -}}
        - {{ $resource.Kind }} {{ $resource.Name }}
        {{ end -}}
        
        Images:
        {{ range .Updated.Images -}}
        - {{.}}
        {{ end -}}
    push:
      branch: main
  update:
    path: ./k8s/overlays/production
    strategy: Setters
```

---

## 3. Monitoring & Observability

### Prometheus Metrics

#### Installing Prometheus Stack

```bash
# Add Prometheus Helm repo
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Install Prometheus stack
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace \
  --set prometheus.prometheusSpec.retention=30d \
  --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=50Gi
```

#### Spring Boot Actuator for Metrics

```xml
<!-- pom.xml -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
```

```yaml
# application.yml
management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus,metrics
  endpoint:
    health:
      show-details: always
    prometheus:
      enabled: true
  metrics:
    tags:
      application: ${spring.application.name}
      environment: ${ENVIRONMENT:dev}
    export:
      prometheus:
        enabled: true
```

#### Custom Business Metrics

```java
// Java code for custom metrics
@Component
public class OrderMetrics {
    
    private final Counter ordersCreated;
    private final Counter ordersCompleted;
    private final Counter ordersFailed;
    private final Timer orderProcessingTime;
    private final Gauge activeOrders;
    
    public OrderMetrics(MeterRegistry registry) {
        this.ordersCreated = Counter.builder("orders.created")
            .description("Total orders created")
            .tags("service", "order")
            .register(registry);
        
        this.ordersCompleted = Counter.builder("orders.completed")
            .description("Total orders completed")
            .tags("service", "order")
            .register(registry);
        
        this.ordersFailed = Counter.builder("orders.failed")
            .description("Total orders failed")
            .tags("service", "order")
            .register(registry);
        
        this.orderProcessingTime = Timer.builder("orders.processing.time")
            .description("Order processing time")
            .tags("service", "order")
            .register(registry);
        
        this.activeOrders = Gauge.builder("orders.active", this, value -> getActiveOrderCount())
            .description("Number of active orders")
            .tags("service", "order")
            .register(registry);
    }
    
    public void recordOrderCreated() {
        ordersCreated.increment();
    }
    
    public void recordOrderCompleted() {
        ordersCompleted.increment();
    }
    
    public void recordOrderFailed() {
        ordersFailed.increment();
    }
    
    public void recordOrderProcessingTime(long milliseconds) {
        orderProcessingTime.record(milliseconds, TimeUnit.MILLISECONDS);
    }
    
    private long getActiveOrderCount() {
        // Implement logic to get active order count
        return 0;
    }
}

@Service
public class OrderService {
    
    private final OrderMetrics metrics;
    
    public OrderService(OrderMetrics metrics) {
        this.metrics = metrics;
    }
    
    public Order createOrder(OrderRequest request) {
        long startTime = System.currentTimeMillis();
        
        try {
            metrics.recordOrderCreated();
            
            // Business logic here
            Order order = processOrder(request);
            
            metrics.recordOrderCompleted();
            long processingTime = System.currentTimeMillis() - startTime;
            metrics.recordOrderProcessingTime(processingTime);
            
            return order;
            
        } catch (Exception e) {
            metrics.recordOrderFailed();
            throw e;
        }
    }
}
```

#### ServiceMonitor for Prometheus

```yaml
# k8s/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: myapp
  namespace: production
  labels:
    app: myapp
    release: prometheus
spec:
  selector:
    matchLabels:
      app: myapp
  endpoints:
    - port: http
      path: /actuator/prometheus
      interval: 30s
      scrapeTimeout: 10s
```

#### PrometheusRule for Alerts

```yaml
# k8s/prometheus-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: myapp-alerts
  namespace: monitoring
  labels:
    release: prometheus
spec:
  groups:
    - name: myapp
      interval: 30s
      rules:
        # High error rate
        - alert: HighErrorRate
          expr: |
            rate(http_server_requests_seconds_count{status=~"5..",job="myapp"}[5m])
            / rate(http_server_requests_seconds_count{job="myapp"}[5m])
            > 0.05
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "High error rate detected"
            description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.instance }}"
        
        # High response time
        - alert: HighResponseTime
          expr: |
            histogram_quantile(0.95,
              rate(http_server_requests_seconds_bucket{job="myapp"}[5m])
            ) > 1
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High response time detected"
            description: "95th percentile response time is {{ $value }}s"
        
        # Low availability
        - alert: ServiceDown
          expr: up{job="myapp"} == 0
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: "Service is down"
            description: "{{ $labels.instance }} is down"
        
        # High CPU usage
        - alert: HighCPUUsage
          expr: |
            rate(process_cpu_seconds_total{job="myapp"}[5m]) > 0.8
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "High CPU usage"
            description: "CPU usage is {{ $value | humanizePercentage }}"
        
        # High memory usage
        - alert: HighMemoryUsage
          expr: |
            (jvm_memory_used_bytes{job="myapp",area="heap"}
            / jvm_memory_max_bytes{job="myapp",area="heap"}) > 0.9
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High memory usage"
            description: "Memory usage is {{ $value | humanizePercentage }}"
        
        # Database connection pool exhaustion
        - alert: DatabaseConnectionPoolExhaustion
          expr: |
            hikaricp_connections_active{job="myapp"}
            / hikaricp_connections_max{job="myapp"} > 0.9
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Database connection pool nearly exhausted"
            description: "Connection pool usage is {{ $value | humanizePercentage }}"
```

---

### Grafana Dashboards

#### Installing Grafana

Grafana is included in the Prometheus stack installation above. Access it:

```bash
# Get Grafana password
kubectl get secret -n monitoring prometheus-grafana -o jsonpath="{.data.admin-password}" | base64 -d

# Port forward
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
```

#### Spring Boot Dashboard JSON

```json
{
  "dashboard": {
    "title": "Spring Boot Application Metrics",
    "panels": [
      {
        "title": "Request Rate",
        "targets": [
          {
            "expr": "rate(http_server_requests_seconds_count{job=\"myapp\"}[5m])",
            "legendFormat": "{{uri}} - {{method}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Error Rate",
        "targets": [
          {
            "expr": "rate(http_server_requests_seconds_count{job=\"myapp\",status=~\"5..\"}[5m])",
            "legendFormat": "{{uri}} - {{status}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Response Time (p95)",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_server_requests_seconds_bucket{job=\"myapp\"}[5m]))",
            "legendFormat": "{{uri}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "JVM Memory",
        "targets": [
          {
            "expr": "jvm_memory_used_bytes{job=\"myapp\",area=\"heap\"}",
            "legendFormat": "Used"
          },
          {
            "expr": "jvm_memory_max_bytes{job=\"myapp\",area=\"heap\"}",
            "legendFormat": "Max"
          }
        ],
        "type": "graph"
      },
      {
        "title": "GC Time",
        "targets": [
          {
            "expr": "rate(jvm_gc_pause_seconds_sum{job=\"myapp\"}[5m])",
            "legendFormat": "{{action}} - {{cause}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Database Connections",
        "targets": [
          {
            "expr": "hikaricp_connections_active{job=\"myapp\"}",
            "legendFormat": "Active"
          },
          {
            "expr": "hikaricp_connections_idle{job=\"myapp\"}",
            "legendFormat": "Idle"
          },
          {
            "expr": "hikaricp_connections_max{job=\"myapp\"}",
            "legendFormat": "Max"
          }
        ],
        "type": "graph"
      }
    ]
  }
}
```

#### Configuring Dashboard via ConfigMap

```yaml
# k8s/grafana-dashboard.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myapp-dashboard
  namespace: monitoring
  labels:
    grafana_dashboard: "1"
data:
  myapp-dashboard.json: |
    {
      "dashboard": {
        "title": "My Application",
        "panels": [
          // Dashboard JSON here
        ]
      }
    }
```

---

### ELK Stack for Logs

#### Installing ELK Stack

```bash
# Add Elastic Helm repo
helm repo add elastic https://helm.elastic.co
helm repo update

# Install Elasticsearch
helm install elasticsearch elastic/elasticsearch \
  --namespace logging \
  --create-namespace \
  --set replicas=3 \
  --set volumeClaimTemplate.resources.requests.storage=30Gi

# Install Kibana
helm install kibana elastic/kibana \
  --namespace logging \
  --set elasticsearchHosts="http://elasticsearch-master:9200"

# Install Filebeat
helm install filebeat elastic/filebeat \
  --namespace logging \
  --set daemonset.enabled=true
```

#### Logback Configuration for JSON Logs

```xml
<!-- src/main/resources/logback-spring.xml -->
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <include resource="org/springframework/boot/logging/logback/defaults.xml"/>
    
    <springProperty scope="context" name="springAppName" source="spring.application.name"/>
    <springProperty scope="context" name="environment" source="spring.profiles.active"/>
    
    <!-- Console appender for local dev -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>${CONSOLE_LOG_PATTERN}</pattern>
        </encoder>
    </appender>
    
    <!-- JSON appender for production -->
    <appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <customFields>{"app":"${springAppName}","environment":"${environment}"}</customFields>
            <fieldNames>
                <timestamp>timestamp</timestamp>
                <version>version</version>
                <logger>logger</logger>
                <thread>thread</thread>
                <level>level</level>
                <message>message</message>
                <stackTrace>stack_trace</stackTrace>
            </fieldNames>
        </encoder>
    </appender>
    
    <springProfile name="local,dev">
        <root level="INFO">
            <appender-ref ref="CONSOLE"/>
        </root>
    </springProfile>
    
    <springProfile name="staging,production">
        <root level="INFO">
            <appender-ref ref="JSON"/>
        </root>
    </springProfile>
    
    <!-- Application-specific loggers -->
    <logger name="com.myapp" level="DEBUG"/>
    <logger name="org.springframework.web" level="INFO"/>
    <logger name="org.hibernate" level="INFO"/>
</configuration>
```

```xml
<!-- pom.xml - Add dependency -->
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>7.4</version>
</dependency>
```

#### Structured Logging in Java

```java
// Use SLF4J with structured logging
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import net.logstash.logback.argument.StructuredArguments;

@RestController
@RequestMapping("/api/orders")
public class OrderController {
    
    private static final Logger log = LoggerFactory.getLogger(OrderController.class);
    
    @PostMapping
    public ResponseEntity<Order> createOrder(@RequestBody OrderRequest request) {
        log.info("Creating order",
            StructuredArguments.keyValue("userId", request.getUserId()),
            StructuredArguments.keyValue("items", request.getItems().size()),
            StructuredArguments.keyValue("totalAmount", request.getTotalAmount())
        );
        
        try {
            Order order = orderService.createOrder(request);
            
            log.info("Order created successfully",
                StructuredArguments.keyValue("orderId", order.getId()),
                StructuredArguments.keyValue("userId", request.getUserId()),
                StructuredArguments.keyValue("processingTime", order.getProcessingTimeMs())
            );
            
            return ResponseEntity.ok(order);
            
        } catch (Exception e) {
            log.error("Failed to create order",
                StructuredArguments.keyValue("userId", request.getUserId()),
                StructuredArguments.keyValue("error", e.getMessage()),
                e
            );
            throw e;
        }
    }
}
```

#### Filebeat Configuration

```yaml
# filebeat-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat-config
  namespace: logging
data:
  filebeat.yml: |
    filebeat.inputs:
    - type: container
      paths:
        - /var/log/containers/*.log
      processors:
        - add_kubernetes_metadata:
            host: ${NODE_NAME}
            matchers:
            - logs_path:
                logs_path: "/var/log/containers/"
        - decode_json_fields:
            fields: ["message"]
            target: ""
            overwrite_keys: true
    
    output.elasticsearch:
      hosts: ['${ELASTICSEARCH_HOST:elasticsearch-master}:${ELASTICSEARCH_PORT:9200}']
      indices:
        - index: "myapp-logs-%{+yyyy.MM.dd}"
          when.contains:
            kubernetes.labels.app: "myapp"
    
    setup.kibana:
      host: '${KIBANA_HOST:kibana}:${KIBANA_PORT:5601}'
    
    setup.ilm:
      enabled: true
      rollover_alias: "myapp-logs"
      pattern: "{now/d}-000001"
      policy_name: "myapp-logs-policy"
```

#### Kibana Index Pattern and Queries

```bash
# Create index pattern in Kibana
curl -X POST "http://kibana:5601/api/saved_objects/index-pattern/myapp-logs" \
  -H 'kbn-xsrf: true' \
  -H 'Content-Type: application/json' \
  -d '{
    "attributes": {
      "title": "myapp-logs-*",
      "timeFieldName": "timestamp"
    }
  }'
```

**Common Kibana queries:**

```
# Find errors in last hour
level:"ERROR" AND timestamp:[now-1h TO now]

# Find slow requests (>1s)
logger:"com.myapp.controller.*" AND processingTime:>1000

# Find specific user activity
userId:"user123" AND timestamp:[now-24h TO now]

# Find database errors
message:"SQLException" OR message:"database connection"

# Find orders with high amounts
totalAmount:>10000 AND message:"Order created"
```

---

### Distributed Tracing (Jaeger)

#### Installing Jaeger

```bash
# Install Jaeger Operator
kubectl create namespace observability
kubectl apply -f https://github.com/jaegertracing/jaeger-operator/releases/download/v1.51.0/jaeger-operator.yaml -n observability

# Deploy Jaeger instance
kubectl apply -f - <<EOF
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: jaeger
  namespace: observability
spec:
  strategy: production
  storage:
    type: elasticsearch
    options:
      es:
        server-urls: http://elasticsearch-master.logging:9200
  ingress:
    enabled: true
EOF
```

#### Spring Boot with Jaeger

```xml
<!-- pom.xml -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-tracing-bridge-otel</artifactId>
</dependency>

<dependency>
    <groupId>io.opentelemetry</groupId>
    <artifactId>opentelemetry-exporter-otlp</artifactId>
</dependency>
```

```yaml
# application.yml
management:
  tracing:
    sampling:
      probability: 1.0  # Sample 100% in dev, lower in prod (e.g., 0.1 for 10%)
  otlp:
    tracing:
      endpoint: http://jaeger-collector.observability:4318/v1/traces

spring:
  application:
    name: myapp
```

#### Custom Spans

```java
import io.micrometer.observation.Observation;
import io.micrometer.observation.ObservationRegistry;

@Service
public class OrderService {
    
    private final ObservationRegistry observationRegistry;
    
    public OrderService(ObservationRegistry observationRegistry) {
        this.observationRegistry = observationRegistry;
    }
    
    public Order processOrder(OrderRequest request) {
        return Observation
            .createNotStarted("order.processing", observationRegistry)
            .contextualName("Process Order")
            .lowCardinalityKeyValue("order.type", request.getType())
            .highCardinalityKeyValue("order.id", request.getId())
            .observe(() -> {
                // Business logic here
                
                // Add custom span
                Observation.createNotStarted("order.validation", observationRegistry)
                    .observe(() -> validateOrder(request));
                
                Observation.createNotStarted("order.payment", observationRegistry)
                    .observe(() -> processPayment(request));
                
                Observation.createNotStarted("order.fulfillment", observationRegistry)
                    .observe(() -> fulfillOrder(request));
                
                return order;
            });
    }
}
```

#### Trace Propagation

```java
// Automatic trace propagation with RestTemplate
@Configuration
public class RestTemplateConfig {
    
    @Bean
    public RestTemplate restTemplate(RestTemplateBuilder builder) {
        return builder
            .interceptors(new RestTemplateTracingInterceptor())
            .build();
    }
}

// Or with WebClient
@Configuration
public class WebClientConfig {
    
    @Bean
    public WebClient webClient(WebClient.Builder builder) {
        return builder
            .filter(new WebClientTracingFilter())
            .build();
    }
}
```

---

### Distributed Tracing (Zipkin)

#### Installing Zipkin

```bash
# Install Zipkin
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: zipkin
  namespace: observability
spec:
  replicas: 1
  selector:
    matchLabels:
      app: zipkin
  template:
    metadata:
      labels:
        app: zipkin
    spec:
      containers:
      - name: zipkin
        image: openzipkin/zipkin:latest
        ports:
        - containerPort: 9411
        env:
        - name: STORAGE_TYPE
          value: elasticsearch
        - name: ES_HOSTS
          value: http://elasticsearch-master.logging:9200
---
apiVersion: v1
kind: Service
metadata:
  name: zipkin
  namespace: observability
spec:
  selector:
    app: zipkin
  ports:
  - port: 9411
    targetPort: 9411
  type: LoadBalancer
EOF
```

#### Spring Boot with Zipkin

```xml
<!-- pom.xml -->
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-tracing-bridge-brave</artifactId>
</dependency>

<dependency>
    <groupId>io.zipkin.reporter2</groupId>
    <artifactId>zipkin-reporter-brave</artifactId>
</dependency>
```

```yaml
# application.yml
management:
  tracing:
    sampling:
      probability: 0.1  # Sample 10% of traces
  zipkin:
    tracing:
      endpoint: http://zipkin.observability:9411/api/v2/spans

spring:
  application:
    name: myapp
```

---

## Summary

### Complete CI/CD Pipeline

- âœ… **End-to-end workflow**: Code commit â†’ Build â†’ Test â†’ Analyze â†’ Package â†’ Scan â†’ Deploy
- âœ… **Multi-stage**: Development â†’ Staging â†’ Production with gates
- âœ… **Security**: SonarQube, OWASP, Trivy, Snyk, SBOM generation
- âœ… **Testing**: Unit, integration, smoke, performance tests
- âœ… **Deployment strategies**: Blue-green, canary, rolling updates
- âœ… **Rollback**: Automated rollback on failure

### Infrastructure as Code

- âœ… **Terraform**: VPC, EKS, RDS, ElastiCache, S3 provisioning
- âœ… **ArgoCD**: GitOps-based continuous deployment
- âœ… **Flux**: Alternative GitOps with image automation
- âœ… **Version control**: All infrastructure in Git

### Monitoring & Observability

- âœ… **Prometheus**: Metrics collection and alerting
- âœ… **Grafana**: Visualization and dashboards
- âœ… **ELK Stack**: Centralized logging (Elasticsearch, Logstash, Kibana)
- âœ… **Jaeger/Zipkin**: Distributed tracing across microservices
- âœ… **Custom metrics**: Business KPIs and SLIs
- âœ… **Structured logging**: JSON logs for easy parsing
- âœ… **Alerting**: PagerDuty, Slack integration

