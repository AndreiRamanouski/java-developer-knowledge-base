
## 1. Spring Boot on Kubernetes

### Graceful Shutdown

**Problem:** When Kubernetes terminates a pod, in-flight requests may fail.

**Solution:** Implement graceful shutdown.

```yaml
# application.properties
server.shutdown=graceful
spring.lifecycle.timeout-per-shutdown-phase=30s
```

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: spring-app
  template:
    metadata:
      labels:
        app: spring-app
    spec:
      containers:
      - name: app
        image: mycompany/spring-app:1.0.0
        ports:
        - containerPort: 8080
        
        lifecycle:
          preStop:
            exec:
              command: ["sh", "-c", "sleep 10"]
        
        # Give app time to finish requests
        terminationGracePeriodSeconds: 40
        
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
```

**Shutdown Sequence:**

```
1. Pod receives SIGTERM
2. Kubernetes removes pod from Service endpoints
3. PreStop hook executes (sleep 10s)
   - Allows time for load balancers to update
   - Prevents new connections
4. Spring Boot graceful shutdown begins
   - Stops accepting new requests
   - Completes in-flight requests (up to 30s)
5. After 40s total, SIGKILL sent (force kill)
```

**Spring Boot Shutdown Hook:**

```java
@Component
public class GracefulShutdown {
    
    @PreDestroy
    public void onShutdown() {
        log.info("Graceful shutdown initiated");
        // Clean up resources
        // Close connections
        // Flush metrics
    }
}
```

---

### Actuator for Health Checks

**Spring Boot Actuator** provides production-ready endpoints.

**Maven Dependency:**

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
```

**Configuration:**

```yaml
# application.properties
management.endpoints.web.exposure.include=health,info,metrics,prometheus
management.endpoint.health.probes.enabled=true
management.endpoint.health.show-details=always
management.health.livenessState.enabled=true
management.health.readinessState.enabled=true

# Customize health check behavior
management.endpoint.health.group.liveness.include=livenessState,diskSpace
management.endpoint.health.group.readiness.include=readinessState,db,redis
```

**Kubernetes Integration:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-app
spec:
  template:
    spec:
      containers:
      - name: app
        image: spring-app:1.0.0
        ports:
        - containerPort: 8080
          name: http
        
        # Startup probe for slow-starting apps
        startupProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          failureThreshold: 30
          periodSeconds: 10
          # Gives up to 5 minutes to start
        
        # Liveness probe
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        
        # Readiness probe
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          initialDelaySeconds: 0
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2
```

**Custom Health Indicators:**

```java
@Component
public class DatabaseHealthIndicator implements HealthIndicator {
    
    @Autowired
    private DataSource dataSource;
    
    @Override
    public Health health() {
        try {
            Connection connection = dataSource.getConnection();
            Statement statement = connection.createStatement();
            statement.execute("SELECT 1");
            return Health.up()
                .withDetail("database", "Available")
                .build();
        } catch (Exception e) {
            return Health.down()
                .withDetail("database", "Unavailable")
                .withException(e)
                .build();
        }
    }
}
```

**Health Check Endpoints:**

```bash
# Liveness: Is application alive?
curl http://localhost:8080/actuator/health/liveness
# Response: {"status":"UP"}

# Readiness: Is application ready for traffic?
curl http://localhost:8080/actuator/health/readiness
# Response: {"status":"UP","components":{"db":{"status":"UP"}}}

# Full health (detailed)
curl http://localhost:8080/actuator/health
```

---

### ConfigMaps for application.properties

**Externalize configuration** using ConfigMaps.

**ConfigMap:**

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: spring-config
  namespace: production
data:
  application.yaml: |
    spring:
      application:
        name: myapp
      datasource:
        url: jdbc:postgresql://postgres.production.svc.cluster.local:5432/mydb
        username: appuser
        hikari:
          maximum-pool-size: 20
          minimum-idle: 5
          connection-timeout: 30000
      
      redis:
        host: redis.production.svc.cluster.local
        port: 6379
      
      jpa:
        hibernate:
          ddl-auto: validate
        show-sql: false
        properties:
          hibernate:
            format_sql: false
    
    logging:
      level:
        root: INFO
        com.mycompany: DEBUG
    
    server:
      port: 8080
      shutdown: graceful
    
    management:
      endpoints:
        web:
          exposure:
            include: health,info,metrics,prometheus
```

**Deployment:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-app
spec:
  template:
    spec:
      containers:
      - name: app
        image: spring-app:1.0.0
        
        # Mount ConfigMap as file
        volumeMounts:
        - name: config
          mountPath: /config
          readOnly: true
        
        # Point Spring Boot to config file
        env:
        - name: SPRING_CONFIG_LOCATION
          value: file:/config/application.yaml
        
        # Or use individual environment variables
        - name: SPRING_DATASOURCE_URL
          valueFrom:
            configMapKeyRef:
              name: spring-config
              key: database.url
      
      volumes:
      - name: config
        configMap:
          name: spring-config
```

**Multiple Profiles:**

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: spring-config
data:
  application.yaml: |
    # Base configuration
    spring:
      application:
        name: myapp
  
  application-production.yaml: |
    # Production-specific
    spring:
      datasource:
        hikari:
          maximum-pool-size: 50
    logging:
      level:
        root: WARN
  
  application-staging.yaml: |
    # Staging-specific
    spring:
      datasource:
        hikari:
          maximum-pool-size: 10
    logging:
      level:
        root: DEBUG
```

```yaml
# Deployment with profile
spec:
  containers:
  - name: app
    image: spring-app:1.0.0
    env:
    - name: SPRING_PROFILES_ACTIVE
      value: "production"
    - name: SPRING_CONFIG_LOCATION
      value: "file:/config/"
    volumeMounts:
    - name: config
      mountPath: /config
```

---

### Secrets for Database Passwords

**Never store passwords in ConfigMaps!** Use Secrets.

**Secret:**

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: spring-secrets
  namespace: production
type: Opaque
stringData:
  # Automatically base64 encoded
  spring.datasource.password: "MySecretPassword123!"
  spring.redis.password: "RedisSecret456!"
  jwt.secret: "JwtSecretKey789xyz"
```

**Deployment:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-app
spec:
  template:
    spec:
      containers:
      - name: app
        image: spring-app:1.0.0
        
        env:
        # Non-sensitive from ConfigMap
        - name: SPRING_DATASOURCE_URL
          valueFrom:
            configMapKeyRef:
              name: spring-config
              key: database.url
        
        - name: SPRING_DATASOURCE_USERNAME
          valueFrom:
            configMapKeyRef:
              name: spring-config
              key: database.username
        
        # Sensitive from Secret
        - name: SPRING_DATASOURCE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: spring-secrets
              key: spring.datasource.password
        
        - name: SPRING_REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: spring-secrets
              key: spring.redis.password
        
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: spring-secrets
              key: jwt.secret
```

**Mount Secrets as Files:**

```yaml
spec:
  containers:
  - name: app
    image: spring-app:1.0.0
    
    volumeMounts:
    - name: secrets
      mountPath: /secrets
      readOnly: true
    
    env:
    # Point to secret file
    - name: SPRING_DATASOURCE_PASSWORD_FILE
      value: /secrets/database-password
  
  volumes:
  - name: secrets
    secret:
      secretName: spring-secrets
      items:
      - key: spring.datasource.password
        path: database-password
```

```java
// Read secret from file
@Configuration
public class DataSourceConfig {
    
    @Value("${spring.datasource.password-file:}")
    private String passwordFile;
    
    @Bean
    public DataSource dataSource() {
        String password;
        if (passwordFile != null && !passwordFile.isEmpty()) {
            // Read from file (Kubernetes Secret)
            password = new String(Files.readAllBytes(Paths.get(passwordFile)));
        } else {
            // Read from environment variable
            password = System.getenv("SPRING_DATASOURCE_PASSWORD");
        }
        
        HikariConfig config = new HikariConfig();
        config.setPassword(password);
        return new HikariDataSource(config);
    }
}
```

---

### Resource Tuning (JVM Heap in Containers)

**Problem:** JVM doesn't respect container memory limits (pre-Java 10).

**Java 8 Solution:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-app
spec:
  template:
    spec:
      containers:
      - name: app
        image: spring-app:1.0.0
        
        env:
        # Explicitly set JVM heap
        - name: JAVA_OPTS
          value: "-Xms512m -Xmx768m -XX:+UseG1GC -XX:MaxGCPauseMillis=100"
        
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "1Gi"  # Container limit
            cpu: "1000m"

# Heap breakdown:
# 1Gi total memory
# - 768m JVM heap (75%)
# - 256m off-heap (metaspace, threads, direct buffers, etc.)
```

**Java 11+ Solution (Container-aware):**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-app
spec:
  template:
    spec:
      containers:
      - name: app
        image: openjdk:17-jdk-slim
        
        env:
        # Let JVM automatically size heap based on container memory
        - name: JAVA_OPTS
          value: >-
            -XX:+UseContainerSupport
            -XX:MaxRAMPercentage=75.0
            -XX:InitialRAMPercentage=50.0
            -XX:+UseG1GC
            -XX:MaxGCPauseMillis=100
            -XX:+HeapDumpOnOutOfMemoryError
            -XX:HeapDumpPath=/tmp/heapdump.hprof
        
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"

# JVM automatically sets:
# Max heap = 1Gi * 75% = 768Mi
# Initial heap = 1Gi * 50% = 512Mi
```

**Complete Dockerfile:**

```dockerfile
FROM openjdk:17-jdk-slim

# Non-root user
RUN useradd -m -u 1000 appuser

WORKDIR /app

COPY target/myapp.jar app.jar

# Change ownership
RUN chown -R appuser:appuser /app

USER appuser

EXPOSE 8080

# Use shell form to allow variable expansion
ENTRYPOINT exec java $JAVA_OPTS -jar app.jar
```

**Resource Calculation Guide:**

```yaml
# Small app (< 100 RPS)
resources:
  requests:
    memory: "512Mi"  # Heap: ~384Mi
    cpu: "250m"
  limits:
    memory: "512Mi"
    cpu: "500m"

# Medium app (100-1000 RPS)
resources:
  requests:
    memory: "1Gi"    # Heap: ~768Mi
    cpu: "500m"
  limits:
    memory: "1Gi"
    cpu: "1000m"

# Large app (> 1000 RPS)
resources:
  requests:
    memory: "2Gi"    # Heap: ~1.5Gi
    cpu: "1000m"
  limits:
    memory: "2Gi"
    cpu: "2000m"
```

**JVM Tuning Recommendations:**

```yaml
env:
- name: JAVA_OPTS
  value: >-
    -XX:+UseContainerSupport
    -XX:MaxRAMPercentage=75.0
    -XX:InitialRAMPercentage=50.0
    
    # G1 GC (recommended for containers)
    -XX:+UseG1GC
    -XX:MaxGCPauseMillis=100
    -XX:G1ReservePercent=20
    
    # Heap dumps for debugging
    -XX:+HeapDumpOnOutOfMemoryError
    -XX:HeapDumpPath=/tmp/heapdump.hprof
    
    # GC logging
    -Xlog:gc*:file=/tmp/gc.log:time,uptime:filecount=5,filesize=10M
    
    # Exit on OOM
    -XX:+ExitOnOutOfMemoryError
    
    # Faster startup
    -XX:TieredStopAtLevel=1
    -noverify
```

---

### Complete Spring Boot Deployment Example

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: spring-config
  namespace: production
data:
  application.yaml: |
    spring:
      application:
        name: myapp
      datasource:
        url: jdbc:postgresql://postgres:5432/mydb
        username: appuser
        hikari:
          maximum-pool-size: 20
      redis:
        host: redis
        port: 6379
    server:
      port: 8080
      shutdown: graceful
    management:
      endpoints.web.exposure.include: health,info,metrics,prometheus
      endpoint.health.probes.enabled: true

---
apiVersion: v1
kind: Secret
metadata:
  name: spring-secrets
  namespace: production
type: Opaque
stringData:
  database-password: "MySecretPassword123!"
  redis-password: "RedisSecret456!"

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-app
  namespace: production
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  
  selector:
    matchLabels:
      app: spring-app
  
  template:
    metadata:
      labels:
        app: spring-app
        version: "1.0.0"
    spec:
      serviceAccountName: spring-app
      
      # Security
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      
      containers:
      - name: app
        image: mycompany/spring-app:1.0.0
        imagePullPolicy: Always
        
        ports:
        - containerPort: 8080
          name: http
        
        env:
        # Profile
        - name: SPRING_PROFILES_ACTIVE
          value: "production"
        
        # Config location
        - name: SPRING_CONFIG_LOCATION
          value: "file:/config/application.yaml"
        
        # Database password from Secret
        - name: SPRING_DATASOURCE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: spring-secrets
              key: database-password
        
        # Redis password from Secret
        - name: SPRING_REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: spring-secrets
              key: redis-password
        
        # JVM options
        - name: JAVA_OPTS
          value: >-
            -XX:+UseContainerSupport
            -XX:MaxRAMPercentage=75.0
            -XX:+UseG1GC
            -XX:MaxGCPauseMillis=100
            -XX:+HeapDumpOnOutOfMemoryError
            -XX:HeapDumpPath=/tmp/heapdump.hprof
        
        # Downward API
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        
        volumeMounts:
        - name: config
          mountPath: /config
          readOnly: true
        - name: tmp
          mountPath: /tmp
        
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        
        # Health checks
        startupProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          failureThreshold: 30
          periodSeconds: 10
        
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2
        
        # Graceful shutdown
        lifecycle:
          preStop:
            exec:
              command: ["sh", "-c", "sleep 10"]
        
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          capabilities:
            drop:
            - ALL
      
      terminationGracePeriodSeconds: 40
      
      volumes:
      - name: config
        configMap:
          name: spring-config
      - name: tmp
        emptyDir: {}

---
apiVersion: v1
kind: Service
metadata:
  name: spring-app
  namespace: production
spec:
  type: ClusterIP
  selector:
    app: spring-app
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
```

---

## 2. Common Patterns

### Sidecar Pattern (Logging, Monitoring)

**Sidecar container** enhances main container without changing it.

**Example: Log Aggregation**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: webapp-with-logging
spec:
  containers:
  # Main application
  - name: webapp
    image: myapp:1.0.0
    ports:
    - containerPort: 8080
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
  
  # Sidecar: Log shipper
  - name: log-shipper
    image: fluent/fluentd:v1.16
    env:
    - name: FLUENTD_CONF
      value: fluent.conf
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
      readOnly: true
    - name: fluentd-config
      mountPath: /fluentd/etc
  
  volumes:
  - name: app-logs
    emptyDir: {}
  - name: fluentd-config
    configMap:
      name: fluentd-config
```

**Example: Metrics Exporter**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: app-with-metrics
spec:
  containers:
  # Main application (doesn't expose Prometheus metrics)
  - name: app
    image: legacy-app:1.0
    ports:
    - containerPort: 8080
  
  # Sidecar: Prometheus exporter
  - name: metrics-exporter
    image: prom/statsd-exporter:v0.26.0
    ports:
    - containerPort: 9102
      name: metrics
    args:
    - --statsd.mapping-config=/etc/statsd/statsd-mapping.conf
```

**Example: Security Proxy (Istio Pattern)**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: app-with-proxy
spec:
  containers:
  # Main application
  - name: app
    image: myapp:1.0
    ports:
    - containerPort: 8080
  
  # Sidecar: Envoy proxy
  - name: istio-proxy
    image: istio/proxyv2:1.20.0
    ports:
    - containerPort: 15001
    env:
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    # Intercepts all traffic, provides:
    # - mTLS encryption
    # - Traffic management
    # - Observability
```

---

### Ambassador Pattern (Proxy)

**Ambassador container** proxies network connections.

**Example: Database Connection Pooler**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: app-with-pgbouncer
spec:
  containers:
  # Main application
  - name: app
    image: myapp:1.0
    env:
    # Connect to localhost (ambassador)
    - name: DATABASE_HOST
      value: "localhost"
    - name: DATABASE_PORT
      value: "5432"
  
  # Ambassador: PgBouncer (connection pooler)
  - name: pgbouncer
    image: pgbouncer/pgbouncer:1.21
    ports:
    - containerPort: 5432
    env:
    - name: DB_HOST
      value: postgres.production.svc.cluster.local
    - name: DB_PORT
      value: "5432"
    - name: POOL_MODE
      value: "transaction"
    - name: MAX_CLIENT_CONN
      value: "1000"
    - name: DEFAULT_POOL_SIZE
      value: "20"
    volumeMounts:
    - name: pgbouncer-config
      mountPath: /etc/pgbouncer
  
  volumes:
  - name: pgbouncer-config
    configMap:
      name: pgbouncer-config

# Benefits:
# - App thinks it's connecting to local database
# - PgBouncer provides connection pooling
# - Reduces connections to actual database
# - Can change DB without changing app
```

**Example: API Rate Limiter**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: app-with-rate-limiter
spec:
  containers:
  # Main application
  - name: app
    image: myapp:1.0
    ports:
    - containerPort: 8080
  
  # Ambassador: Nginx rate limiter
  - name: rate-limiter
    image: nginx:1.25
    ports:
    - containerPort: 80
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/nginx.conf
      subPath: nginx.conf
  
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-rate-limit-config

# nginx.conf includes rate limiting
# limit_req_zone $binary_remote_addr zone=one:10m rate=10r/s;
```

---

### Adapter Pattern (Normalize Output)

**Adapter container** transforms/normalizes output.

**Example: Log Format Adapter**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: legacy-app-with-adapter
spec:
  containers:
  # Main application (outputs non-standard logs)
  - name: legacy-app
    image: legacy-app:1.0
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
  
  # Adapter: Converts logs to JSON
  - name: log-adapter
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      tail -f /var/log/app/app.log | while read line; do
        echo "{\"timestamp\":\"$(date -Iseconds)\",\"message\":\"$line\"}"
      done
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
  
  volumes:
  - name: app-logs
    emptyDir: {}
```

**Example: Metrics Format Adapter**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: app-with-metrics-adapter
spec:
  containers:
  # Main application (outputs custom metrics format)
  - name: app
    image: app-custom-metrics:1.0
    volumeMounts:
    - name: metrics
      mountPath: /var/metrics
  
  # Adapter: Converts to Prometheus format
  - name: metrics-adapter
    image: prom/statsd-exporter:v0.26.0
    ports:
    - containerPort: 9102
      name: prometheus
    volumeMounts:
    - name: metrics
      mountPath: /var/metrics
    command:
    - /bin/statsd_exporter
    - --statsd.mapping-config=/etc/adapter/mapping.conf
  
  volumes:
  - name: metrics
    emptyDir: {}
```

---

### Init Containers (Wait for Dependencies)

**Init containers** run before main containers, ensuring dependencies ready.

**Example: Wait for Database**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: spring-app
spec:
  initContainers:
  # Wait for PostgreSQL
  - name: wait-for-db
    image: busybox:1.36
    command:
    - sh
    - -c
    - |
      until nc -z postgres.production.svc.cluster.local 5432; do
        echo "Waiting for database..."
        sleep 2
      done
      echo "Database is ready!"
  
  # Wait for Redis
  - name: wait-for-redis
    image: busybox:1.36
    command:
    - sh
    - -c
    - |
      until nc -z redis.production.svc.cluster.local 6379; do
        echo "Waiting for Redis..."
        sleep 2
      done
      echo "Redis is ready!"
  
  containers:
  - name: app
    image: spring-app:1.0
    # Starts only after init containers complete
```

**Example: Database Migration**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: spring-app
spec:
  initContainers:
  # Run Flyway migrations
  - name: db-migration
    image: flyway/flyway:9
    command:
    - flyway
    - migrate
    args:
    - -url=jdbc:postgresql://postgres:5432/mydb
    - -user=admin
    - -password=secret
    - -locations=filesystem:/migrations
    volumeMounts:
    - name: migrations
      mountPath: /migrations
  
  containers:
  - name: app
    image: spring-app:1.0
    # App starts with migrated database
  
  volumes:
  - name: migrations
    configMap:
      name: db-migrations
```

**Example: Configuration Setup**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  initContainers:
  # Generate dynamic configuration
  - name: config-generator
    image: busybox
    command:
    - sh
    - -c
    - |
      # Generate config based on environment
      cat > /config/app.conf <<EOF
      server_name=$(hostname)
      environment=production
      timestamp=$(date -Iseconds)
      EOF
      echo "Configuration generated"
    volumeMounts:
    - name: config
      mountPath: /config
  
  containers:
  - name: app
    image: myapp:1.0
    volumeMounts:
    - name: config
      mountPath: /etc/app
  
  volumes:
  - name: config
    emptyDir: {}
```

---

## 3. Migration Strategies

### Blue-Green Deployments

**Blue-Green:** Run two identical environments. Switch traffic instantly.

```yaml
# Blue deployment (current version)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-blue
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: blue
  template:
    metadata:
      labels:
        app: myapp
        version: blue
    spec:
      containers:
      - name: app
        image: myapp:1.0.0
        ports:
        - containerPort: 8080

---
# Green deployment (new version)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-green
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: green
  template:
    metadata:
      labels:
        app: myapp
        version: green
    spec:
      containers:
      - name: app
        image: myapp:2.0.0
        ports:
        - containerPort: 8080

---
# Service (initially points to blue)
apiVersion: v1
kind: Service
metadata:
  name: myapp
spec:
  selector:
    app: myapp
    version: blue  # Traffic goes to blue
  ports:
  - port: 80
    targetPort: 8080
```

**Deployment Process:**

```bash
# 1. Deploy green (new version)
kubectl apply -f deployment-green.yaml

# 2. Test green internally
kubectl port-forward svc/app-green 8080:80
curl http://localhost:8080

# 3. Switch traffic to green (instant!)
kubectl patch service myapp -p '{"spec":{"selector":{"version":"green"}}}'

# 4. Monitor new version
# If issues, rollback instantly:
kubectl patch service myapp -p '{"spec":{"selector":{"version":"blue"}}}'

# 5. If successful, delete blue
kubectl delete deployment app-blue
```

**Pros:**

- ✅ Instant switchover
- ✅ Instant rollback
- ✅ Zero downtime
- ✅ Test new version before switch

**Cons:**

- ❌ Double resources (expensive)
- ❌ Database migrations tricky
- ❌ Not suitable for stateful apps

---

### Canary Deployments

**Canary:** Gradually shift traffic to new version.

```yaml
# Stable deployment (90% traffic)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-stable
spec:
  replicas: 9
  selector:
    matchLabels:
      app: myapp
      version: stable
  template:
    metadata:
      labels:
        app: myapp
        version: stable
    spec:
      containers:
      - name: app
        image: myapp:1.0.0

---
# Canary deployment (10% traffic)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-canary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myapp
      version: canary
  template:
    metadata:
      labels:
        app: myapp
        version: canary
    spec:
      containers:
      - name: app
        image: myapp:2.0.0

---
# Service (load balances across both)
apiVersion: v1
kind: Service
metadata:
  name: myapp
spec:
  selector:
    app: myapp  # No version selector!
  ports:
  - port: 80
    targetPort: 8080
```

**Deployment Process:**

```bash
# 1. Deploy canary (1 replica = 10% traffic)
kubectl apply -f deployment-canary.yaml

# 2. Monitor metrics
# - Error rate
# - Latency
# - User feedback

# 3. If good, increase canary
kubectl scale deployment app-canary --replicas=3  # 25% traffic
kubectl scale deployment app-stable --replicas=6  # 75% traffic

# 4. Continue increasing
kubectl scale deployment app-canary --replicas=5  # 50% traffic
kubectl scale deployment app-stable --replicas=5  # 50% traffic

# 5. Full rollout
kubectl scale deployment app-canary --replicas=10  # 100% traffic
kubectl delete deployment app-stable

# Rename canary to stable for next deployment
kubectl patch deployment app-canary -p '{"metadata":{"name":"app-stable"}}'
```

**Advanced: Traffic Splitting with Istio**

```yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp
spec:
  hosts:
  - myapp
  http:
  - match:
    - headers:
        user-agent:
          regex: ".*Mobile.*"
    route:
    - destination:
        host: myapp
        subset: canary
      weight: 50  # 50% mobile traffic to canary
    - destination:
        host: myapp
        subset: stable
      weight: 50
  
  - route:
    - destination:
        host: myapp
        subset: canary
      weight: 10  # 10% overall traffic to canary
    - destination:
        host: myapp
        subset: stable
      weight: 90
```

**Pros:**

- ✅ Gradual rollout
- ✅ Low risk
- ✅ Real user feedback
- ✅ Easy rollback

**Cons:**

- ❌ Complex monitoring required
- ❌ Longer deployment time
- ❌ Requires traffic splitting capability

---

### Rolling Updates

**Rolling Update:** Default Kubernetes deployment strategy.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 10
  
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 2        # Max 2 extra pods during update
      maxUnavailable: 1  # Max 1 pod unavailable during update
  
  selector:
    matchLabels:
      app: myapp
  
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        image: myapp:1.0.0
        
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          periodSeconds: 5
        
        lifecycle:
          preStop:
            exec:
              command: ["sh", "-c", "sleep 10"]
```

**Update Process:**

```bash
# Update image
kubectl set image deployment/myapp app=myapp:2.0.0

# What happens:
# 1. Create 2 new pods (maxSurge)
# 2. Wait for new pods to be ready
# 3. Terminate 1 old pod (maxUnavailable)
# 4. Repeat until all updated

# Monitor rollout
kubectl rollout status deployment/myapp

# Pause rollout
kubectl rollout pause deployment/myapp

# Resume rollout
kubectl rollout resume deployment/myapp
```

**Timeline Example:**

```
Replicas: 10, maxSurge: 2, maxUnavailable: 1

Time  Old  New  Total  Status
----  ---  ---  -----  ------
t=0   10   0    10     Create 2 new pods
t=1   10   2    12     Wait for new pods ready
t=2   10   2    12     New pods ready
t=3   9    2    11     Terminate 1 old pod
t=4   9    2    11     Create 2 more new pods
t=5   9    4    13     Wait for new pods ready
t=6   9    4    13     New pods ready
t=7   8    4    12     Terminate 1 old pod
...continues until...
t=N   0    10   10     All pods updated
```

**Pros:**

- ✅ Zero downtime
- ✅ Automatic (built-in)
- ✅ No extra resources needed
- ✅ Gradual rollout

**Cons:**

- ❌ Slower than blue-green
- ❌ Mixed versions during rollout
- ❌ Rollback not instant

---

### Rollback Strategies

**Automatic Rollback:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  progressDeadlineSeconds: 600  # Rollout must complete in 10min
  
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0  # Zero downtime
  
  template:
    spec:
      containers:
      - name: app
        image: myapp:2.0.0
        
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          failureThreshold: 3
          periodSeconds: 5

# If new pods fail readiness probe:
# - Rollout stalls (doesn't continue)
# - After progressDeadlineSeconds, rollout fails
# - Manual rollback required
```

**Manual Rollback:**

```bash
# View rollout history
kubectl rollout history deployment/myapp

# Output:
REVISION  CHANGE-CAUSE
1         Initial deployment
2         Updated image to v2.0.0
3         Updated image to v3.0.0

# Rollback to previous version
kubectl rollout undo deployment/myapp

# Rollback to specific revision
kubectl rollout undo deployment/myapp --to-revision=2

# Check rollback status
kubectl rollout status deployment/myapp
```

**Health Check-Based Rollback:**

```yaml
# Use readiness probe to automatically prevent bad rollouts
readinessProbe:
  httpGet:
    path: /actuator/health/readiness
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 5
  failureThreshold: 3

# If new pods fail readiness:
# - Not added to service
# - Rollout stalls
# - Old pods continue serving traffic
# - Manual intervention required
```

---

## Summary

### Spring Boot Best Practices

- ✅ Use Actuator for health checks
- ✅ Implement graceful shutdown
- ✅ Configure JVM heap properly (75% of container memory)
- ✅ Use ConfigMaps for config, Secrets for passwords
- ✅ Set appropriate resource requests/limits

### Common Patterns

- **Sidecar**: Enhance functionality (logging, monitoring)
- **Ambassador**: Proxy connections (connection pooling)
- **Adapter**: Normalize output (log format conversion)
- **Init Container**: Wait for dependencies

### Deployment Strategies

- **Blue-Green**: Instant switch, instant rollback (expensive)
- **Canary**: Gradual rollout, low risk (complex)
- **Rolling Update**: Default, zero downtime (slower)

### Key Takeaways

- Spring Boot integrates excellently with Kubernetes
- Health checks are critical for zero-downtime deployments
- Choose deployment strategy based on risk tolerance and resources
- Always implement rollback capability
- Monitor metrics during deployments
