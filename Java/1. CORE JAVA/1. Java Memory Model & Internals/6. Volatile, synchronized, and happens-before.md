# Java Volatile, Synchronized, and Happens-Before

## Overview

Understanding Java's memory visibility, synchronization, and ordering guarantees is essential for writing correct concurrent programs. This guide covers the foundations of thread safety in Java.

---

## 1. Memory Visibility Problems

### The Fundamental Problem

```java
/**
 * MEMORY VISIBILITY:
 * 
 * Problem: Each thread has its own CPU cache
 * Without synchronization, changes in one thread may not be visible to others
 * 
 * MEMORY HIERARCHY:
 * 
 * Thread 1:               Thread 2:
 * ┌──────────────┐        ┌──────────────┐
 * │  CPU Core 1  │        │  CPU Core 2  │
 * │  ┌────────┐  │        │  ┌────────┐  │
 * │  │ Cache  │  │        │  │ Cache  │  │
 * │  │ x = 10 │  │        │  │ x = 0  │  │
 * │  └────────┘  │        │  └────────┘  │
 * └──────────────┘        └──────────────┘
 *         ↓                       ↓
 *     ┌────────────────────────────────┐
 *     │      Main Memory (RAM)         │
 *     │          x = 10                │
 *     └────────────────────────────────┘
 * 
 * Thread 1 writes x = 10
 * Value cached in CPU Core 1's cache
 * Thread 2 reads x from its cache
 * Thread 2 sees stale value (x = 0)!
 */

public class VisibilityProblemDemo {
    
    /**
     * BROKEN: Classic visibility problem
     */
    private static boolean ready = false;
    private static int number = 0;
    
    static class ReaderThread extends Thread {
        public void run() {
            while (!ready) {
                Thread.yield();  // Hint to scheduler
            }
            System.out.println("Number: " + number);
        }
    }
    
    public static void main(String[] args) throws InterruptedException {
        new ReaderThread().start();
        
        Thread.sleep(100);
        
        number = 42;
        ready = true;
        
        /**
         * POSSIBLE OUTCOMES:
         * 
         * 1. Prints "Number: 42" (correct, if lucky)
         * 2. Never prints (reader never sees ready=true)
         * 3. Prints "Number: 0" (sees ready=true but not number=42)
         * 
         * WHY?
         * 
         * Main thread:
         * 1. Writes number=42 to its cache
         * 2. Writes ready=true to its cache
         * 3. Eventually flushes to main memory (but when?)
         * 
         * Reader thread:
         * 1. Reads ready from its cache (sees false)
         * 2. Loop never exits
         * 
         * OR:
         * 
         * 1. Sees ready=true (after cache coherence)
         * 2. But number still cached as 0
         * 3. Prints wrong value!
         */
    }
    
    /**
     * REORDERING PROBLEM:
     * 
     * Compiler and CPU can reorder instructions!
     */
    public void exampleReordering() {
        int a = 1;
        int b = 2;
        
        /**
         * Compiler might reorder to:
         * int b = 2;
         * int a = 1;
         * 
         * Single-threaded: No difference
         * Multi-threaded: Can cause bugs!
         */
    }
}
```

### Caching and Reordering

```java
/**
 * TYPES OF REORDERING:
 * 
 * 1. Compiler reordering (javac, JIT)
 * 2. CPU reordering (instruction pipeline)
 * 3. Memory reordering (store buffer, cache)
 */

public class ReorderingProblems {
    
    private int x = 0;
    private int y = 0;
    
    /**
     * EXAMPLE 1: Data race
     */
    public void thread1() {
        x = 1;  // Write 1
        y = 2;  // Write 2
    }
    
    public void thread2() {
        int a = y;  // Read y
        int b = x;  // Read x
        
        /**
         * POSSIBLE VALUES:
         * 
         * Expected:
         * - a=0, b=0 (before any writes)
         * - a=0, b=1 (x written, y not yet)
         * - a=2, b=1 (both written)
         * 
         * Surprising:
         * - a=2, b=0 (REORDERED!)
         * 
         * How?
         * Thread 1 reordered: y=2, then x=1
         * Thread 2 sees y=2 but x still 0
         */
    }
    
    /**
     * EXAMPLE 2: Classic broken singleton
     */
    private static Resource resource;
    
    public static Resource getInstance() {
        if (resource == null) {
            resource = new Resource();  // NOT ATOMIC!
        }
        return resource;
    }
    
    /**
     * PROBLEM:
     * 
     * "new Resource()" is 3 steps:
     * 1. Allocate memory
     * 2. Initialize object
     * 3. Assign reference
     * 
     * Can be reordered to:
     * 1. Allocate memory
     * 2. Assign reference (resource != null)
     * 3. Initialize object
     * 
     * Thread A: Executes steps 1, 2
     * Thread B: Sees resource != null
     * Thread B: Returns partially-constructed object!
     * Thread B: Crashes when using object
     * 
     * This is why double-checked locking needs volatile!
     */
    
    static class Resource {
        private int value;
        Resource() {
            // Expensive initialization
            value = 42;
        }
    }
}
```

---

## 2. Volatile Semantics

### What is Volatile?

```java
/**
 * VOLATILE:
 * 
 * Guarantees:
 * 1. Visibility: All threads see latest value
 * 2. Ordering: No reordering around volatile operations
 * 3. Atomicity: Read/write are atomic (NOT compound operations!)
 * 
 * How it works:
 * - Read: Forces read from main memory
 * - Write: Forces write to main memory
 * - Memory barriers prevent reordering
 */

public class VolatileDemo {
    
    /**
     * FIXED: Visibility problem with volatile
     */
    private static volatile boolean ready = false;
    private static volatile int number = 0;
    
    static class ReaderThread extends Thread {
        public void run() {
            while (!ready) {
                Thread.yield();
            }
            System.out.println("Number: " + number);
        }
    }
    
    public static void main(String[] args) throws InterruptedException {
        new ReaderThread().start();
        
        Thread.sleep(100);
        
        number = 42;
        ready = true;  // volatile write guarantees number visible
        
        /**
         * GUARANTEED OUTCOMES:
         * 
         * 1. Prints "Number: 42" (correct)
         * 
         * WHY?
         * 
         * Main thread:
         * 1. Writes number=42 to cache
         * 2. Writes ready=true (volatile write)
         * 3. Flushes all pending writes to main memory
         * 
         * Reader thread:
         * 1. Reads ready (volatile read)
         * 2. Invalidates cache, reads from main memory
         * 3. Sees ready=true AND number=42
         * 
         * MEMORY BARRIER:
         * 
         * Volatile write:
         * - StoreStore barrier BEFORE write
         * - StoreLoad barrier AFTER write
         * 
         * Volatile read:
         * - LoadLoad barrier AFTER read
         * - LoadStore barrier AFTER read
         */
    }
    
    /**
     * VOLATILE USE CASES:
     */
    
    // 1. Status flag
    private volatile boolean shutdown = false;
    
    public void run() {
        while (!shutdown) {
            // Work
        }
    }
    
    public void stop() {
        shutdown = true;
    }
    
    // 2. Independent observations
    private volatile long lastAccess;
    
    public void accessed() {
        lastAccess = System.currentTimeMillis();
    }
    
    public long getLastAccess() {
        return lastAccess;
    }
    
    // 3. Double-checked locking (with volatile)
    private volatile Resource instance;
    
    public Resource getInstance() {
        if (instance == null) {
            synchronized (this) {
                if (instance == null) {
                    instance = new Resource();
                }
            }
        }
        return instance;
    }
}
```

### Memory Barriers

```java
/**
 * MEMORY BARRIERS:
 * 
 * Instructions that prevent reordering
 * 
 * Types:
 * 1. LoadLoad: Load1; LoadLoad; Load2
 *    - Load2 sees results of Load1
 * 
 * 2. StoreStore: Store1; StoreStore; Store2
 *    - Store1 visible before Store2
 * 
 * 3. LoadStore: Load1; LoadStore; Store2
 *    - Load1 completes before Store2
 * 
 * 4. StoreLoad: Store1; StoreLoad; Load2
 *    - Store1 visible before Load2 (most expensive!)
 */

public class MemoryBarrierDemo {
    
    private int x = 0;
    private volatile int y = 0;
    
    /**
     * VOLATILE WRITE BARRIERS:
     */
    public void writer() {
        x = 1;           // Normal write
        // StoreStore barrier
        y = 2;           // Volatile write
        // StoreLoad barrier
        
        /**
         * GUARANTEES:
         * 
         * 1. x=1 visible before y=2 (StoreStore)
         * 2. y=2 flushed to main memory (StoreLoad)
         * 3. No reordering of x=1 after y=2
         */
    }
    
    /**
     * VOLATILE READ BARRIERS:
     */
    public void reader() {
        int a = y;       // Volatile read
        // LoadLoad barrier
        // LoadStore barrier
        int b = x;       // Normal read
        
        /**
         * GUARANTEES:
         * 
         * 1. y read from main memory (volatile)
         * 2. x read after y (LoadLoad)
         * 3. If y=2, then x=1 (happens-before)
         */
    }
    
    /**
     * PIGGYBACKING ON VOLATILE:
     * 
     * Non-volatile writes before volatile write are visible
     * Non-volatile reads after volatile read see updates
     */
    
    private int data1 = 0;
    private int data2 = 0;
    private int data3 = 0;
    private volatile boolean ready = false;
    
    public void produce() {
        data1 = 1;       // Non-volatile
        data2 = 2;       // Non-volatile
        data3 = 3;       // Non-volatile
        ready = true;    // Volatile write flushes all
    }
    
    public void consume() {
        if (ready) {     // Volatile read
            // Guaranteed to see data1=1, data2=2, data3=3
            System.out.println(data1 + data2 + data3);
        }
    }
}
```

### Volatile Limitations

```java
/**
 * VOLATILE LIMITATIONS:
 * 
 * Volatile provides atomicity for reads and writes
 * But NOT for compound operations!
 */

public class VolatileLimitations {
    
    private volatile int counter = 0;
    
    /**
     * BROKEN: Increment is not atomic
     */
    public void increment() {
        counter++;  // Read-modify-write (NOT ATOMIC!)
        
        /**
         * BYTECODE:
         * 
         * 0: aload_0
         * 1: dup
         * 2: getfield counter    // Read
         * 5: iconst_1
         * 6: iadd                // Modify
         * 7: putfield counter    // Write
         * 
         * RACE CONDITION:
         * 
         * Thread A: Read counter=0
         * Thread B: Read counter=0
         * Thread A: Increment to 1
         * Thread B: Increment to 1
         * Thread A: Write counter=1
         * Thread B: Write counter=1
         * Result: counter=1 (should be 2!)
         */
    }
    
    /**
     * FIXED: Use AtomicInteger
     */
    private final java.util.concurrent.atomic.AtomicInteger atomicCounter = 
        new java.util.concurrent.atomic.AtomicInteger(0);
    
    public void incrementAtomic() {
        atomicCounter.incrementAndGet();  // Atomic using CAS
    }
    
    /**
     * OR FIXED: Use synchronized
     */
    private int syncCounter = 0;
    
    public synchronized void incrementSync() {
        syncCounter++;  // Protected by monitor lock
    }
    
    /**
     * VOLATILE GOOD FOR:
     * 
     * 1. Single writer, multiple readers
     * 2. Independent operations (no compound operations)
     * 3. Status flags
     * 4. Double-checked locking
     * 
     * VOLATILE BAD FOR:
     * 
     * 1. Compound operations (++, +=, etc.)
     * 2. Operations depending on current value
     * 3. Multiple interdependent variables
     */
    
    /**
     * PERFORMANCE:
     * 
     * Volatile is much faster than synchronized:
     * - No lock acquisition
     * - No context switch
     * - Just memory barrier
     * 
     * But slower than normal field access:
     * - Prevents compiler optimizations
     * - Memory barrier overhead
     * - Can't be cached in register
     */
}
```

---

## 3. Synchronized Implementation

### Monitor Locks

```java
/**
 * SYNCHRONIZED:
 * 
 * Every Java object has a monitor lock
 * 
 * Guarantees:
 * 1. Mutual exclusion: Only one thread at a time
 * 2. Memory visibility: Like volatile
 * 3. Happens-before: Unlock happens-before subsequent lock
 */

public class SynchronizedDemo {
    
    private int counter = 0;
    
    /**
     * SYNCHRONIZED METHOD:
     */
    public synchronized void increment() {
        counter++;
    }
    
    /**
     * EQUIVALENT TO:
     */
    public void incrementExplicit() {
        synchronized (this) {
            counter++;
        }
    }
    
    /**
     * BYTECODE:
     * 
     * public synchronized void increment();
     *   Code:
     *      0: aload_0
     *      1: dup
     *      2: getfield counter
     *      5: iconst_1
     *      6: iadd
     *      7: putfield counter
     *     10: return
     *   
     *   Flags: ACC_SYNCHRONIZED
     * 
     * public void incrementExplicit();
     *   Code:
     *      0: aload_0
     *      1: dup
     *      2: astore_1
     *      3: monitorenter      // Acquire lock
     *      4: aload_0
     *      5: dup
     *      6: getfield counter
     *      9: iconst_1
     *     10: iadd
     *     11: putfield counter
     *     14: aload_1
     *     15: monitorexit       // Release lock
     *     16: goto 24
     *     19: astore_2
     *     20: aload_1
     *     21: monitorexit       // Release on exception
     *     22: aload_2
     *     23: athrow
     *     24: return
     * 
     * Exception table:
     *    from    to  target type
     *       4    16    19   any
     * 
     * Note: Two monitorexit (normal and exception path)
     */
    
    /**
     * STATIC SYNCHRONIZED:
     */
    public static synchronized void staticMethod() {
        // Locks on Class object
    }
    
    /**
     * EQUIVALENT TO:
     */
    public static void staticMethodExplicit() {
        synchronized (SynchronizedDemo.class) {
            // ...
        }
    }
}
```

### Monitor States

```java
/**
 * MONITOR LOCK STATES:
 * 
 * Object Header (Mark Word):
 * ┌──────────────────────────────────────────────┐
 * │  Lock State  │  Mark Word Contents           │
 * ├──────────────┼───────────────────────────────┤
 * │  Unlocked    │  hash code, age, bias bit     │
 * │  Biased      │  thread ID, epoch, bias bit   │
 * │  Lightweight │  pointer to lock record       │
 * │  Heavyweight │  pointer to monitor           │
 * │  GC marked   │  marking information          │
 * └──────────────┴───────────────────────────────┘
 */

public class MonitorStatesDemo {
    
    private final Object lock = new Object();
    
    /**
     * MONITOR INFLATION:
     * 
     * Unlocked → Biased → Lightweight → Heavyweight
     * 
     * Each state has different overhead
     */
    
    /**
     * 1. BIASED LOCKING:
     * 
     * Optimization for single-thread access
     * First thread acquires bias
     * Subsequent locks are nearly free
     */
    public void biasedLockExample() {
        synchronized (lock) {
            // First lock: Record thread ID in object header
            // Subsequent locks: Just check thread ID
            // No CAS needed!
        }
        
        /**
         * PERFORMANCE:
         * Biased lock: ~10 nanoseconds
         * 
         * REVOCATION:
         * If another thread tries to lock:
         * - Bias revoked
         * - Inflates to lightweight lock
         */
    }
    
    /**
     * 2. LIGHTWEIGHT LOCKING:
     * 
     * For short-duration locks with low contention
     * Uses CAS to update object header
     */
    public void lightweightLockExample() {
        synchronized (lock) {
            /**
             * ACQUISITION:
             * 1. Create lock record in stack
             * 2. CAS to set object header to point to lock record
             * 3. If CAS succeeds: Lock acquired
             * 4. If CAS fails: Spin or inflate
             * 
             * RELEASE:
             * 1. CAS to restore original header
             * 2. If CAS succeeds: Lock released
             * 3. If CAS fails: Another thread waiting, inflate
             */
        }
        
        /**
         * PERFORMANCE:
         * Lightweight lock: ~100 nanoseconds
         * 
         * SPINNING:
         * Thread spins (busy-waits) briefly
         * If lock not acquired: Inflate to heavyweight
         */
    }
    
    /**
     * 3. HEAVYWEIGHT LOCKING:
     * 
     * For long-duration or contended locks
     * Uses OS-level mutex
     */
    public void heavyweightLockExample() {
        synchronized (lock) {
            /**
             * ACQUISITION:
             * 1. Enter OS monitor
             * 2. If locked: Block thread (OS scheduler)
             * 3. Thread suspended until lock available
             * 
             * RELEASE:
             * 1. Exit OS monitor
             * 2. Notify waiting threads
             */
        }
        
        /**
         * PERFORMANCE:
         * Heavyweight lock: ~1000+ nanoseconds
         * 
         * COST:
         * - Context switch (~1-10 microseconds)
         * - Kernel transition
         * - Thread scheduling
         * 
         * But better for:
         * - Long critical sections
         * - High contention
         * - Waiting (not busy-waiting)
         */
    }
    
    /**
     * JVM FLAGS:
     * 
     * -XX:+UseBiasedLocking (default: true in Java 8-14)
     * -XX:-UseBiasedLocking (disable biased locking)
     * 
     * -XX:BiasedLockingStartupDelay=0 (enable immediately)
     * Default: 4000ms (4 seconds after JVM start)
     * 
     * Note: Biased locking deprecated in Java 15, removed in Java 18
     * Reason: JVM improvements made it less beneficial
     */
}
```

### Synchronized Scope

```java
/**
 * SYNCHRONIZED SCOPE:
 * 
 * Choose the right granularity
 */

public class SynchronizedScopeDemo {
    
    private int counter = 0;
    private final List<Integer> items = new ArrayList<>();
    
    /**
     * COARSE-GRAINED:
     */
    public synchronized void addCoarse(int item) {
        // Entire method synchronized
        items.add(item);
        counter++;
        // Heavy computations also synchronized (bad!)
        processItem(item);
    }
    
    /**
     * FINE-GRAINED:
     */
    public void addFine(int item) {
        // Only synchronize when needed
        synchronized (this) {
            items.add(item);
            counter++;
        }
        // Heavy computation outside lock
        processItem(item);
    }
    
    /**
     * SEPARATE LOCKS:
     */
    private final Object itemsLock = new Object();
    private final Object counterLock = new Object();
    
    public void addSeparate(int item) {
        synchronized (itemsLock) {
            items.add(item);
        }
        synchronized (counterLock) {
            counter++;
        }
        processItem(item);
    }
    
    private void processItem(int item) {
        // Expensive operation
    }
    
    /**
     * LOCK ORDERING:
     * 
     * Always acquire locks in same order to avoid deadlock
     */
    private final Object lock1 = new Object();
    private final Object lock2 = new Object();
    
    // Good: Consistent order
    public void method1() {
        synchronized (lock1) {
            synchronized (lock2) {
                // ...
            }
        }
    }
    
    public void method2() {
        synchronized (lock1) {  // Same order!
            synchronized (lock2) {
                // ...
            }
        }
    }
    
    // Bad: Inconsistent order (deadlock risk)
    public void method3() {
        synchronized (lock1) {
            synchronized (lock2) {
                // ...
            }
        }
    }
    
    public void method4() {
        synchronized (lock2) {  // Different order!
            synchronized (lock1) {
                // ...
            }
        }
    }
}
```

---

## 4. Happens-Before Relationship

### Happens-Before Rules

```java
/**
 * HAPPENS-BEFORE:
 * 
 * Defines visibility guarantees between operations
 * 
 * If A happens-before B:
 * - Memory writes by A are visible to B
 * - A is ordered before B (no reordering)
 * 
 * RULES:
 * 
 * 1. Program Order: Within a thread, A before B in code
 * 2. Monitor Lock: Unlock happens-before subsequent lock
 * 3. Volatile: Write happens-before subsequent read
 * 4. Thread Start: Thread.start() happens-before thread actions
 * 5. Thread Termination: Thread actions happen-before Thread.join()
 * 6. Interruption: Thread.interrupt() happens-before detecting interrupt
 * 7. Finalization: Constructor happens-before finalizer
 * 8. Transitivity: A hb B, B hb C ⇒ A hb C
 */

public class HappensBeforeDemo {
    
    /**
     * RULE 1: PROGRAM ORDER
     */
    public void programOrder() {
        int x = 1;  // A
        int y = 2;  // B
        
        // A happens-before B (within same thread)
        // But can be reordered if no other thread observes!
    }
    
    /**
     * RULE 2: MONITOR LOCK
     */
    private int sharedValue = 0;
    private final Object lock = new Object();
    
    public void writer() {
        synchronized (lock) {
            sharedValue = 42;  // A
        }  // Unlock
    }
    
    public void reader() {
        synchronized (lock) {  // Lock
            int value = sharedValue;  // B
            System.out.println(value);
        }
    }
    
    /**
     * GUARANTEE:
     * 
     * Unlock in writer() happens-before lock in reader()
     * Therefore: A (write 42) happens-before B (read)
     * Reader guaranteed to see 42
     */
    
    /**
     * RULE 3: VOLATILE
     */
    private volatile boolean flag = false;
    private int data = 0;
    
    public void producer() {
        data = 42;       // A
        flag = true;     // B (volatile write)
    }
    
    public void consumer() {
        if (flag) {      // C (volatile read)
            int value = data;  // D
            System.out.println(value);
        }
    }
    
    /**
     * GUARANTEE:
     * 
     * B (volatile write) happens-before C (volatile read)
     * A happens-before B (program order)
     * C happens-before D (program order)
     * Therefore: A happens-before D (transitivity)
     * Consumer guaranteed to see data=42
     */
    
    /**
     * RULE 4: THREAD START
     */
    private int x = 0;
    
    public void startThread() {
        x = 42;  // A
        
        Thread t = new Thread(() -> {
            System.out.println(x);  // B
        });
        
        t.start();  // Start happens-before B
        
        /**
         * GUARANTEE:
         * 
         * A happens-before t.start()
         * t.start() happens-before actions in thread t
         * Therefore: A happens-before B
         * Thread t guaranteed to see x=42
         */
    }
    
    /**
     * RULE 5: THREAD TERMINATION
     */
    public void joinThread() throws InterruptedException {
        final int[] result = new int[1];
        
        Thread t = new Thread(() -> {
            result[0] = 42;  // A
        });
        
        t.start();
        t.join();  // Wait for termination
        
        System.out.println(result[0]);  // B
        
        /**
         * GUARANTEE:
         * 
         * A happens-before thread t termination
         * t.join() returns after termination
         * Therefore: A happens-before B
         * Main thread guaranteed to see result[0]=42
         */
    }
}
```

### Happens-Before Chain

```java
/**
 * BUILDING HAPPENS-BEFORE CHAINS:
 * 
 * Use transitivity to establish visibility
 */

public class HappensBeforeChainDemo {
    
    private int data1 = 0;
    private int data2 = 0;
    private int data3 = 0;
    private volatile boolean ready = false;
    
    /**
     * PRODUCER-CONSUMER WITH VOLATILE:
     */
    public void produce() {
        data1 = 1;       // A
        data2 = 2;       // B
        data3 = 3;       // C
        ready = true;    // D (volatile write)
        
        /**
         * CHAIN:
         * A hb B hb C hb D (program order)
         */
    }
    
    public void consume() {
        if (ready) {     // E (volatile read)
            // D hb E (volatile rule)
            // A hb B hb C hb D hb E (transitivity)
            
            int sum = data1 + data2 + data3;  // F
            // E hb F (program order)
            // A hb B hb C hb D hb E hb F
            
            System.out.println(sum);  // Guaranteed to be 6
        }
    }
    
    /**
     * SAFE PUBLICATION:
     */
    private Map<String, Integer> map = new HashMap<>();
    private volatile boolean mapInitialized = false;
    
    public void initialize() {
        map.put("key1", 1);    // A
        map.put("key2", 2);    // B
        map.put("key3", 3);    // C
        mapInitialized = true; // D (volatile write)
    }
    
    public Integer getValue(String key) {
        if (mapInitialized) {  // E (volatile read)
            return map.get(key);  // F
            // A, B, C visible at F
        }
        return null;
    }
    
    /**
     * WITHOUT VOLATILE:
     * 
     * map might appear partially initialized
     * Thread might see mapInitialized=true
     * But map.get() returns null (race condition)
     */
}
```

---

## 5. Lock Coarsening and Lock Elision

### Lock Coarsening

```java
/**
 * LOCK COARSENING:
 * 
 * JIT compiler optimization
 * Combines adjacent synchronized blocks into one larger block
 */

public class LockCoarseningDemo {
    
    private final StringBuilder sb = new StringBuilder();
    
    /**
     * ORIGINAL CODE:
     */
    public void appendMultiple() {
        sb.append("Hello");    // synchronized
        sb.append(" ");        // synchronized
        sb.append("World");    // synchronized
        
        /**
         * PROBLEM:
         * 
         * StringBuilder.append() is synchronized
         * Lock acquired and released 3 times!
         * 
         * BYTECODE (conceptually):
         * monitorenter sb
         * sb.append("Hello")
         * monitorexit sb
         * 
         * monitorenter sb
         * sb.append(" ")
         * monitorexit sb
         * 
         * monitorenter sb
         * sb.append("World")
         * monitorexit sb
         */
    }
    
    /**
     * JIT OPTIMIZATION (Lock Coarsening):
     * 
     * monitorenter sb
     * sb.append("Hello")
     * sb.append(" ")
     * sb.append("World")
     * monitorexit sb
     * 
     * Result: Single lock acquisition!
     * Much faster!
     */
    
    /**
     * ANOTHER EXAMPLE:
     */
    private final Vector<Integer> vector = new Vector<>();
    
    public void addMultiple() {
        vector.add(1);    // synchronized
        vector.add(2);    // synchronized
        vector.add(3);    // synchronized
        
        /**
         * JIT coarsens to:
         * synchronized (vector) {
         *     vector.add(1);
         *     vector.add(2);
         *     vector.add(3);
         * }
         */
    }
    
    /**
     * WHEN COARSENING APPLIES:
     * 
     * 1. Adjacent synchronized blocks
     * 2. Same lock object
     * 3. No intervening operations
     * 4. JIT determines it's beneficial
     * 
     * MANUAL COARSENING:
     */
    public void manualCoarsening() {
        // Instead of multiple synchronized calls:
        // sb.append("a").append("b").append("c");
        
        // Manually coarsen:
        synchronized (sb) {
            sb.append("a");
            sb.append("b");
            sb.append("c");
        }
    }
}
```

### Lock Elision

```java
/**
 * LOCK ELISION:
 * 
 * JIT compiler optimization
 * Eliminates locks that cannot be contended
 */

public class LockElisionDemo {
    
    /**
     * ESCAPE ANALYSIS + LOCK ELISION:
     */
    public String buildString() {
        StringBuilder sb = new StringBuilder();  // Local object
        
        sb.append("Hello");    // synchronized (in StringBuilder)
        sb.append(" ");        // synchronized
        sb.append("World");    // synchronized
        
        return sb.toString();
        
        /**
         * ANALYSIS:
         * 
         * sb doesn't escape method
         * No other thread can access sb
         * Synchronization unnecessary!
         * 
         * JIT OPTIMIZATION:
         * 
         * Removes all synchronization
         * Treats as if unsynchronized
         * 
         * Result: As fast as StringBuffer would be!
         */
    }
    
    /**
     * ANOTHER EXAMPLE:
     */
    public int sumVector() {
        Vector<Integer> v = new Vector<>();
        v.add(1);
        v.add(2);
        v.add(3);
        
        int sum = 0;
        for (int i : v) {
            sum += i;
        }
        
        return sum;
        
        /**
         * ANALYSIS:
         * 
         * Vector v is local
         * Never escapes method
         * All locks elided!
         * 
         * Performs like ArrayList!
         */
    }
    
    /**
     * WHEN ELISION APPLIES:
     * 
     * 1. Object doesn't escape
     * 2. Escape analysis proves no sharing
     * 3. JIT is confident
     * 
     * MONITORING:
     * 
     * -XX:+EliminateLocks (default: true)
     * -XX:-EliminateLocks (disable)
     * 
     * -XX:+PrintEliminateAllocations
     * Shows lock eliminations
     */
    
    /**
     * PERFORMANCE IMPACT:
     */
    public void performanceComparison() {
        // Test 1: StringBuilder (synchronized, but locks elided)
        long start = System.nanoTime();
        for (int i = 0; i < 1000000; i++) {
            StringBuilder sb = new StringBuilder();
            sb.append("test");
        }
        long elapsed1 = System.nanoTime() - start;
        System.out.println("StringBuilder: " + elapsed1 / 1_000_000 + "ms");
        
        // Test 2: StringBuffer (synchronized, no elision possible)
        StringBuffer[] buffers = new StringBuffer[1000000];
        for (int i = 0; i < buffers.length; i++) {
            buffers[i] = new StringBuffer();
        }
        
        start = System.nanoTime();
        for (StringBuffer sb : buffers) {
            sb.append("test");  // Escapes, can't elide
        }
        long elapsed2 = System.nanoTime() - start;
        System.out.println("StringBuffer (escaped): " + elapsed2 / 1_000_000 + "ms");
        
        /**
         * TYPICAL RESULTS:
         * 
         * StringBuilder: 10ms (locks elided)
         * StringBuffer: 100ms (locks present)
         * 
         * 10x difference!
         */
    }
}
```

---

## 6. Double-Checked Locking

### The Problem

```java
/**
 * DOUBLE-CHECKED LOCKING:
 * 
 * Attempt to optimize lazy initialization
 * 
 * BROKEN WITHOUT VOLATILE!
 */

public class DoubleCheckedLockingBroken {
    
    /**
     * BROKEN IMPLEMENTATION:
     */
    private static Resource instance;  // No volatile!
    
    public static Resource getInstance() {
        if (instance == null) {              // Check 1 (no lock)
            synchronized (DoubleCheckedLockingBroken.class) {
                if (instance == null) {      // Check 2 (with lock)
                    instance = new Resource();
                }
            }
        }
        return instance;
    }
    
    /**
     * WHY BROKEN?
     * 
     * "instance = new Resource()" is not atomic:
     * 
     * 1. Allocate memory for Resource
     * 2. Initialize Resource object
     * 3. Assign reference to instance
     * 
     * Compiler/CPU can reorder to:
     * 
     * 1. Allocate memory for Resource
     * 2. Assign reference to instance  ← instance != null now!
     * 3. Initialize Resource object    ← But not initialized yet!
     * 
     * RACE CONDITION:
     * 
     * Thread A:
     * - Enters synchronized block
     * - Allocates memory
     * - Assigns reference (instance != null)
     * - <Not initialized yet>
     * 
     * Thread B:
     * - Checks instance == null (false!)
     * - Returns instance
     * - Uses partially-initialized object
     * - CRASH or incorrect behavior!
     */
    
    static class Resource {
        private int value;
        
        public Resource() {
            // This might not complete before instance is visible!
            value = 42;
        }
        
        public int getValue() {
            return value;  // Might return 0 instead of 42!
        }
    }
}
```

### The Fix

```java
/**
 * FIXED WITH VOLATILE:
 */

public class DoubleCheckedLockingFixed {
    
    /**
     * CORRECT IMPLEMENTATION:
     */
    private static volatile Resource instance;  // volatile!
    
    public static Resource getInstance() {
        if (instance == null) {              // Check 1 (no lock)
            synchronized (DoubleCheckedLockingFixed.class) {
                if (instance == null) {      // Check 2 (with lock)
                    instance = new Resource();
                }
            }
        }
        return instance;
    }
    
    /**
     * WHY VOLATILE FIXES IT?
     * 
     * Volatile write has StoreStore barrier:
     * 
     * 1. Allocate memory
     * 2. Initialize object
     * 3. StoreStore barrier  ← Ensures 2 completes before 4
     * 4. Assign to volatile instance
     * 5. StoreLoad barrier
     * 
     * Volatile read has LoadLoad barrier:
     * 
     * Thread B:
     * 1. Read volatile instance
     * 2. LoadLoad barrier    ← Ensures 1 completes before 3
     * 3. Use object
     * 
     * GUARANTEE:
     * 
     * If Thread B sees instance != null,
     * it's guaranteed to be fully initialized!
     */
    
    static class Resource {
        private int value;
        
        public Resource() {
            value = 42;
        }
        
        public int getValue() {
            return value;  // Always returns 42
        }
    }
    
    /**
     * PERFORMANCE:
     * 
     * First call: ~1000ns (synchronized)
     * Subsequent calls: ~10ns (volatile read only)
     * 
     * Much better than always synchronized!
     */
}
```

### Alternatives to Double-Checked Locking

```java
/**
 * BETTER ALTERNATIVES:
 */

public class InitializationAlternatives {
    
    /**
     * 1. HOLDER CLASS IDIOM (Best!)
     * 
     * Uses class initialization guarantee
     * No synchronization needed!
     */
    private static class ResourceHolder {
        static final Resource INSTANCE = new Resource();
    }
    
    public static Resource getInstance1() {
        return ResourceHolder.INSTANCE;
    }
    
    /**
     * WHY IT WORKS:
     * 
     * - Class initialization is thread-safe (JVM guarantee)
     * - ResourceHolder not loaded until first access
     * - Lazy initialization without synchronization!
     * - No volatile, no synchronized, no double-check
     * 
     * PERFORMANCE:
     * ~5ns per call (just field access)
     */
    
    /**
     * 2. ENUM SINGLETON (Joshua Bloch's recommendation)
     */
    public enum ResourceSingleton {
        INSTANCE;
        
        private final Resource resource = new Resource();
        
        public Resource getResource() {
            return resource;
        }
    }
    
    /**
     * USAGE:
     * Resource r = ResourceSingleton.INSTANCE.getResource();
     * 
     * BENEFITS:
     * - Thread-safe
     * - Serialization-safe
     * - Reflection-safe
     * - Simplest code
     */
    
    /**
     * 3. ALWAYS SYNCHRONIZED (Simplest)
     */
    private static Resource instance3;
    
    public static synchronized Resource getInstance3() {
        if (instance3 == null) {
            instance3 = new Resource();
        }
        return instance3;
    }
    
    /**
     * DRAWBACK:
     * Synchronized on every call (~100ns)
     * 
     * But often good enough!
     * "Premature optimization is the root of all evil"
     */
    
    /**
     * 4. EAGER INITIALIZATION
     */
    private static final Resource INSTANCE4 = new Resource();
    
    public static Resource getInstance4() {
        return INSTANCE4;
    }
    
    /**
     * BENEFITS:
     * - Simple
     * - Thread-safe
     * - Fast
     * 
     * DRAWBACK:
     * - Not lazy (created at class load)
     * - OK if cheap to create
     */
    
    static class Resource {
        Resource() {
            // Initialization
        }
    }
}
```

---

## 7. Performance Implications

### Synchronization Overhead

```java
/**
 * PERFORMANCE COSTS:
 * 
 * 1. Uncontended synchronized: ~25-50ns
 * 2. Volatile read: ~5-10ns
 * 3. Volatile write: ~10-20ns
 * 4. Contended synchronized: ~1000+ ns (context switch)
 * 5. Normal field access: ~1ns
 */

public class PerformanceDemo {
    
    private int unsyncCounter = 0;
    private volatile int volatileCounter = 0;
    private int syncCounter = 0;
    private final java.util.concurrent.atomic.AtomicInteger atomicCounter = 
        new java.util.concurrent.atomic.AtomicInteger(0);
    
    /**
     * BENCHMARK: Single-threaded
     */
    public void benchmarkSingleThread() {
        final int ITERATIONS = 10_000_000;
        
        // 1. Normal field
        long start = System.nanoTime();
        for (int i = 0; i < ITERATIONS; i++) {
            unsyncCounter++;
        }
        long elapsed1 = System.nanoTime() - start;
        System.out.println("Unsync: " + elapsed1 / 1_000_000 + "ms");
        
        // 2. Volatile field
        start = System.nanoTime();
        for (int i = 0; i < ITERATIONS; i++) {
            volatileCounter++;
        }
        long elapsed2 = System.nanoTime() - start;
        System.out.println("Volatile: " + elapsed2 / 1_000_000 + "ms");
        
        // 3. Synchronized
        start = System.nanoTime();
        for (int i = 0; i < ITERATIONS; i++) {
            incrementSync();
        }
        long elapsed3 = System.nanoTime() - start;
        System.out.println("Synchronized: " + elapsed3 / 1_000_000 + "ms");
        
        // 4. AtomicInteger
        start = System.nanoTime();
        for (int i = 0; i < ITERATIONS; i++) {
            atomicCounter.incrementAndGet();
        }
        long elapsed4 = System.nanoTime() - start;
        System.out.println("Atomic: " + elapsed4 / 1_000_000 + "ms");
        
        /**
         * TYPICAL RESULTS (single-threaded):
         * 
         * Unsync: 10ms (baseline)
         * Volatile: 150ms (15x slower)
         * Synchronized: 250ms (25x slower, biased locking)
         * Atomic: 200ms (20x slower, CAS operations)
         * 
         * NOTE: With JIT optimizations, synchronized might be elided!
         */
    }
    
    public synchronized void incrementSync() {
        syncCounter++;
    }
    
    /**
     * BENCHMARK: Multi-threaded
     */
    public void benchmarkMultiThread() throws InterruptedException {
        final int THREADS = 4;
        final int ITERATIONS = 1_000_000;
        
        // Reset counters
        syncCounter = 0;
        atomicCounter.set(0);
        
        // Test synchronized
        Thread[] threads1 = new Thread[THREADS];
        long start = System.nanoTime();
        
        for (int i = 0; i < THREADS; i++) {
            threads1[i] = new Thread(() -> {
                for (int j = 0; j < ITERATIONS; j++) {
                    incrementSync();
                }
            });
            threads1[i].start();
        }
        
        for (Thread t : threads1) {
            t.join();
        }
        long elapsed1 = System.nanoTime() - start;
        System.out.println("Synchronized (" + THREADS + " threads): " + 
            elapsed1 / 1_000_000 + "ms");
        
        // Test atomic
        Thread[] threads2 = new Thread[THREADS];
        start = System.nanoTime();
        
        for (int i = 0; i < THREADS; i++) {
            threads2[i] = new Thread(() -> {
                for (int j = 0; j < ITERATIONS; j++) {
                    atomicCounter.incrementAndGet();
                }
            });
            threads2[i].start();
        }
        
        for (Thread t : threads2) {
            t.join();
        }
        long elapsed2 = System.nanoTime() - start;
        System.out.println("Atomic (" + THREADS + " threads): " + 
            elapsed2 / 1_000_000 + "ms");
        
        /**
         * TYPICAL RESULTS (multi-threaded):
         * 
         * Synchronized (4 threads): 1500ms
         * Atomic (4 threads): 800ms
         * 
         * Atomic faster under contention!
         * - No blocking
         * - Lock-free algorithm
         * - Better CPU utilization
         */
    }
}
```

### Optimization Strategies

```java
/**
 * PERFORMANCE OPTIMIZATION:
 */

public class OptimizationStrategies {
    
    /**
     * 1. REDUCE LOCK SCOPE
     */
    private final List<String> items = new ArrayList<>();
    
    // Bad: Large critical section
    public synchronized void processBad(String item) {
        // Expensive computation in lock
        String processed = expensiveProcessing(item);
        items.add(processed);
    }
    
    // Good: Small critical section
    public void processGood(String item) {
        // Expensive computation outside lock
        String processed = expensiveProcessing(item);
        
        // Only synchronize the update
        synchronized (this) {
            items.add(processed);
        }
    }
    
    private String expensiveProcessing(String item) {
        // Simulate expensive work
        return item.toUpperCase();
    }
    
    /**
     * 2. USE CONCURRENT COLLECTIONS
     */
    
    // Bad: Synchronized HashMap
    private final Map<String, Integer> map1 = 
        Collections.synchronizedMap(new HashMap<>());
    
    public void useSyncMap() {
        synchronized (map1) {
            map1.put("key", 1);
            int value = map1.get("key");
        }
    }
    
    // Good: ConcurrentHashMap
    private final java.util.concurrent.ConcurrentHashMap<String, Integer> map2 = 
        new java.util.concurrent.ConcurrentHashMap<>();
    
    public void useConcurrentMap() {
        map2.put("key", 1);  // Lock-free for reads, fine-grained locking for writes
        int value = map2.get("key");
    }
    
    /**
     * PERFORMANCE:
     * 
     * Synchronized HashMap: One lock for entire map
     * - Read: Synchronized
     * - Write: Synchronized
     * - Throughput: Low under contention
     * 
     * ConcurrentHashMap: Lock striping (multiple locks)
     * - Read: Lock-free (volatile)
     * - Write: Fine-grained locks per segment
     * - Throughput: High under contention
     * 
     * ConcurrentHashMap is 10-50x faster under contention!
     */
    
    /**
     * 3. AVOID SYNCHRONIZATION IF POSSIBLE
     */
    
    // If truly thread-local, no sync needed
    public void threadLocalExample() {
        ThreadLocal<StringBuilder> threadLocal = 
            ThreadLocal.withInitial(() -> new StringBuilder());
        
        StringBuilder sb = threadLocal.get();
        sb.append("Hello");  // No synchronization needed!
    }
    
    /**
     * 4. READ-WRITE LOCKS
     */
    private final java.util.concurrent.locks.ReadWriteLock rwLock = 
        new java.util.concurrent.locks.ReentrantReadWriteLock();
    private int value = 0;
    
    public int read() {
        rwLock.readLock().lock();
        try {
            return value;  // Multiple readers allowed
        } finally {
            rwLock.readLock().unlock();
        }
    }
    
    public void write(int newValue) {
        rwLock.writeLock().lock();
        try {
            value = newValue;  // Exclusive writer
        } finally {
            rwLock.writeLock().unlock();
        }
    }
    
    /**
     * WHEN TO USE:
     * 
     * - Read-heavy workloads
     * - Reads >> Writes
     * - Example: Cache implementations
     */
    
    /**
     * 5. LOCK-FREE ALGORITHMS
     */
    private final java.util.concurrent.atomic.AtomicReference<Node> head = 
        new java.util.concurrent.atomic.AtomicReference<>();
    
    static class Node {
        final int value;
        final Node next;
        
        Node(int value, Node next) {
            this.value = value;
            this.next = next;
        }
    }
    
    public void addLockFree(int value) {
        Node newHead;
        Node oldHead;
        
        do {
            oldHead = head.get();
            newHead = new Node(value, oldHead);
        } while (!head.compareAndSet(oldHead, newHead));
        
        /**
         * BENEFITS:
         * 
         * - No blocking
         * - No deadlock possible
         * - Better scalability
         * 
         * DRAWBACKS:
         * 
         * - Complex to implement correctly
         * - ABA problem
         * - High contention can cause spinning
         */
    }
}
```

### Measuring Performance

```java
/**
 * PERFORMANCE MEASUREMENT:
 */

public class PerformanceMeasurement {
    
    /**
     * USING JMH (Java Microbenchmark Harness)
     * 
     * Best tool for accurate microbenchmarks
     */
    
    /*
    @Benchmark
    @BenchmarkMode(Mode.AverageTime)
    @OutputTimeUnit(TimeUnit.NANOSECONDS)
    @Warmup(iterations = 5, time = 1)
    @Measurement(iterations = 10, time = 1)
    @Fork(1)
    public void benchmarkVolatileRead(Blackhole bh) {
        bh.consume(volatileField);
    }
    
    @Benchmark
    public void benchmarkSynchronized(Blackhole bh) {
        synchronized (lock) {
            bh.consume(counter++);
        }
    }
    */
    
    /**
     * MANUAL BENCHMARKING (Less accurate)
     */
    public void manualBenchmark() {
        final int WARMUP = 10000;
        final int ITERATIONS = 1000000;
        
        // Warmup (let JIT compile)
        for (int i = 0; i < WARMUP; i++) {
            doWork();
        }
        
        // Measure
        long start = System.nanoTime();
        for (int i = 0; i < ITERATIONS; i++) {
            doWork();
        }
        long elapsed = System.nanoTime() - start;
        
        double avgNanos = (double) elapsed / ITERATIONS;
        System.out.println("Average: " + avgNanos + " ns/op");
    }
    
    private void doWork() {
        // Work to measure
    }
    
    /**
     * PROFILING TOOLS:
     * 
     * 1. VisualVM
     *    - Lock contention profiling
     *    - Thread states
     *    - Monitor contention
     * 
     * 2. Java Flight Recorder
     *    - Lock statistics
     *    - Context switches
     *    - CPU profiling
     * 
     * 3. Async-profiler
     *    - Low overhead
     *    - Lock profiling
     *    - Allocation profiling
     * 
     * JVM FLAGS:
     * 
     * -XX:+UnlockDiagnosticVMOptions
     * -XX:+LogCompilation
     * -XX:+PrintCompilation
     * -XX:+PrintInlining
     * -XX:+PrintEliminateAllocations
     * -XX:+PrintEliminateLocks
     */
}
```

---

## Summary

### Key Concepts

**Memory Visibility:**

- Each thread has CPU cache
- Without synchronization, changes may not be visible
- Requires volatile or synchronized

**Volatile:**

- Guarantees visibility and ordering
- Read/write are atomic
- NOT atomic for compound operations (++, +=)
- Memory barriers prevent reordering
- Faster than synchronized

**Synchronized:**

- Provides mutual exclusion
- Guarantees visibility (like volatile)
- Uses monitor locks
- Three states: Biased, Lightweight, Heavyweight
- JIT optimizations: Lock coarsening, lock elision

**Happens-Before:**

- Defines visibility and ordering guarantees
- Key rules: Program order, monitor lock, volatile, thread start/join
- Use transitivity to build chains

**Double-Checked Locking:**

- Broken without volatile
- Requires volatile for correctness
- Better alternatives: Holder class idiom, enum singleton

### Performance Characteristics

|Operation|Single-Threaded|Multi-Threaded|Notes|
|---|---|---|---|
|Normal field|1ns|N/A|Not thread-safe|
|Volatile read|5-10ns|5-10ns|Thread-safe reads|
|Volatile write|10-20ns|10-20ns|Thread-safe writes|
|Synchronized (uncontended)|25-50ns|25-50ns|Biased locking|
|Synchronized (contended)|N/A|1000+ns|Context switch|
|AtomicInteger|20ns|50-200ns|CAS operations|
|ConcurrentHashMap|Varies|Fast|Lock striping|

### Best Practices

**Synchronization:**

- ✅ Use synchronized for mutual exclusion
- ✅ Use volatile for visibility only (no compound ops)
- ✅ Keep critical sections small
- ✅ Use concurrent collections when possible
- ✅ Consider ReadWriteLock for read-heavy workloads
- ✅ Profile before optimizing

**Correctness:**

- ✅ Always use volatile with double-checked locking
- ✅ Establish happens-before relationships
- ✅ Acquire locks in consistent order (avoid deadlock)
- ✅ Prefer immutability when possible
- ✅ Use java.util.concurrent over manual synchronization

**Performance:**

- ✅ Measure with JMH
- ✅ Profile with VisualVM or Flight Recorder
- ✅ Trust JIT optimizations (lock elision, coarsening)
- ✅ Don't prematurely optimize
- ✅ Use AtomicInteger over synchronized int

### Common Pitfalls

**❌ Volatile without understanding limitations:**

```java
private volatile int counter = 0;
public void increment() {
    counter++;  // NOT ATOMIC! Data race!
}
```

**❌ Double-checked locking without volatile:**

```java
private static Resource instance;  // Missing volatile!
public static Resource getInstance() {
    if (instance == null) {
        synchronized(...) {
            if (instance == null) {
                instance = new Resource();  // Broken!
            }
        }
    }
    return instance;
}
```

**❌ Inconsistent lock ordering:**

```java
// Thread 1: lock(A); lock(B);
// Thread 2: lock(B); lock(A);  // DEADLOCK!
```

### JVM Flags Reference

```bash
# Lock monitoring
-XX:+PrintBiasedLockingStatistics
-XX:+PrintEliminateAllocations
-XX:+PrintEliminateLocks

# Lock configuration
-XX:+UseBiasedLocking           # Enable biased locking (default in Java 8-14)
-XX:-UseBiasedLocking           # Disable biased locking
-XX:BiasedLockingStartupDelay=0 # Enable biased locking immediately

# Profiling
-XX:+UnlockDiagnosticVMOptions
-XX:+LogCompilation
```

---

