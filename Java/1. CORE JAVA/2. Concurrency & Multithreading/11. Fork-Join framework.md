# Java Fork/Join Framework

## Overview

The Fork/Join framework is designed for parallel processing of recursive algorithms. It excels at divide-and-conquer problems by splitting tasks into smaller subtasks, processing them in parallel, and combining results. Introduced in Java 7, it's the foundation for parallel streams.

---

## 1. RecursiveTask vs RecursiveAction

### Basic Concepts

```java
/**
 * FORK/JOIN FRAMEWORK BASICS
 * 
 * RecursiveTask - Returns a result
 * RecursiveAction - No result (void)
 */

import java.util.concurrent.*;

public class ForkJoinBasics {
    
    /**
     * RecursiveTask - Returns result
     */
    static class SumTask extends RecursiveTask<Long> {
        private final long[] array;
        private final int start;
        private final int end;
        private static final int THRESHOLD = 1000;  // When to stop forking
        
        public SumTask(long[] array, int start, int end) {
            this.array = array;
            this.start = start;
            this.end = end;
        }
        
        @Override
        protected Long compute() {
            int length = end - start;
            
            // Base case: small enough to compute directly
            if (length <= THRESHOLD) {
                return computeDirectly();
            }
            
            // Recursive case: split into subtasks
            int mid = start + length / 2;
            
            SumTask leftTask = new SumTask(array, start, mid);
            SumTask rightTask = new SumTask(array, mid, end);
            
            // Fork left task (run in parallel)
            leftTask.fork();
            
            // Compute right task in current thread
            long rightResult = rightTask.compute();
            
            // Join left task (wait for result)
            long leftResult = leftTask.join();
            
            // Combine results
            return leftResult + rightResult;
        }
        
        private long computeDirectly() {
            long sum = 0;
            for (int i = start; i < end; i++) {
                sum += array[i];
            }
            return sum;
        }
    }
    
    /**
     * RecursiveAction - No result
     */
    static class IncrementAction extends RecursiveAction {
        private final int[] array;
        private final int start;
        private final int end;
        private static final int THRESHOLD = 1000;
        
        public IncrementAction(int[] array, int start, int end) {
            this.array = array;
            this.start = start;
            this.end = end;
        }
        
        @Override
        protected void compute() {
            int length = end - start;
            
            if (length <= THRESHOLD) {
                incrementDirectly();
            } else {
                int mid = start + length / 2;
                
                IncrementAction left = new IncrementAction(array, start, mid);
                IncrementAction right = new IncrementAction(array, mid, end);
                
                // Fork both tasks
                invokeAll(left, right);  // Convenience method
            }
        }
        
        private void incrementDirectly() {
            for (int i = start; i < end; i++) {
                array[i]++;
            }
        }
    }
    
    /**
     * Usage examples
     */
    public static void recursiveTaskDemo() {
        // Create array
        long[] array = new long[10_000_000];
        for (int i = 0; i < array.length; i++) {
            array[i] = i + 1;
        }
        
        // Create ForkJoinPool
        ForkJoinPool pool = new ForkJoinPool();
        
        // Create and execute task
        SumTask task = new SumTask(array, 0, array.length);
        
        long start = System.nanoTime();
        long result = pool.invoke(task);
        long elapsed = System.nanoTime() - start;
        
        System.out.println("Sum: " + result);
        System.out.println("Time: " + elapsed / 1_000_000 + "ms");
        
        /**
         * OUTPUT:
         * Sum: 50000005000000
         * Time: ~50ms
         * 
         * COMPARISON WITH SEQUENTIAL:
         * Sequential: ~20ms
         * Fork/Join: ~50ms
         * 
         * NOTE: For simple sum, sequential may be faster!
         * Fork/Join overhead only pays off for complex computations
         */
    }
    
    public static void recursiveActionDemo() {
        int[] array = new int[10_000_000];
        
        ForkJoinPool pool = new ForkJoinPool();
        IncrementAction action = new IncrementAction(array, 0, array.length);
        
        long start = System.nanoTime();
        pool.invoke(action);
        long elapsed = System.nanoTime() - start;
        
        System.out.println("First elements: " + array[0] + ", " + array[1]);
        System.out.println("Time: " + elapsed / 1_000_000 + "ms");
    }
    
    /**
     * Key differences
     */
    public static void differences() {
        /**
         * RECURSIVETASK<V>:
         * - Returns value of type V
         * - Use compute() to get result
         * - join() returns result
         * - Example: sum, max, search
         * 
         * RECURSIVEACTION:
         * - No return value (void)
         * - Side effects only
         * - join() waits for completion
         * - Example: array modification, file processing
         * 
         * PATTERN:
         * 1. Check if task small enough (threshold)
         * 2. If yes: compute directly
         * 3. If no: split into subtasks
         * 4. Fork subtasks
         * 5. Join and combine results
         */
    }
    
    public static void main(String[] args) {
        System.out.println("=== RecursiveTask ===");
        recursiveTaskDemo();
        
        System.out.println("\n=== RecursiveAction ===");
        recursiveActionDemo();
    }
}
```

---

## 2. Work-Stealing Algorithm

### How Fork/Join Pool Works

```java
/**
 * WORK-STEALING ALGORITHM
 * 
 * Core mechanism of ForkJoinPool
 */

public class WorkStealingExplanation {
    
    /**
     * Work-stealing architecture
     */
    public static void architecture() {
        /**
         * FORKJOINPOOL ARCHITECTURE:
         * 
         * Each worker thread has its own deque (double-ended queue):
         * 
         * Thread 1:  [Task A] [Task B] [Task C]
         *             ↑ (push/pop from head - LIFO)
         * 
         * Thread 2:  [Task D] [Task E]
         *             ↑ (push/pop from head - LIFO)
         * 
         * Thread 3:  [] (empty - idle)
         *             ↓ (steals from tail of other threads - FIFO)
         * 
         * 
         * WORK-STEALING PROCESS:
         * 
         * 1. NORMAL OPERATION:
         *    - Thread completes task
         *    - Pops next task from HEAD of own deque (LIFO)
         *    - LIFO preserves cache locality
         * 
         * 2. FORKING:
         *    - task.fork() → push to HEAD of own deque
         *    - Allows immediate execution by same thread
         * 
         * 3. STEALING:
         *    - Thread's deque is empty
         *    - Randomly picks victim thread
         *    - Steals task from TAIL of victim's deque (FIFO)
         *    - FIFO gets largest tasks (oldest = biggest)
         * 
         * 4. JOINING:
         *    - task.join() waits for result
         *    - If task not done, helps complete it
         *    - May steal and execute other tasks while waiting
         * 
         * 
         * WHY LIFO FOR OWN QUEUE?
         * - Cache locality: Recently forked tasks hot in cache
         * - Depth-first execution: Complete subtree before moving on
         * - Better memory usage
         * 
         * WHY FIFO FOR STEALING?
         * - Oldest tasks = larger tasks (not subdivided yet)
         * - Steal big tasks → more parallelism
         * - Reduce contention (fewer steals needed)
         * 
         * 
         * EXAMPLE:
         * 
         * Task splits 1000-element array:
         * 
         * Fork:     [0-1000]
         *              ↓
         *      [0-500]  [500-1000]
         *         ↓
         *   [0-250]  [250-500]
         * 
         * Thread 1's deque (after forking):
         * Head → [0-250] [250-500] [0-500] [500-1000] ← Tail
         * 
         * Thread 1 pops [0-250] (LIFO - smallest, most recent)
         * Thread 2 steals [500-1000] (FIFO - largest, oldest)
         * 
         * Result: Good work distribution!
         */
    }
    
    /**
     * Demonstration of work stealing
     */
    static class WorkStealingDemo extends RecursiveTask<Integer> {
        private final int start;
        private final int end;
        private static final int THRESHOLD = 10;
        
        public WorkStealingDemo(int start, int end) {
            this.start = start;
            this.end = end;
        }
        
        @Override
        protected Integer compute() {
            int length = end - start;
            
            if (length <= THRESHOLD) {
                System.out.println(Thread.currentThread().getName() + 
                    " computing [" + start + "-" + end + "]");
                return length;
            }
            
            int mid = start + length / 2;
            
            WorkStealingDemo left = new WorkStealingDemo(start, mid);
            WorkStealingDemo right = new WorkStealingDemo(mid, end);
            
            left.fork();
            int rightResult = right.compute();
            int leftResult = left.join();
            
            return leftResult + rightResult;
        }
    }
    
    public static void workStealingDemo() {
        ForkJoinPool pool = new ForkJoinPool(4);  // 4 worker threads
        
        WorkStealingDemo task = new WorkStealingDemo(0, 100);
        Integer result = pool.invoke(task);
        
        System.out.println("Result: " + result);
        
        /**
         * OUTPUT (typical):
         * ForkJoinPool-1-worker-1 computing [0-10]
         * ForkJoinPool-1-worker-2 computing [50-60]
         * ForkJoinPool-1-worker-3 computing [25-35]
         * ForkJoinPool-1-worker-1 computing [10-20]
         * ...
         * 
         * OBSERVE:
         * - Different threads process different ranges
         * - Work distributed automatically
         * - No explicit coordination needed
         */
    }
    
    /**
     * Pool statistics
     */
    public static void poolStatistics() {
        ForkJoinPool pool = ForkJoinPool.commonPool();
        
        System.out.println("Parallelism: " + pool.getParallelism());
        System.out.println("Pool size: " + pool.getPoolSize());
        System.out.println("Active threads: " + pool.getActiveThreadCount());
        System.out.println("Running threads: " + pool.getRunningThreadCount());
        System.out.println("Queued tasks: " + pool.getQueuedTaskCount());
        System.out.println("Steal count: " + pool.getStealCount());
        
        /**
         * METRICS:
         * - Parallelism: Target number of threads
         * - Pool size: Current threads in pool
         * - Active threads: Threads running or trying to run tasks
         * - Steal count: Total successful steals
         * 
         * HIGH STEAL COUNT = GOOD (work well distributed)
         * LOW STEAL COUNT = MAY indicate poor decomposition
         */
    }
    
    public static void main(String[] args) {
        workStealingDemo();
        System.out.println();
        poolStatistics();
    }
}
```

---

## 3. When to Use Fork/Join vs ExecutorService

### Decision Criteria

```java
/**
 * FORK/JOIN VS EXECUTORSERVICE
 * 
 * When to use each
 */

import java.util.concurrent.*;
import java.util.*;

public class ForkJoinVsExecutor {
    
    /**
     * Use Fork/Join when:
     */
    public static void useForkJoinWhen() {
        /**
         * ✓ RECURSIVE DECOMPOSITION:
         *   - Problem naturally splits into subproblems
         *   - Divide-and-conquer algorithm
         *   - Example: quicksort, mergesort, tree traversal
         * 
         * ✓ UNKNOWN NUMBER OF TASKS:
         *   - Tasks create more tasks dynamically
         *   - Depth varies by input
         *   - Example: parsing nested structures
         * 
         * ✓ CPU-INTENSIVE:
         *   - Computational work dominates
         *   - Little or no I/O
         *   - Example: image processing, scientific computing
         * 
         * ✓ BALANCED SUBTASKS:
         *   - Subtasks have similar execution time
         *   - Work-stealing can balance load
         * 
         * ✓ FINE-GRAINED PARALLELISM:
         *   - Many small tasks
         *   - Low overhead important
         */
    }
    
    /**
     * Use ExecutorService when:
     */
    public static void useExecutorWhen() {
        /**
         * ✓ INDEPENDENT TASKS:
         *   - Tasks don't spawn subtasks
         *   - Fixed number of tasks known upfront
         *   - Example: processing list of files
         * 
         * ✓ I/O-BOUND:
         *   - Network calls, database queries
         *   - Blocking operations
         *   - Fork/Join not designed for blocking
         * 
         * ✓ HETEROGENEOUS TASKS:
         *   - Tasks have very different execution times
         *   - Some long, some short
         * 
         * ✓ CUSTOM SCHEDULING:
         *   - Need priority queues
         *   - Need scheduling policies
         *   - Need task cancellation
         */
    }
    
    /**
     * Comparison examples
     */
    
    // GOOD for Fork/Join: Parallel merge sort
    static class MergeSort extends RecursiveAction {
        private final int[] array;
        private final int start;
        private final int end;
        private static final int THRESHOLD = 1000;
        
        public MergeSort(int[] array, int start, int end) {
            this.array = array;
            this.start = start;
            this.end = end;
        }
        
        @Override
        protected void compute() {
            if (end - start <= THRESHOLD) {
                Arrays.sort(array, start, end);
            } else {
                int mid = start + (end - start) / 2;
                
                MergeSort left = new MergeSort(array, start, mid);
                MergeSort right = new MergeSort(array, mid, end);
                
                invokeAll(left, right);
                merge(array, start, mid, end);
            }
        }
        
        private void merge(int[] array, int start, int mid, int end) {
            int[] temp = new int[end - start];
            int i = start, j = mid, k = 0;
            
            while (i < mid && j < end) {
                temp[k++] = array[i] < array[j] ? array[i++] : array[j++];
            }
            
            while (i < mid) temp[k++] = array[i++];
            while (j < end) temp[k++] = array[j++];
            
            System.arraycopy(temp, 0, array, start, temp.length);
        }
    }
    
    public static void forkJoinMergeSortDemo() {
        int[] array = new Random().ints(10_000_000, 0, 1000).toArray();
        
        ForkJoinPool pool = new ForkJoinPool();
        MergeSort task = new MergeSort(array, 0, array.length);
        
        long start = System.nanoTime();
        pool.invoke(task);
        long elapsed = System.nanoTime() - start;
        
        System.out.println("Fork/Join merge sort: " + elapsed / 1_000_000 + "ms");
        
        /**
         * GOOD FIT:
         * - Recursive decomposition
         * - CPU-intensive (sorting)
         * - Balanced subtasks
         */
    }
    
    // GOOD for ExecutorService: Processing files
    public static void executorFileProcessingDemo() throws InterruptedException {
        ExecutorService executor = Executors.newFixedThreadPool(10);
        List<Future<Integer>> futures = new ArrayList<>();
        
        // Simulate 100 files
        for (int i = 0; i < 100; i++) {
            final int fileId = i;
            Future<Integer> future = executor.submit(() -> {
                // Simulate I/O
                Thread.sleep(100);
                return fileId;
            });
            futures.add(future);
        }
        
        executor.shutdown();
        executor.awaitTermination(1, TimeUnit.MINUTES);
        
        System.out.println("Processed " + futures.size() + " files");
        
        /**
         * GOOD FIT:
         * - Independent tasks
         * - I/O-bound (file reading)
         * - Fixed number of tasks
         * - Blocking operations OK
         */
    }
    
    /**
     * Decision matrix
     */
    public static void decisionMatrix() {
        /**
         * ┌────────────────────────┬─────────────┬──────────────────┐
         * │ Characteristic         │ Fork/Join   │ ExecutorService  │
         * ├────────────────────────┼─────────────┼──────────────────┤
         * │ Task structure         │ Recursive   │ Independent      │
         * │ Number of tasks        │ Dynamic     │ Fixed            │
         * │ Task granularity       │ Fine        │ Coarse           │
         * │ Work type              │ CPU-bound   │ I/O-bound OK     │
         * │ Blocking operations    │ Avoid       │ OK               │
         * │ Work-stealing          │ Yes         │ No               │
         * │ Task dependencies      │ Parent-child│ None             │
         * │ Scheduling             │ LIFO/FIFO   │ FIFO             │
         * └────────────────────────┴─────────────┴──────────────────┘
         * 
         * EXAMPLES:
         * 
         * Fork/Join:
         * - Quicksort, mergesort
         * - Tree/graph traversal
         * - Matrix multiplication
         * - Image processing
         * - Parallel streams
         * 
         * ExecutorService:
         * - Batch processing
         * - Web scraping
         * - Database queries
         * - File I/O
         * - Network requests
         */
    }
    
    public static void main(String[] args) throws InterruptedException {
        System.out.println("=== Fork/Join Merge Sort ===");
        forkJoinMergeSortDemo();
        
        System.out.println("\n=== Executor File Processing ===");
        executorFileProcessingDemo();
    }
}
```

---

## 4. Parallel Streams Implementation

### How Parallel Streams Use Fork/Join

```java
/**
 * PARALLEL STREAMS
 * 
 * Built on top of Fork/Join framework
 */

import java.util.*;
import java.util.stream.*;

public class ParallelStreamsInternal {
    
    /**
     * How parallel streams work
     */
    public static void parallelStreamArchitecture() {
        /**
         * PARALLEL STREAM INTERNALS:
         * 
         * stream.parallel() uses ForkJoinPool.commonPool()
         * 
         * Behind the scenes:
         * 
         * list.parallelStream()
         *     .map(...)
         *     .filter(...)
         *     .collect(...);
         * 
         * Becomes:
         * 
         * ForkJoinPool.commonPool().invoke(
         *     new RecursiveTask() {
         *         protected Result compute() {
         *             // Split data
         *             // Fork subtasks
         *             // Process in parallel
         *             // Combine results
         *         }
         *     }
         * );
         * 
         * 
         * SPLITERATOR:
         * - Splits data source for parallel processing
         * - ArrayList: Excellent splitting (random access)
         * - LinkedList: Poor splitting (sequential access)
         * - HashSet: Good splitting
         */
    }
    
    /**
     * Basic parallel stream usage
     */
    public static void basicParallelStream() {
        List<Integer> numbers = IntStream.rangeClosed(1, 10_000_000)
            .boxed()
            .collect(Collectors.toList());
        
        // Sequential
        long start = System.nanoTime();
        long sum = numbers.stream()
            .mapToLong(Integer::longValue)
            .sum();
        long sequential = System.nanoTime() - start;
        
        // Parallel
        start = System.nanoTime();
        long parallelSum = numbers.parallelStream()
            .mapToLong(Integer::longValue)
            .sum();
        long parallel = System.nanoTime() - start;
        
        System.out.println("Sequential: " + sequential / 1_000_000 + "ms");
        System.out.println("Parallel: " + parallel / 1_000_000 + "ms");
        System.out.println("Speedup: " + (double) sequential / parallel + "x");
        
        /**
         * OUTPUT (typical):
         * Sequential: 45ms
         * Parallel: 15ms
         * Speedup: 3x
         * 
         * NOTE: Speedup depends on:
         * - Number of cores
         * - Task complexity
         * - Data size
         */
    }
    
    /**
     * Custom ForkJoinPool for parallel streams
     */
    public static void customPool() throws Exception {
        List<Integer> numbers = IntStream.rangeClosed(1, 1000)
            .boxed()
            .collect(Collectors.toList());
        
        // Default: Uses ForkJoinPool.commonPool()
        numbers.parallelStream().forEach(n -> {
            System.out.println(Thread.currentThread().getName());
        });
        
        // Custom pool
        ForkJoinPool customPool = new ForkJoinPool(2);  // 2 threads
        
        customPool.submit(() -> {
            numbers.parallelStream().forEach(n -> {
                System.out.println(Thread.currentThread().getName());
            });
        }).get();
        
        customPool.shutdown();
        
        /**
         * CAUTION:
         * - Custom pool is tricky
         * - Can lead to unexpected behavior
         * - Generally stick with commonPool
         */
    }
    
    /**
     * When parallel streams help
     */
    public static void whenParallelHelps() {
        List<Integer> numbers = IntStream.rangeClosed(1, 1_000_000)
            .boxed()
            .collect(Collectors.toList());
        
        // GOOD: CPU-intensive operation
        long start = System.nanoTime();
        long sum = numbers.parallelStream()
            .map(n -> {
                // Expensive computation
                double result = 0;
                for (int i = 0; i < 100; i++) {
                    result += Math.sqrt(n * i);
                }
                return n;
            })
            .mapToLong(Integer::longValue)
            .sum();
        long elapsed = System.nanoTime() - start;
        
        System.out.println("With expensive computation: " + elapsed / 1_000_000 + "ms");
        
        /**
         * PARALLEL HELPS WHEN:
         * - Operation is CPU-intensive
         * - Large dataset (>1000 elements)
         * - Independent operations (no shared state)
         * - Stateless operations
         * 
         * PARALLEL HURTS WHEN:
         * - Simple operations (overhead > benefit)
         * - Small dataset
         * - Synchronized operations
         * - I/O operations
         */
    }
    
    /**
     * When parallel streams hurt
     */
    public static void whenParallelHurts() {
        List<Integer> numbers = IntStream.rangeClosed(1, 1000)
            .boxed()
            .collect(Collectors.toList());
        
        // BAD: Synchronized operation
        List<Integer> results = Collections.synchronizedList(new ArrayList<>());
        
        long start = System.nanoTime();
        numbers.parallelStream().forEach(n -> {
            results.add(n);  // Synchronized!
        });
        long parallel = System.nanoTime() - start;
        
        // Sequential is faster
        results.clear();
        start = System.nanoTime();
        numbers.stream().forEach(results::add);
        long sequential = System.nanoTime() - start;
        
        System.out.println("Parallel (synchronized): " + parallel / 1_000_000 + "ms");
        System.out.println("Sequential: " + sequential / 1_000_000 + "ms");
        
        /**
         * OUTPUT:
         * Parallel (synchronized): 15ms
         * Sequential: 2ms
         * 
         * WHY PARALLEL IS SLOWER:
         * - Synchronization contention
         * - Work-stealing overhead
         * - Thread coordination overhead
         */
    }
    
    /**
     * Best practices for parallel streams
     */
    public static void bestPractices() {
        /**
         * DO:
         * ✓ Use for CPU-intensive operations
         * ✓ Use with ArrayList, arrays, IntStream, LongStream
         * ✓ Use stateless operations
         * ✓ Benchmark before and after
         * 
         * DON'T:
         * ✗ Use for I/O operations
         * ✗ Use with LinkedList, Stream.iterate()
         * ✗ Use with synchronized collections
         * ✗ Modify shared state
         * ✗ Assume it's always faster
         * 
         * COLLECT PROPERLY:
         * 
         * // BAD: Thread contention
         * List<Integer> list = new ArrayList<>();
         * stream.parallel().forEach(list::add);
         * 
         * // GOOD: Concurrent collection
         * List<Integer> list = stream.parallel()
         *     .collect(Collectors.toList());
         * 
         * // GOOD: Proper reduction
         * int sum = stream.parallel()
         *     .reduce(0, Integer::sum);
         */
    }
    
    public static void main(String[] args) throws Exception {
        System.out.println("=== Basic Parallel Stream ===");
        basicParallelStream();
        
        System.out.println("\n=== When Parallel Helps ===");
        whenParallelHelps();
        
        System.out.println("\n=== When Parallel Hurts ===");
        whenParallelHurts();
    }
}
```

---

## 5. Common Pitfalls

### Avoiding Fork/Join Mistakes

```java
/**
 * FORK/JOIN PITFALLS
 * 
 * Common mistakes and how to avoid them
 */

import java.util.concurrent.*;

public class ForkJoinPitfalls {
    
    /**
     * Pitfall 1: Too many tasks (overhead)
     */
    static class TooManyTasksBad extends RecursiveTask<Long> {
        private final int start;
        private final int end;
        private static final int THRESHOLD = 1;  // TOO SMALL!
        
        public TooManyTasksBad(int start, int end) {
            this.start = start;
            this.end = end;
        }
        
        @Override
        protected Long compute() {
            if (end - start <= THRESHOLD) {
                return (long) (end - start);
            }
            
            int mid = start + (end - start) / 2;
            TooManyTasksBad left = new TooManyTasksBad(start, mid);
            TooManyTasksBad right = new TooManyTasksBad(mid, end);
            
            left.fork();
            long rightResult = right.compute();
            long leftResult = left.join();
            
            return leftResult + rightResult;
        }
    }
    
    static class GoodThreshold extends RecursiveTask<Long> {
        private final int start;
        private final int end;
        private static final int THRESHOLD = 10000;  // GOOD!
        
        public GoodThreshold(int start, int end) {
            this.start = start;
            this.end = end;
        }
        
        @Override
        protected Long compute() {
            if (end - start <= THRESHOLD) {
                long sum = 0;
                for (int i = start; i < end; i++) {
                    sum += i;
                }
                return sum;
            }
            
            int mid = start + (end - start) / 2;
            GoodThreshold left = new GoodThreshold(start, mid);
            GoodThreshold right = new GoodThreshold(mid, end);
            
            left.fork();
            long rightResult = right.compute();
            long leftResult = left.join();
            
            return leftResult + rightResult;
        }
    }
    
    public static void thresholdComparison() {
        ForkJoinPool pool = new ForkJoinPool();
        int n = 10_000_000;
        
        // Bad threshold
        long start = System.nanoTime();
        pool.invoke(new TooManyTasksBad(0, n));
        long badTime = System.nanoTime() - start;
        
        // Good threshold
        start = System.nanoTime();
        pool.invoke(new GoodThreshold(0, n));
        long goodTime = System.nanoTime() - start;
        
        System.out.println("Bad threshold (1): " + badTime / 1_000_000 + "ms");
        System.out.println("Good threshold (10000): " + goodTime / 1_000_000 + "ms");
        System.out.println("Speedup: " + (double) badTime / goodTime + "x");
        
        /**
         * OUTPUT (typical):
         * Bad threshold (1): 5000ms
         * Good threshold (10000): 50ms
         * Speedup: 100x
         * 
         * WHY BAD THRESHOLD HURTS:
         * - Creates millions of tasks
         * - Task creation overhead
         * - Work-stealing overhead
         * - Memory overhead
         * 
         * GUIDELINE:
         * - Start with 1000-10000 elements
         * - Benchmark and tune
         * - Balance: not too many, not too few tasks
         */
    }
    
    /**
     * Pitfall 2: Blocking operations
     */
    static class BlockingInForkJoin extends RecursiveTask<Integer> {
        private final int id;
        
        public BlockingInForkJoin(int id) {
            this.id = id;
        }
        
        @Override
        protected Integer compute() {
            try {
                // BAD: Blocking in Fork/Join!
                Thread.sleep(100);
                return id;
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                return 0;
            }
        }
    }
    
    public static void blockingProblem() {
        ForkJoinPool pool = new ForkJoinPool(4);  // 4 threads
        
        long start = System.nanoTime();
        
        // Fork 100 tasks that block
        java.util.List<RecursiveTask<Integer>> tasks = new java.util.ArrayList<>();
        for (int i = 0; i < 100; i++) {
            BlockingInForkJoin task = new BlockingInForkJoin(i);
            pool.execute(task);
            tasks.add(task);
        }
        
        for (RecursiveTask<Integer> task : tasks) {
            task.join();
        }
        
        long elapsed = System.nanoTime() - start;
        System.out.println("Time with blocking: " + elapsed / 1_000_000 + "ms");
        
        /**
         * OUTPUT:
         * Time with blocking: ~2500ms
         * 
         * EXPECTED: 100ms (100 tasks * 100ms / 4 threads)
         * ACTUAL: 2500ms (25x slower!)
         * 
         * WHY:
         * - Fork/Join assumes CPU-bound work
         * - Blocking ties up worker threads
         * - Work-stealing can't help
         * - Thread starvation
         * 
         * SOLUTION:
         * - Use ExecutorService for blocking tasks
         * - Or use ManagedBlocker (advanced)
         */
    }
    
    /**
     * Pitfall 3: Imbalanced tasks
     */
    static class ImbalancedTasks extends RecursiveTask<Long> {
        private final int start;
        private final int end;
        private static final int THRESHOLD = 100;
        
        public ImbalancedTasks(int start, int end) {
            this.start = start;
            this.end = end;
        }
        
        @Override
        protected Long compute() {
            if (end - start <= THRESHOLD) {
                long sum = 0;
                for (int i = start; i < end; i++) {
                    // Work proportional to i (imbalanced!)
                    for (int j = 0; j < i; j++) {
                        sum += j;
                    }
                }
                return sum;
            }
            
            int mid = start + (end - start) / 2;
            ImbalancedTasks left = new ImbalancedTasks(start, mid);
            ImbalancedTasks right = new ImbalancedTasks(mid, end);
            
            left.fork();
            long rightResult = right.compute();
            long leftResult = left.join();
            
            return leftResult + rightResult;
        }
    }
    
    /**
     * Pitfall 4: Sharing mutable state
     */
    static class SharedStateBad extends RecursiveAction {
        private final int[] sharedArray;  // MUTABLE!
        private final int start;
        private final int end;
        
        public SharedStateBad(int[] array, int start, int end) {
            this.sharedArray = array;
            this.start = start;
            this.end = end;
        }
        
        @Override
        protected void compute() {
            for (int i = start; i < end; i++) {
                // RACE CONDITION!
                sharedArray[0]++;
            }
        }
    }
    
    public static void sharedStateProblem() {
        int[] shared = new int[1];
        ForkJoinPool pool = new ForkJoinPool();
        
        for (int trial = 0; trial < 10; trial++) {
            shared[0] = 0;
            
            SharedStateBad task = new SharedStateBad(shared, 0, 10000);
            pool.invoke(task);
            
            System.out.println("Trial " + trial + ": " + shared[0]);
        }
        
        /**
         * OUTPUT:
         * Trial 0: 9823
         * Trial 1: 9891
         * Trial 2: 9765
         * ...
         * 
         * EXPECTED: 10000
         * ACTUAL: Random values < 10000
         * 
         * PROBLEM:
         * - Multiple threads modify shared state
         * - No synchronization
         * - Lost updates
         * 
         * SOLUTION:
         * - Use immutable data
         * - Or AtomicInteger
         * - Or proper synchronization
         * - Or return results and combine
         */
    }
    
    /**
     * Pitfall 5: Inefficient join pattern
     */
    static class InefficientJoin extends RecursiveTask<Integer> {
        private final int value;
        
        public InefficientJoin(int value) {
            this.value = value;
        }
        
        @Override
        protected Integer compute() {
            if (value <= 1) {
                return value;
            }
            
            // BAD: Fork then immediately join
            InefficientJoin left = new InefficientJoin(value - 1);
            InefficientJoin right = new InefficientJoin(value - 2);
            
            left.fork();
            right.fork();
            
            // Immediately join both (no parallelism!)
            return left.join() + right.join();
        }
    }
    
    static class EfficientJoin extends RecursiveTask<Integer> {
        private final int value;
        
        public EfficientJoin(int value) {
            this.value = value;
        }
        
        @Override
        protected Integer compute() {
            if (value <= 1) {
                return value;
            }
            
            // GOOD: Fork one, compute other
            EfficientJoin left = new EfficientJoin(value - 1);
            EfficientJoin right = new EfficientJoin(value - 2);
            
            left.fork();
            int rightResult = right.compute();  // Compute in current thread
            int leftResult = left.join();
            
            return leftResult + rightResult;
        }
    }
    
    /**
     * Summary of pitfalls
     */
    public static void pitfallSummary() {
        /**
         * COMMON PITFALLS:
         * 
         * 1. Too small threshold
         *    - Creates too many tasks
         *    - Overhead > benefit
         *    - Solution: Increase threshold (1000-10000)
         * 
         * 2. Blocking operations
         *    - Ties up worker threads
         *    - Defeats work-stealing
         *    - Solution: Use ExecutorService instead
         * 
         * 3. Imbalanced tasks
         *    - Some tasks much longer than others
         *    - Poor work distribution
         *    - Solution: Better decomposition strategy
         * 
         * 4. Shared mutable state
         *    - Race conditions
         *    - Non-deterministic results
         *    - Solution: Immutable data or proper sync
         * 
         * 5. Inefficient join
         *    - Fork then immediately join
         *    - No parallelism
         *    - Solution: Compute one branch in current thread
         * 
         * 6. Wrong data structure
         *    - LinkedList poor for parallel streams
         *    - Stream.iterate() sequential
         *    - Solution: Use ArrayList, arrays, ranges
         */
    }
    
    public static void main(String[] args) {
        System.out.println("=== Threshold Comparison ===");
        thresholdComparison();
        
        System.out.println("\n=== Blocking Problem ===");
        blockingProblem();
        
        System.out.println("\n=== Shared State Problem ===");
        sharedStateProblem();
    }
}
```

---

## 6. Performance Tuning

### Optimizing Fork/Join Performance

```java
/**
 * FORK/JOIN PERFORMANCE TUNING
 * 
 * Techniques for optimal performance
 */

import java.util.concurrent.*;

public class ForkJoinPerformanceTuning {
    
    /**
     * Tuning 1: Threshold selection
     */
    static class TunableTask extends RecursiveTask<Long> {
        private final long[] array;
        private final int start;
        private final int end;
        private final int threshold;
        
        public TunableTask(long[] array, int start, int end, int threshold) {
            this.array = array;
            this.start = start;
            this.end = end;
            this.threshold = threshold;
        }
        
        @Override
        protected Long compute() {
            if (end - start <= threshold) {
                long sum = 0;
                for (int i = start; i < end; i++) {
                    sum += array[i];
                }
                return sum;
            }
            
            int mid = start + (end - start) / 2;
            TunableTask left = new TunableTask(array, start, mid, threshold);
            TunableTask right = new TunableTask(array, mid, end, threshold);
            
            left.fork();
            long rightResult = right.compute();
            long leftResult = left.join();
            
            return leftResult + rightResult;
        }
    }
    
    public static void thresholdTuning() {
        long[] array = new long[10_000_000];
        for (int i = 0; i < array.length; i++) {
            array[i] = i;
        }
        
        ForkJoinPool pool = new ForkJoinPool();
        
        int[] thresholds = {100, 1_000, 10_000, 100_000, 1_000_000};
        
        for (int threshold : thresholds) {
            long start = System.nanoTime();
            TunableTask task = new TunableTask(array, 0, array.length, threshold);
            pool.invoke(task);
            long elapsed = System.nanoTime() - start;
            
            System.out.println("Threshold " + threshold + ": " + 
                elapsed / 1_000_000 + "ms");
        }
        
        /**
         * OUTPUT (typical):
         * Threshold 100: 450ms
         * Threshold 1000: 85ms
         * Threshold 10000: 45ms
         * Threshold 100000: 42ms
         * Threshold 1000000: 48ms
         * 
         * OPTIMAL: Around 10,000-100,000
         * 
         * GUIDELINES:
         * - Too small: Task creation overhead
         * - Too large: Not enough parallelism
         * - Sweet spot: 1000-10000 for simple operations
         * - Increase for complex operations
         * - Benchmark with real data
         */
    }
    
    /**
     * Tuning 2: Pool sizing
     */
    public static void poolSizing() {
        long[] array = new long[10_000_000];
        for (int i = 0; i < array.length; i++) {
            array[i] = i;
        }
        
        int cores = Runtime.getRuntime().availableProcessors();
        System.out.println("Available processors: " + cores);
        
        int[] poolSizes = {1, 2, 4, cores, cores * 2};
        
        for (int poolSize : poolSizes) {
            ForkJoinPool pool = new ForkJoinPool(poolSize);
            
            long start = System.nanoTime();
            TunableTask task = new TunableTask(array, 0, array.length, 10000);
            pool.invoke(task);
            long elapsed = System.nanoTime() - start;
            
            System.out.println("Pool size " + poolSize + ": " + 
                elapsed / 1_000_000 + "ms");
            
            pool.shutdown();
        }
        
        /**
         * OUTPUT (8-core machine):
         * Available processors: 8
         * Pool size 1: 180ms
         * Pool size 2: 95ms
         * Pool size 4: 52ms
         * Pool size 8: 45ms
         * Pool size 16: 48ms
         * 
         * GUIDELINE:
         * - Default (commonPool): CPU cores
         * - CPU-bound: CPU cores or cores - 1
         * - Mixed workload: CPU cores + 1 or 2
         * - Don't over-provision (context switching overhead)
         */
    }
    
    /**
     * Tuning 3: Computation complexity
     */
    static class ComplexComputation extends RecursiveTask<Double> {
        private final double[] data;
        private final int start;
        private final int end;
        private static final int THRESHOLD = 1000;
        
        public ComplexComputation(double[] data, int start, int end) {
            this.data = data;
            this.start = start;
            this.end = end;
        }
        
        @Override
        protected Double compute() {
            if (end - start <= THRESHOLD) {
                double result = 0;
                for (int i = start; i < end; i++) {
                    // Complex computation
                    result += Math.sqrt(data[i]) * Math.sin(data[i]);
                }
                return result;
            }
            
            int mid = start + (end - start) / 2;
            ComplexComputation left = new ComplexComputation(data, start, mid);
            ComplexComputation right = new ComplexComputation(data, mid, end);
            
            left.fork();
            double rightResult = right.compute();
            double leftResult = left.join();
            
            return leftResult + rightResult;
        }
    }
    
    public static void complexityBenchmark() {
        double[] data = new double[1_000_000];
        for (int i = 0; i < data.length; i++) {
            data[i] = i;
        }
        
        // Sequential
        long start = System.nanoTime();
        double sum = 0;
        for (double v : data) {
            sum += Math.sqrt(v) * Math.sin(v);
        }
        long sequential = System.nanoTime() - start;
        
        // Parallel
        ForkJoinPool pool = new ForkJoinPool();
        start = System.nanoTime();
        ComplexComputation task = new ComplexComputation(data, 0, data.length);
        pool.invoke(task);
        long parallel = System.nanoTime() - start;
        
        System.out.println("Sequential: " + sequential / 1_000_000 + "ms");
        System.out.println("Parallel: " + parallel / 1_000_000 + "ms");
        System.out.println("Speedup: " + (double) sequential / parallel + "x");
        
        /**
         * OUTPUT (8 cores):
         * Sequential: 850ms
         * Parallel: 125ms
         * Speedup: 6.8x
         * 
         * OBSERVATION:
         * - More complex computation = better speedup
         * - Simple operations may not benefit
         * - Overhead is amortized over complex work
         */
    }
    
    /**
     * Tuning 4: Memory locality
     */
    static class LocalityAware extends RecursiveTask<Long> {
        private final long[] array;
        private final int start;
        private final int end;
        private static final int THRESHOLD = 10000;
        
        public LocalityAware(long[] array, int start, int end) {
            this.array = array;
            this.start = start;
            this.end = end;
        }
        
        @Override
        protected Long compute() {
            if (end - start <= THRESHOLD) {
                // Process contiguous block (good cache locality)
                long sum = 0;
                for (int i = start; i < end; i++) {
                    sum += array[i];
                }
                return sum;
            }
            
            // Split in middle (preserves locality)
            int mid = start + (end - start) / 2;
            
            LocalityAware left = new LocalityAware(array, start, mid);
            LocalityAware right = new LocalityAware(array, mid, end);
            
            left.fork();
            long rightResult = right.compute();
            long leftResult = left.join();
            
            return leftResult + rightResult;
        }
    }
    
    /**
     * Monitoring and diagnostics
     */
    public static void monitoring() {
        ForkJoinPool pool = ForkJoinPool.commonPool();
        
        System.out.println("=== Pool Statistics ===");
        System.out.println("Parallelism: " + pool.getParallelism());
        System.out.println("Pool size: " + pool.getPoolSize());
        System.out.println("Active threads: " + pool.getActiveThreadCount());
        System.out.println("Running threads: " + pool.getRunningThreadCount());
        System.out.println("Queued submissions: " + pool.getQueuedSubmissionCount());
        System.out.println("Queued tasks: " + pool.getQueuedTaskCount());
        System.out.println("Steal count: " + pool.getStealCount());
        
        /**
         * METRICS TO WATCH:
         * 
         * High steal count = Good (work well distributed)
         * Low steal count = May indicate:
         *   - Poor decomposition
         *   - Imbalanced tasks
         *   - Threshold too large
         * 
         * Active threads < parallelism = May indicate:
         *   - Blocking operations
         *   - Insufficient work
         * 
         * Queued tasks growing = May indicate:
         *   - Too many small tasks
         *   - Insufficient parallelism
         */
    }
    
    /**
     * Performance checklist
     */
    public static void performanceChecklist() {
        /**
         * PERFORMANCE TUNING CHECKLIST:
         * 
         * 1. THRESHOLD SELECTION:
         *    ✓ Start with 1000-10000
         *    ✓ Benchmark with real data
         *    ✓ Balance task count vs overhead
         * 
         * 2. POOL SIZING:
         *    ✓ Default (CPU cores) for CPU-bound
         *    ✓ Don't over-provision
         *    ✓ Monitor thread utilization
         * 
         * 3. ALGORITHM:
         *    ✓ Minimize shared state
         *    ✓ Balance subtasks
         *    ✓ Avoid blocking
         *    ✓ Good cache locality
         * 
         * 4. MEASUREMENT:
         *    ✓ Benchmark sequential vs parallel
         *    ✓ Monitor steal count
         *    ✓ Check thread utilization
         *    ✓ Profile with JFR
         * 
         * 5. COMPARISON:
         *    ✓ Try parallel streams
         *    ✓ Try ExecutorService
         *    ✓ Measure real workload
         */
    }
    
    public static void main(String[] args) {
        System.out.println("=== Threshold Tuning ===");
        thresholdTuning();
        
        System.out.println("\n=== Pool Sizing ===");
        poolSizing();
        
        System.out.println("\n=== Complexity Benchmark ===");
        complexityBenchmark();
        
        System.out.println("\n=== Monitoring ===");
        monitoring();
    }
}
```

---

## 7. Real-World Use Cases

### Practical Applications

```java
/**
 * FORK/JOIN REAL-WORLD USE CASES
 * 
 * Practical examples
 */

import java.util.concurrent.*;
import java.util.*;

public class ForkJoinUseCases {
    
    /**
     * Use Case 1: Parallel quick sort
     */
    static class ParallelQuickSort extends RecursiveAction {
        private final int[] array;
        private final int start;
        private final int end;
        private static final int THRESHOLD = 1000;
        
        public ParallelQuickSort(int[] array, int start, int end) {
            this.array = array;
            this.start = start;
            this.end = end;
        }
        
        @Override
        protected void compute() {
            if (end - start <= THRESHOLD) {
                Arrays.sort(array, start, end);
            } else {
                int pivot = partition(array, start, end);
                
                ParallelQuickSort left = new ParallelQuickSort(array, start, pivot);
                ParallelQuickSort right = new ParallelQuickSort(array, pivot + 1, end);
                
                invokeAll(left, right);
            }
        }
        
        private int partition(int[] array, int start, int end) {
            int pivot = array[end - 1];
            int i = start - 1;
            
            for (int j = start; j < end - 1; j++) {
                if (array[j] <= pivot) {
                    i++;
                    swap(array, i, j);
                }
            }
            
            swap(array, i + 1, end - 1);
            return i + 1;
        }
        
        private void swap(int[] array, int i, int j) {
            int temp = array[i];
            array[i] = array[j];
            array[j] = temp;
        }
    }
    
    public static void quickSortDemo() {
        int[] array = new Random().ints(10_000_000, 0, 1000).toArray();
        int[] copy = Arrays.copyOf(array, array.length);
        
        // Sequential
        long start = System.nanoTime();
        Arrays.sort(copy);
        long sequential = System.nanoTime() - start;
        
        // Parallel
        ForkJoinPool pool = new ForkJoinPool();
        start = System.nanoTime();
        pool.invoke(new ParallelQuickSort(array, 0, array.length));
        long parallel = System.nanoTime() - start;
        
        System.out.println("Sequential sort: " + sequential / 1_000_000 + "ms");
        System.out.println("Parallel sort: " + parallel / 1_000_000 + "ms");
        System.out.println("Speedup: " + (double) sequential / parallel + "x");
    }
    
    /**
     * Use Case 2: Document processing
     */
    static class DocumentProcessor extends RecursiveTask<Map<String, Integer>> {
        private final List<String> documents;
        private final int start;
        private final int end;
        private static final int THRESHOLD = 100;
        
        public DocumentProcessor(List<String> documents, int start, int end) {
            this.documents = documents;
            this.start = start;
            this.end = end;
        }
        
        @Override
        protected Map<String, Integer> compute() {
            if (end - start <= THRESHOLD) {
                return processDocuments();
            }
            
            int mid = start + (end - start) / 2;
            
            DocumentProcessor left = new DocumentProcessor(documents, start, mid);
            DocumentProcessor right = new DocumentProcessor(documents, mid, end);
            
            left.fork();
            Map<String, Integer> rightResult = right.compute();
            Map<String, Integer> leftResult = left.join();
            
            return merge(leftResult, rightResult);
        }
        
        private Map<String, Integer> processDocuments() {
            Map<String, Integer> wordCount = new HashMap<>();
            
            for (int i = start; i < end; i++) {
                String[] words = documents.get(i).split("\\s+");
                for (String word : words) {
                    wordCount.merge(word.toLowerCase(), 1, Integer::sum);
                }
            }
            
            return wordCount;
        }
        
        private Map<String, Integer> merge(Map<String, Integer> left, 
                Map<String, Integer> right) {
            Map<String, Integer> merged = new HashMap<>(left);
            right.forEach((word, count) -> 
                merged.merge(word, count, Integer::sum));
            return merged;
        }
    }
    
    public static void documentProcessingDemo() {
        // Generate sample documents
        List<String> documents = new ArrayList<>();
        Random random = new Random();
        String[] words = {"hello", "world", "java", "fork", "join", "parallel"};
        
        for (int i = 0; i < 10000; i++) {
            StringBuilder doc = new StringBuilder();
            for (int j = 0; j < 100; j++) {
                doc.append(words[random.nextInt(words.length)]).append(" ");
            }
            documents.add(doc.toString());
        }
        
        ForkJoinPool pool = new ForkJoinPool();
        
        long start = System.nanoTime();
        DocumentProcessor task = new DocumentProcessor(documents, 0, documents.size());
        Map<String, Integer> result = pool.invoke(task);
        long elapsed = System.nanoTime() - start;
        
        System.out.println("Processed " + documents.size() + " documents");
        System.out.println("Time: " + elapsed / 1_000_000 + "ms");
        System.out.println("Total words: " + result.values().stream()
            .mapToInt(Integer::intValue).sum());
    }
    
    /**
     * Use Case 3: Image processing
     */
    static class ImageBlur extends RecursiveAction {
        private final int[] pixels;
        private final int[] result;
        private final int width;
        private final int start;
        private final int end;
        private static final int THRESHOLD = 1000;
        
        public ImageBlur(int[] pixels, int[] result, int width, int start, int end) {
            this.pixels = pixels;
            this.result = result;
            this.width = width;
            this.start = start;
            this.end = end;
        }
        
        @Override
        protected void compute() {
            if (end - start <= THRESHOLD) {
                blurDirectly();
            } else {
                int mid = start + (end - start) / 2;
                
                ImageBlur left = new ImageBlur(pixels, result, width, start, mid);
                ImageBlur right = new ImageBlur(pixels, result, width, mid, end);
                
                invokeAll(left, right);
            }
        }
        
        private void blurDirectly() {
            for (int i = start; i < end; i++) {
                result[i] = blur(i);
            }
        }
        
        private int blur(int index) {
            int sum = 0;
            int count = 0;
            
            // Simple 3x3 blur
            int row = index / width;
            int col = index % width;
            
            for (int dr = -1; dr <= 1; dr++) {
                for (int dc = -1; dc <= 1; dc++) {
                    int r = row + dr;
                    int c = col + dc;
                    if (r >= 0 && r < pixels.length / width && c >= 0 && c < width) {
                        sum += pixels[r * width + c];
                        count++;
                    }
                }
            }
            
            return count > 0 ? sum / count : pixels[index];
        }
    }
    
    public static void imageProcessingDemo() {
        int width = 4000;
        int height = 3000;
        int[] pixels = new int[width * height];
        int[] result = new int[width * height];
        
        // Initialize with random pixel values
        Random random = new Random();
        for (int i = 0; i < pixels.length; i++) {
            pixels[i] = random.nextInt(256);
        }
        
        ForkJoinPool pool = new ForkJoinPool();
        
        long start = System.nanoTime();
        ImageBlur task = new ImageBlur(pixels, result, width, 0, pixels.length);
        pool.invoke(task);
        long elapsed = System.nanoTime() - start;
        
        System.out.println("Processed " + width + "x" + height + " image");
        System.out.println("Time: " + elapsed / 1_000_000 + "ms");
    }
    
    /**
     * Use Case 4: File system traversal
     */
    static class DirectorySize extends RecursiveTask<Long> {
        private final java.io.File directory;
        
        public DirectorySize(java.io.File directory) {
            this.directory = directory;
        }
        
        @Override
        protected Long compute() {
            if (!directory.isDirectory()) {
                return directory.length();
            }
            
            java.io.File[] files = directory.listFiles();
            if (files == null) {
                return 0L;
            }
            
            List<DirectorySize> subtasks = new ArrayList<>();
            long size = 0;
            
            for (java.io.File file : files) {
                if (file.isDirectory()) {
                    DirectorySize subtask = new DirectorySize(file);
                    subtask.fork();
                    subtasks.add(subtask);
                } else {
                    size += file.length();
                }
            }
            
            for (DirectorySize subtask : subtasks) {
                size += subtask.join();
            }
            
            return size;
        }
    }
    
    public static void fileSystemDemo() {
        java.io.File directory = new java.io.File(".");
        
        ForkJoinPool pool = new ForkJoinPool();
        
        long start = System.nanoTime();
        DirectorySize task = new DirectorySize(directory);
        Long size = pool.invoke(task);
        long elapsed = System.nanoTime() - start;
        
        System.out.println("Directory: " + directory.getAbsolutePath());
        System.out.println("Total size: " + size / (1024 * 1024) + " MB");
        System.out.println("Time: " + elapsed / 1_000_000 + "ms");
    }
    
    public static void main(String[] args) {
        System.out.println("=== Parallel Quick Sort ===");
        quickSortDemo();
        
        System.out.println("\n=== Document Processing ===");
        documentProcessingDemo();
        
        System.out.println("\n=== Image Processing ===");
        imageProcessingDemo();
        
        System.out.println("\n=== File System Traversal ===");
        fileSystemDemo();
    }
}
```

---

## Summary

### Quick Reference

**RecursiveTask vs RecursiveAction:**

```java
// Returns result
class SumTask extends RecursiveTask<Long> {
    protected Long compute() {
        if (small) return computeDirectly();
        
        SumTask left = new SumTask(...);
        SumTask right = new SumTask(...);
        
        left.fork();
        long rightResult = right.compute();
        long leftResult = left.join();
        
        return leftResult + rightResult;
    }
}

// No result (void)
class IncrementAction extends RecursiveAction {
    protected void compute() {
        if (small) {
            incrementDirectly();
        } else {
            invokeAll(left, right);
        }
    }
}
```

**Threshold Selection:**

```
Too small (< 100): Too many tasks, overhead dominates
Optimal (1000-10000): Good balance
Too large (> 100000): Not enough parallelism
```

**Fork/Join vs ExecutorService:**

```
Fork/Join:
✓ Recursive decomposition
✓ CPU-intensive
✓ Dynamic task creation
✓ Work-stealing

ExecutorService:
✓ Independent tasks
✓ I/O-bound OK
✓ Fixed task count
✓ Blocking OK
```

**Parallel Streams:**

```java
// Uses ForkJoinPool.commonPool()
list.parallelStream()
    .filter(...)
    .map(...)
    .collect(Collectors.toList());

// Good: ArrayList, arrays, ranges
// Bad: LinkedList, Stream.iterate()
```

### Best Practices

1. ✅ **Threshold 1000-10000** for simple operations
2. ✅ **Compute one branch** in current thread (fork one, compute other)
3. ✅ **CPU-intensive only** (no blocking)
4. ✅ **Balanced subtasks**
5. ✅ **Immutable data** or careful synchronization
6. ✅ **Benchmark** sequential vs parallel
7. ❌ **Don't use for I/O** operations
8. ❌ **Don't share mutable state**
9. ❌ **Don't fork then immediately join both**
10. ❌ **Don't assume faster** (measure!)

---

