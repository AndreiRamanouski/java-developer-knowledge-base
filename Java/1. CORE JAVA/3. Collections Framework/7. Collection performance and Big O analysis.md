# Collection Performance and Big O Analysis

## Overview

Understanding the performance characteristics of Java collections is crucial for writing efficient code. This guide provides comprehensive Big O analysis, real-world benchmarks, and decision frameworks for choosing optimal data structures. We'll examine time and space complexity, amortized analysis, cache locality, and practical benchmarking techniques.


---

## 1. Time Complexity for Each Operation

### Complete Big O Reference

```java
/**
 * TIME COMPLEXITY REFERENCE
 * 
 * Comprehensive Big O for all major collections
 */

public class TimeComplexityReference {
    
    /**
     * Complete complexity table
     */
    public static void completeTable() {
        /**
         * ═══════════════════════════════════════════════════════════════════
         * LIST IMPLEMENTATIONS
         * ═══════════════════════════════════════════════════════════════════
         * 
         * ARRAYLIST:
         * ┌──────────────────┬──────────┬────────────┬──────────────┐
         * │ Operation        │ Average  │ Worst Case │ Notes        │
         * ├──────────────────┼──────────┼────────────┼──────────────┤
         * │ get(index)       │ O(1)     │ O(1)       │ Direct       │
         * │ add(element)     │ O(1)*    │ O(n)       │ Amortized*   │
         * │ add(index, e)    │ O(n)     │ O(n)       │ Shift        │
         * │ remove(index)    │ O(n)     │ O(n)       │ Shift        │
         * │ remove(object)   │ O(n)     │ O(n)       │ Search+shift │
         * │ contains(e)      │ O(n)     │ O(n)       │ Linear scan  │
         * │ size()           │ O(1)     │ O(1)       │ Field        │
         * │ clear()          │ O(n)     │ O(n)       │ Null refs    │
         * │ iterator.next()  │ O(1)     │ O(1)       │ Index++      │
         * └──────────────────┴──────────┴────────────┴──────────────┘
         * 
         * LINKEDLIST:
         * ┌──────────────────┬──────────┬────────────┬──────────────┐
         * │ Operation        │ Average  │ Worst Case │ Notes        │
         * ├──────────────────┼──────────┼────────────┼──────────────┤
         * │ get(index)       │ O(n)     │ O(n)       │ Traverse     │
         * │ add(element)     │ O(1)     │ O(1)       │ At tail      │
         * │ addFirst(e)      │ O(1)     │ O(1)       │ Update head  │
         * │ add(index, e)    │ O(n)     │ O(n)       │ Traverse     │
         * │ remove(index)    │ O(n)     │ O(n)       │ Traverse     │
         * │ removeFirst()    │ O(1)     │ O(1)       │ Update head  │
         * │ contains(e)      │ O(n)     │ O(n)       │ Linear scan  │
         * │ iterator.next()  │ O(1)     │ O(1)       │ Follow ptr   │
         * │ iterator.remove()│ O(1)     │ O(1)       │ Unlink       │
         * └──────────────────┴──────────┴────────────┴──────────────┘
         * 
         * 
         * ═══════════════════════════════════════════════════════════════════
         * MAP IMPLEMENTATIONS
         * ═══════════════════════════════════════════════════════════════════
         * 
         * HASHMAP:
         * ┌──────────────────┬──────────┬────────────┬──────────────┐
         * │ Operation        │ Average  │ Worst Case │ Notes        │
         * ├──────────────────┼──────────┼────────────┼──────────────┤
         * │ get(key)         │ O(1)     │ O(log n)   │ Java 8 tree  │
         * │ put(key, value)  │ O(1)     │ O(log n)   │ Java 8 tree  │
         * │ remove(key)      │ O(1)     │ O(log n)   │ Java 8 tree  │
         * │ containsKey(k)   │ O(1)     │ O(log n)   │ Java 8 tree  │
         * │ containsValue(v) │ O(n)     │ O(n)       │ Scan all     │
         * │ size()           │ O(1)     │ O(1)       │ Field        │
         * │ iteration        │ O(n+m)   │ O(n+m)     │ n=size,m=cap │
         * └──────────────────┴──────────┴────────────┴──────────────┘
         * 
         * TREEMAP:
         * ┌──────────────────┬──────────┬────────────┬──────────────┐
         * │ Operation        │ Average  │ Worst Case │ Notes        │
         * ├──────────────────┼──────────┼────────────┼──────────────┤
         * │ get(key)         │ O(log n) │ O(log n)   │ Tree height  │
         * │ put(key, value)  │ O(log n) │ O(log n)   │ Tree insert  │
         * │ remove(key)      │ O(log n) │ O(log n)   │ Tree delete  │
         * │ firstKey()       │ O(log n) │ O(log n)   │ Find min     │
         * │ lastKey()        │ O(log n) │ O(log n)   │ Find max     │
         * │ floorKey(k)      │ O(log n) │ O(log n)   │ Tree search  │
         * │ ceilingKey(k)    │ O(log n) │ O(log n)   │ Tree search  │
         * │ subMap(k1, k2)   │ O(log n) │ O(log n)   │ Find bounds  │
         * │ iteration        │ O(n)     │ O(n)       │ In-order     │
         * └──────────────────┴──────────┴────────────┴──────────────┘
         * 
         * LINKEDHASHMAP:
         * Same as HashMap, but iteration is O(n) not O(n+m)
         * 
         * 
         * ═══════════════════════════════════════════════════════════════════
         * SET IMPLEMENTATIONS
         * ═══════════════════════════════════════════════════════════════════
         * 
         * HASHSET (backed by HashMap):
         * ┌──────────────────┬──────────┬────────────┬──────────────┐
         * │ Operation        │ Average  │ Worst Case │ Notes        │
         * ├──────────────────┼──────────┼────────────┼──────────────┤
         * │ add(element)     │ O(1)     │ O(log n)   │ Java 8 tree  │
         * │ remove(element)  │ O(1)     │ O(log n)   │ Java 8 tree  │
         * │ contains(e)      │ O(1)     │ O(log n)   │ Java 8 tree  │
         * │ size()           │ O(1)     │ O(1)       │ Field        │
         * │ iteration        │ O(n+m)   │ O(n+m)     │ n=size,m=cap │
         * └──────────────────┴──────────┴────────────┴──────────────┘
         * 
         * TREESET (backed by TreeMap):
         * ┌──────────────────┬──────────┬────────────┬──────────────┐
         * │ Operation        │ Average  │ Worst Case │ Notes        │
         * ├──────────────────┼──────────┼────────────┼──────────────┤
         * │ add(element)     │ O(log n) │ O(log n)   │ Tree insert  │
         * │ remove(element)  │ O(log n) │ O(log n)   │ Tree delete  │
         * │ contains(e)      │ O(log n) │ O(log n)   │ Tree search  │
         * │ first()          │ O(log n) │ O(log n)   │ Find min     │
         * │ last()           │ O(log n) │ O(log n)   │ Find max     │
         * │ iteration        │ O(n)     │ O(n)       │ In-order     │
         * └──────────────────┴──────────┴────────────┴──────────────┘
         * 
         * 
         * ═══════════════════════════════════════════════════════════════════
         * QUEUE IMPLEMENTATIONS
         * ═══════════════════════════════════════════════════════════════════
         * 
         * ARRAYDEQUE:
         * ┌──────────────────┬──────────┬────────────┬──────────────┐
         * │ Operation        │ Average  │ Worst Case │ Notes        │
         * ├──────────────────┼──────────┼────────────┼──────────────┤
         * │ addFirst(e)      │ O(1)*    │ O(n)       │ Amortized*   │
         * │ addLast(e)       │ O(1)*    │ O(n)       │ Amortized*   │
         * │ removeFirst()    │ O(1)     │ O(1)       │ Index++      │
         * │ removeLast()     │ O(1)     │ O(1)       │ Index--      │
         * │ peekFirst()      │ O(1)     │ O(1)       │ Direct       │
         * │ peekLast()       │ O(1)     │ O(1)       │ Direct       │
         * │ size()           │ O(1)     │ O(1)       │ Field        │
         * └──────────────────┴──────────┴────────────┴──────────────┘
         * 
         * PRIORITYQUEUE:
         * ┌──────────────────┬──────────┬────────────┬──────────────┐
         * │ Operation        │ Average  │ Worst Case │ Notes        │
         * ├──────────────────┼──────────┼────────────┼──────────────┤
         * │ offer(element)   │ O(log n) │ O(log n)   │ Bubble up    │
         * │ poll()           │ O(log n) │ O(log n)   │ Bubble down  │
         * │ peek()           │ O(1)     │ O(1)       │ Array[0]     │
         * │ remove(object)   │ O(n)     │ O(n)       │ Find+remove  │
         * │ contains(e)      │ O(n)     │ O(n)       │ Linear scan  │
         * │ size()           │ O(1)     │ O(1)       │ Field        │
         * └──────────────────┴──────────┴────────────┴──────────────┘
         * 
         * 
         * ═══════════════════════════════════════════════════════════════════
         * CONCURRENT COLLECTIONS
         * ═══════════════════════════════════════════════════════════════════
         * 
         * CONCURRENTHASHMAP:
         * ┌──────────────────┬──────────┬────────────┬──────────────┐
         * │ Operation        │ Average  │ Worst Case │ Notes        │
         * ├──────────────────┼──────────┼────────────┼──────────────┤
         * │ get(key)         │ O(1)     │ O(log n)   │ Lock-free    │
         * │ put(key, value)  │ O(1)     │ O(log n)   │ Fine lock    │
         * │ remove(key)      │ O(1)     │ O(log n)   │ Fine lock    │
         * │ size()           │ O(n)     │ O(n)       │ Expensive!   │
         * └──────────────────┴──────────┴────────────┴──────────────┘
         * 
         * COPYONWRITEARRAYLIST:
         * ┌──────────────────┬──────────┬────────────┬──────────────┐
         * │ Operation        │ Average  │ Worst Case │ Notes        │
         * ├──────────────────┼──────────┼────────────┼──────────────┤
         * │ get(index)       │ O(1)     │ O(1)       │ Direct       │
         * │ add(element)     │ O(n)     │ O(n)       │ Copy array!  │
         * │ set(index, e)    │ O(n)     │ O(n)       │ Copy array!  │
         * │ contains(e)      │ O(n)     │ O(n)       │ Linear scan  │
         * │ iteration        │ O(n)     │ O(n)       │ Snapshot     │
         * └──────────────────┴──────────┴────────────┴──────────────┘
         * 
         * 
         * KEY:
         * O(1)     - Constant time
         * O(log n) - Logarithmic (tree height)
         * O(n)     - Linear (scan all elements)
         * O(n+m)   - Linear in size + capacity
         * *        - Amortized (occasional expensive operation)
         */
    }
}
```

---

## 2. Space Complexity Considerations

### Memory Overhead Analysis

```java
/**
 * SPACE COMPLEXITY
 * 
 * Memory usage for each collection
 */

import java.util.*;

public class SpaceComplexity {
    
    /**
     * Space complexity overview
     */
    public static void spaceComplexityOverview() {
        /**
         * SPACE COMPLEXITY TABLE:
         * 
         * ┌──────────────────────┬───────────┬─────────────┬──────────────┐
         * │ Collection           │ Base      │ Per Element │ Total (1000) │
         * ├──────────────────────┼───────────┼─────────────┼──────────────┤
         * │ ArrayList            │ 24 bytes  │ 8 bytes     │ ~8 KB        │
         * │ LinkedList           │ 32 bytes  │ 40 bytes    │ ~40 KB       │
         * │ HashMap              │ 48 bytes  │ 40 bytes    │ ~64 KB       │
         * │ TreeMap              │ 48 bytes  │ 48 bytes    │ ~48 KB       │
         * │ HashSet              │ 64 bytes  │ 40 bytes    │ ~64 KB       │
         * │ TreeSet              │ 64 bytes  │ 48 bytes    │ ~48 KB       │
         * │ ArrayDeque           │ 24 bytes  │ 8 bytes     │ ~8 KB        │
         * │ PriorityQueue        │ 32 bytes  │ 8 bytes     │ ~8 KB        │
         * └──────────────────────┴───────────┴─────────────┴──────────────┘
         * 
         * NOTES:
         * - Assumes 64-bit JVM with compressed OOPs
         * - Per-element includes object header + references
         * - HashMap includes load factor overhead (capacity > size)
         * - LinkedList has highest overhead (3 references per node)
         */
    }
    
    /**
     * Detailed breakdown
     */
    public static void detailedBreakdown() {
        /**
         * ARRAYLIST MEMORY:
         * 
         * ArrayList object: 24 bytes
         * ├─ Object header: 12 bytes
         * ├─ elementData reference: 8 bytes
         * ├─ size int: 4 bytes
         * └─ (padding: 0 bytes)
         * 
         * Array (capacity 16):
         * ├─ Array header: 16 bytes
         * ├─ 16 references: 16 × 8 = 128 bytes
         * └─ Total: 144 bytes
         * 
         * Per element: 8 bytes (reference in array)
         * 
         * TOTAL for 10 elements (capacity 16):
         * 24 + 144 = 168 bytes (base)
         * + 10 × element_object_size
         * 
         * 
         * LINKEDLIST MEMORY:
         * 
         * LinkedList object: 32 bytes
         * ├─ Object header: 12 bytes
         * ├─ size int: 4 bytes
         * ├─ first reference: 8 bytes
         * ├─ last reference: 8 bytes
         * └─ (padding: 0 bytes)
         * 
         * Each Node: 40 bytes
         * ├─ Object header: 12 bytes
         * ├─ item reference: 8 bytes
         * ├─ next reference: 8 bytes
         * ├─ prev reference: 8 bytes
         * └─ padding: 4 bytes
         * 
         * Per element: 40 bytes (entire Node)
         * 
         * TOTAL for 10 elements:
         * 32 + (10 × 40) = 432 bytes (base)
         * + 10 × element_object_size
         * 
         * 
         * HASHMAP MEMORY:
         * 
         * HashMap object: 48 bytes
         * ├─ Object header: 12 bytes
         * ├─ Various fields: ~36 bytes
         * └─ (padding)
         * 
         * Array (capacity 16):
         * ├─ Array header: 16 bytes
         * ├─ 16 references: 128 bytes
         * └─ Total: 144 bytes
         * 
         * Each Entry: 40 bytes
         * ├─ Object header: 12 bytes
         * ├─ key reference: 8 bytes
         * ├─ value reference: 8 bytes
         * ├─ next reference: 8 bytes
         * ├─ hash int: 4 bytes
         * └─ padding: 0 bytes
         * 
         * Per element: 40 bytes (Entry)
         * 
         * TOTAL for 10 elements (capacity 16):
         * 48 + 144 + (10 × 40) = 592 bytes (base)
         * + 10 × (key_size + value_size)
         * 
         * 
         * MEMORY COMPARISON (1000 elements):
         * 
         * ArrayList:    ~8 KB   (most efficient)
         * ArrayDeque:   ~8 KB   (most efficient)
         * PriorityQueue:~8 KB   (most efficient)
         * HashMap:      ~64 KB  (8x ArrayList)
         * TreeMap:      ~48 KB  (6x ArrayList)
         * LinkedList:   ~40 KB  (5x ArrayList)
         */
    }
    
    /**
     * Load factor impact (HashMap)
     */
    public static void loadFactorImpact() {
        /**
         * HASHMAP LOAD FACTOR:
         * 
         * Default: 0.75
         * Resize trigger: size > capacity × 0.75
         * 
         * Example (1000 elements):
         * - Minimum capacity: 1000 / 0.75 = 1334
         * - Actual capacity: 2048 (next power of 2)
         * - Wasted slots: 2048 - 1000 = 1048
         * - Wasted memory: 1048 × 8 = 8.4 KB
         * 
         * Load factor tradeoff:
         * 
         * High (0.9):
         * + Less memory waste
         * - More collisions
         * - Slower lookups
         * 
         * Low (0.5):
         * + Fewer collisions
         * + Faster lookups
         * - More memory waste
         * 
         * Default (0.75):
         * Good balance
         */
    }
    
    /**
     * Practical memory measurement
     */
    public static void measureMemory() {
        Runtime runtime = Runtime.getRuntime();
        
        // Force GC
        runtime.gc();
        Thread.sleep(100);
        
        long before = runtime.totalMemory() - runtime.freeMemory();
        
        // Create collection
        List<Integer> list = new ArrayList<>();
        for (int i = 0; i < 100_000; i++) {
            list.add(i);
        }
        
        runtime.gc();
        Thread.sleep(100);
        
        long after = runtime.totalMemory() - runtime.freeMemory();
        long used = after - before;
        
        System.out.println("ArrayList (100K integers):");
        System.out.println("Memory used: " + used / 1024 + " KB");
        System.out.println("Per element: " + used / 100_000 + " bytes");
        
        /**
         * OUTPUT (typical):
         * ArrayList (100K integers):
         * Memory used: 1600 KB
         * Per element: 16 bytes
         * 
         * BREAKDOWN:
         * - ArrayList overhead: ~8 KB
         * - Array overhead: ~400 KB (100K × 4 bytes refs)
         * - Integer objects: ~1200 KB (100K × 12 bytes each)
         * 
         * NOTE: Integer object is ~12 bytes:
         * - Object header: 12 bytes
         * - int value: 4 bytes (already in header padding)
         */
    }
}
```

---

## 3. Amortized Analysis (ArrayList Resizing)

### Understanding Amortized O(1)

```java
/**
 * AMORTIZED ANALYSIS
 * 
 * ArrayList resizing costs amortized over operations
 */

import java.util.*;

public class AmortizedAnalysis {
    
    /**
     * What is amortized analysis?
     */
    public static void amortizedConcept() {
        /**
         * AMORTIZED ANALYSIS:
         * 
         * Average cost per operation over worst-case sequence
         * 
         * ArrayList.add() example:
         * - Most adds: O(1) - just set array[size++]
         * - Occasional add: O(n) - resize array, copy all
         * 
         * Question: Is add() O(1) or O(n)?
         * Answer: Amortized O(1)!
         * 
         * 
         * INTUITION:
         * 
         * Add to ArrayList (capacity 4):
         * 
         * add(1): capacity=4, size=0 → cost=1 [    1]
         * add(2): capacity=4, size=1 → cost=1 [  1 2]
         * add(3): capacity=4, size=2 → cost=1 [1 2 3]
         * add(4): capacity=4, size=3 → cost=1 [1 2 3 4]
         * add(5): RESIZE!
         *         capacity=8, size=4 → cost=5 (copy 4 + add 1)
         *         [1 2 3 4 5      ]
         * add(6): capacity=8, size=5 → cost=1 [1 2 3 4 5 6    ]
         * add(7): capacity=8, size=6 → cost=1 [1 2 3 4 5 6 7  ]
         * add(8): capacity=8, size=7 → cost=1 [1 2 3 4 5 6 7 8]
         * add(9): RESIZE!
         *         capacity=16, size=8 → cost=9 (copy 8 + add 1)
         * 
         * Total: 8 cheap ops (cost=1) + 2 expensive (cost=5, 9)
         * Total cost: 8 + 5 + 9 = 22
         * Average: 22 / 9 ≈ 2.4 per operation
         * 
         * Amortized O(1)!
         */
    }
    
    /**
     * Formal proof
     */
    public static void formalProof() {
        /**
         * ACCOUNTING METHOD:
         * 
         * Assign "cost" to each operation:
         * - Actual cost: real work done
         * - Amortized cost: accounting cost
         * 
         * Strategy: Charge more than actual cost,
         * save credit for expensive operations
         * 
         * 
         * ARRAYLIST ADD:
         * 
         * Amortized cost per add: 3 units
         * 
         * Regular add (no resize):
         * - Actual cost: 1 unit (set array element)
         * - Amortized cost: 3 units
         * - Credit saved: 2 units
         * 
         * Resize add:
         * - Actual cost: n + 1 units (copy n + add 1)
         * - Use saved credit: n units (from previous adds)
         * - Remaining cost: 1 unit
         * - Amortized cost: 1 + 2 = 3 units
         * 
         * 
         * PROOF:
         * 
         * After n adds, we've saved 2n credits
         * (2 credits per operation)
         * 
         * Next resize costs n (copy all elements)
         * We have 2n credits saved
         * More than enough!
         * 
         * Therefore: Amortized O(1) ✓
         * 
         * 
         * GROWTH FACTOR MATTERS:
         * 
         * Java ArrayList: 1.5x growth
         * - Old capacity: n
         * - New capacity: n + n/2 = 1.5n
         * 
         * If growth was 1.1x (too small):
         * - Resize too often
         * - Higher amortized cost
         * 
         * If growth was 3x (too large):
         * - Waste memory
         * - Same amortized time
         * 
         * 1.5x is sweet spot!
         */
    }
    
    /**
     * Measuring resize costs
     */
    public static void measureResizeCosts() {
        List<Long> costs = new ArrayList<>();
        List<Integer> list = new ArrayList<>(1);  // Start small
        
        long start = System.nanoTime();
        long lastTime = start;
        
        for (int i = 0; i < 1_000_000; i++) {
            list.add(i);
            
            long currentTime = System.nanoTime();
            long cost = currentTime - lastTime;
            
            // Record if expensive (resize)
            if (cost > 10_000) {  // 10 microseconds threshold
                costs.add(cost);
                System.out.println("Resize at size " + i + 
                    ": " + cost / 1000 + " µs");
            }
            
            lastTime = currentTime;
        }
        
        System.out.println("\nTotal resizes: " + costs.size());
        
        /**
         * OUTPUT (typical):
         * Resize at size 1: 15 µs
         * Resize at size 2: 12 µs
         * Resize at size 3: 14 µs
         * Resize at size 4: 16 µs
         * Resize at size 6: 18 µs
         * Resize at size 9: 22 µs
         * Resize at size 13: 28 µs
         * ...
         * Resize at size 699050: 8500 µs
         * Resize at size 1048575: 12000 µs
         * 
         * Total resizes: 30
         * 
         * OBSERVATIONS:
         * - Resizes happen at powers of ~1.5
         * - Cost increases with size (more to copy)
         * - Only ~30 resizes for 1M adds
         * - Most adds are very fast
         */
    }
    
    /**
     * Avoiding resizes with sizing
     */
    public static void avoidingResizes() {
        int n = 1_000_000;
        
        // Without sizing
        long start = System.nanoTime();
        List<Integer> list1 = new ArrayList<>();
        for (int i = 0; i < n; i++) {
            list1.add(i);
        }
        long time1 = System.nanoTime() - start;
        
        // With sizing
        start = System.nanoTime();
        List<Integer> list2 = new ArrayList<>(n);
        for (int i = 0; i < n; i++) {
            list2.add(i);
        }
        long time2 = System.nanoTime() - start;
        
        System.out.println("Adding " + n + " elements:");
        System.out.println("Without sizing: " + time1 / 1_000_000 + "ms");
        System.out.println("With sizing: " + time2 / 1_000_000 + "ms");
        System.out.println("Speedup: " + (double) time1 / time2 + "x");
        
        /**
         * OUTPUT (typical):
         * Adding 1000000 elements:
         * Without sizing: 85ms
         * With sizing: 45ms
         * Speedup: 1.9x
         * 
         * BEST PRACTICE:
         * If you know size, pre-allocate!
         * 
         * List<E> list = new ArrayList<>(expectedSize);
         * 
         * Benefits:
         * - No resize costs
         * - No memory waste
         * - Faster overall
         */
    }
}
```

---

## 4. Cache Locality and Memory Access Patterns

### Hardware-Level Performance

```java
/**
 * CACHE LOCALITY
 * 
 * How memory layout affects performance
 */

import java.util.*;

public class CacheLocality {
    
    /**
     * CPU cache hierarchy
     */
    public static void cacheHierarchy() {
        /**
         * MODERN CPU CACHE:
         * 
         * ┌─────────────┬──────────┬──────────┬────────────┐
         * │ Level       │ Size     │ Latency  │ Bandwidth  │
         * ├─────────────┼──────────┼──────────┼────────────┤
         * │ L1 Cache    │ 32-64 KB │ 4 cycles │ Fastest    │
         * │ L2 Cache    │ 256-512KB│ 12 cycles│ Very Fast  │
         * │ L3 Cache    │ 8-32 MB  │ 40 cycles│ Fast       │
         * │ Main Memory │ 8-64 GB  │ 200 cyc  │ Slow       │
         * └─────────────┴──────────┴──────────┴────────────┘
         * 
         * CACHE LINE:
         * - Typically 64 bytes
         * - Smallest unit of cache
         * - Fetches nearby data automatically
         * 
         * 
         * SPATIAL LOCALITY:
         * 
         * Data accessed together should be stored together
         * 
         * Good (array):
         * [1][2][3][4][5][6][7][8]
         *  ↑  ↑  ↑  ↑  ↑  ↑  ↑  ↑
         *  └──┴──┴──┴──┴──┴──┴──┴─ One cache line
         * 
         * Access [0] → loads entire line
         * Access [1] → already in cache!
         * Access [2] → already in cache!
         * ...
         * 
         * Bad (linked list):
         * [Node1] → [Node2] → [Node3] → [Node4]
         *    ↓         ↓         ↓         ↓
         * Random    Random    Random    Random
         * location  location  location  location
         * 
         * Access Node1 → cache miss
         * Access Node2 → cache miss (random location)
         * Access Node3 → cache miss (random location)
         * ...
         * 
         * PERFORMANCE IMPACT:
         * Cache hit: ~4 cycles
         * Cache miss: ~200 cycles
         * 50x difference!
         */
    }
    
    /**
     * ArrayList vs LinkedList cache performance
     */
    public static void arrayVsLinkedCache() {
        int n = 100_000;
        
        // ArrayList
        List<Integer> arrayList = new ArrayList<>(n);
        for (int i = 0; i < n; i++) {
            arrayList.add(i);
        }
        
        // LinkedList
        List<Integer> linkedList = new LinkedList<>();
        for (int i = 0; i < n; i++) {
            linkedList.add(i);
        }
        
        // Iterate ArrayList
        long start = System.nanoTime();
        long sum = 0;
        for (Integer num : arrayList) {
            sum += num;
        }
        long arrayTime = System.nanoTime() - start;
        
        // Iterate LinkedList
        start = System.nanoTime();
        sum = 0;
        for (Integer num : linkedList) {
            sum += num;
        }
        long linkedTime = System.nanoTime() - start;
        
        System.out.println("Iterate " + n + " elements:");
        System.out.println("ArrayList: " + arrayTime / 1_000_000 + "ms");
        System.out.println("LinkedList: " + linkedTime / 1_000_000 + "ms");
        System.out.println("ArrayList is " + 
            (double) linkedTime / arrayTime + "x faster");
        
        /**
         * OUTPUT (typical):
         * Iterate 100000 elements:
         * ArrayList: 2ms
         * LinkedList: 8ms
         * ArrayList is 4x faster
         * 
         * WHY:
         * ArrayList:
         * - Contiguous memory
         * - CPU prefetches next elements
         * - High cache hit rate (>90%)
         * 
         * LinkedList:
         * - Scattered memory
         * - Each node = cache miss
         * - Low cache hit rate (<10%)
         * 
         * CACHE LOCALITY MATTERS!
         */
    }
    
    /**
     * Random access patterns
     */
    public static void randomAccessPattern() {
        int n = 100_000;
        int accesses = 10_000;
        Random random = new Random(42);
        
        // ArrayList
        List<Integer> arrayList = new ArrayList<>(n);
        for (int i = 0; i < n; i++) {
            arrayList.add(i);
        }
        
        // Random access ArrayList
        long start = System.nanoTime();
        for (int i = 0; i < accesses; i++) {
            int index = random.nextInt(n);
            int value = arrayList.get(index);
        }
        long arrayTime = System.nanoTime() - start;
        
        // LinkedList
        List<Integer> linkedList = new LinkedList<>();
        for (int i = 0; i < n; i++) {
            linkedList.add(i);
        }
        
        // Random access LinkedList
        random = new Random(42);  // Reset
        start = System.nanoTime();
        for (int i = 0; i < accesses; i++) {
            int index = random.nextInt(n);
            int value = linkedList.get(index);
        }
        long linkedTime = System.nanoTime() - start;
        
        System.out.println("Random access (" + accesses + " ops):");
        System.out.println("ArrayList: " + arrayTime / 1_000_000 + "ms");
        System.out.println("LinkedList: " + linkedTime / 1_000_000 + "ms");
        System.out.println("ArrayList is " + 
            (double) linkedTime / arrayTime + "x faster");
        
        /**
         * OUTPUT (typical):
         * Random access (10000 ops):
         * ArrayList: 5ms
         * LinkedList: 35000ms (35 seconds!)
         * ArrayList is 7000x faster
         * 
         * CATASTROPHIC FOR LINKEDLIST:
         * - get(index) is O(n) - must traverse
         * - Each traversal = many cache misses
         * - No benefit from sequential access
         * 
         * NEVER use get(index) with LinkedList!
         */
    }
    
    /**
     * Cache-friendly data structures
     */
    public static void cacheFriendlyStructures() {
        /**
         * CACHE-FRIENDLY:
         * 
         * ✅ ArrayList
         * - Contiguous array
         * - Perfect spatial locality
         * - CPU prefetching works
         * 
         * ✅ ArrayDeque
         * - Circular array
         * - Good spatial locality
         * - Cache-friendly
         * 
         * ✅ Primitive arrays (int[], long[])
         * - No object overhead
         * - Dense packing
         * - Best cache performance
         * 
         * 
         * CACHE-UNFRIENDLY:
         * 
         * ❌ LinkedList
         * - Scattered nodes
         * - Poor spatial locality
         * - Many cache misses
         * 
         * ❌ HashMap (large)
         * - Sparse array
         * - Node objects scattered
         * - Moderate cache misses
         * 
         * ❌ TreeMap
         * - Tree nodes scattered
         * - Poor spatial locality
         * - Many cache misses
         * 
         * 
         * RECOMMENDATION:
         * For large datasets with sequential access,
         * always prefer array-based structures!
         */
    }
}
```

---

## 5. Benchmarking Collections (JMH)

### Professional Performance Measurement

```java
/**
 * JMH BENCHMARKING
 * 
 * Proper microbenchmarking with JMH
 */

import org.openjdk.jmh.annotations.*;
import org.openjdk.jmh.runner.*;
import org.openjdk.jmh.runner.options.*;
import java.util.*;
import java.util.concurrent.TimeUnit;

/**
 * JMH (Java Microbenchmark Harness)
 * 
 * Maven dependency:
 * <dependency>
 *     <groupId>org.openjdk.jmh</groupId>
 *     <artifactId>jmh-core</artifactId>
 *     <version>1.36</version>
 * </dependency>
 * <dependency>
 *     <groupId>org.openjdk.jmh</groupId>
 *     <artifactId>jmh-generator-annprocess</artifactId>
 *     <version>1.36</version>
 * </dependency>
 */

@State(Scope.Benchmark)
@BenchmarkMode(Mode.AverageTime)
@OutputTimeUnit(TimeUnit.NANOSECONDS)
@Warmup(iterations = 5, time = 1)
@Measurement(iterations = 10, time = 1)
@Fork(2)
public class CollectionBenchmarks {
    
    /**
     * Why JMH?
     */
    public static void whyJMH() {
        /**
         * PROBLEMS WITH NAIVE BENCHMARKS:
         * 
         * 1. JIT COMPILATION:
         *    Code optimized after warmup
         *    First runs are slow (interpreted)
         *    Must warm up before measuring
         * 
         * 2. DEAD CODE ELIMINATION:
         *    JIT removes unused results
         *    
         *    // JIT optimizes this away:
         *    for (int i = 0; i < 1000; i++) {
         *        int x = list.get(i);  // x never used
         *    }
         *    // Becomes: /* nothing */
         * 
         * 3. GARBAGE COLLECTION:
         *    GC pauses skew results
         *    Unpredictable timing
         * 
         * 4. CPU CACHE EFFECTS:
         *    First run cold cache
         *    Subsequent runs hot cache
         * 
         * 5. MEASUREMENT OVERHEAD:
         *    System.nanoTime() has cost
         *    Affects results
         * 
         * 
         * JMH SOLUTIONS:
         * ✓ Automatic warmup iterations
         * ✓ Blackhole.consume() prevents dead code elimination
         * ✓ Multiple forks for statistical significance
         * ✓ Precise time measurement
         * ✓ Statistical analysis
         */
    }
    
    /**
     * Basic benchmark example
     */
    @Param({"100", "1000", "10000"})
    private int size;
    
    private List<Integer> arrayList;
    private List<Integer> linkedList;
    
    @Setup
    public void setup() {
        arrayList = new ArrayList<>();
        linkedList = new LinkedList<>();
        
        for (int i = 0; i < size; i++) {
            arrayList.add(i);
            linkedList.add(i);
        }
    }
    
    @Benchmark
    public void arrayListIteration(Blackhole blackhole) {
        for (Integer num : arrayList) {
            blackhole.consume(num);  // Prevent dead code elimination
        }
    }
    
    @Benchmark
    public void linkedListIteration(Blackhole blackhole) {
        for (Integer num : linkedList) {
            blackhole.consume(num);
        }
    }
    
    @Benchmark
    public int arrayListGet() {
        return arrayList.get(size / 2);
    }
    
    @Benchmark
    public int linkedListGet() {
        return linkedList.get(size / 2);
    }
    
    /**
     * Run benchmarks
     */
    public static void main(String[] args) throws Exception {
        Options opt = new OptionsBuilder()
            .include(CollectionBenchmarks.class.getSimpleName())
            .build();
        
        new Runner(opt).run();
        
        /**
         * OUTPUT (typical):
         * 
         * Benchmark                        (size)  Mode  Cnt    Score   Error  Units
         * arrayListIteration                  100  avgt   20   120.5 ±  2.1    ns/op
         * arrayListIteration                 1000  avgt   20  1205.3 ± 15.2    ns/op
         * arrayListIteration                10000  avgt   20 12089.7 ± 98.4    ns/op
         * linkedListIteration                 100  avgt   20   310.2 ±  8.3    ns/op
         * linkedListIteration                1000  avgt   20  3145.8 ± 42.1    ns/op
         * linkedListIteration               10000  avgt   20 31523.4 ± 215.6   ns/op
         * arrayListGet                        100  avgt   20     2.1 ±  0.1    ns/op
         * arrayListGet                       1000  avgt   20     2.2 ±  0.1    ns/op
         * arrayListGet                      10000  avgt   20     2.1 ±  0.1    ns/op
         * linkedListGet                       100  avgt   20    85.3 ±  2.1    ns/op
         * linkedListGet                      1000  avgt   20   950.2 ± 18.5    ns/op
         * linkedListGet                     10000  avgt   20  9823.7 ± 142.3   ns/op
         * 
         * INSIGHTS:
         * - ArrayList.get() constant time (O(1))
         * - LinkedList.get() linear time (O(n))
         * - ArrayList iteration 2.6x faster
         * - Error bars show statistical confidence
         */
    }
    
    /**
     * HashMap vs TreeMap benchmark
     */
    @State(Scope.Benchmark)
    public static class MapBenchmark {
        
        @Param({"100", "1000", "10000"})
        private int size;
        
        private Map<Integer, String> hashMap;
        private Map<Integer, String> treeMap;
        private Random random;
        
        @Setup
        public void setup() {
            hashMap = new HashMap<>();
            treeMap = new TreeMap<>();
            random = new Random(42);
            
            for (int i = 0; i < size; i++) {
                hashMap.put(i, "value" + i);
                treeMap.put(i, "value" + i);
            }
        }
        
        @Benchmark
        public String hashMapGet() {
            return hashMap.get(random.nextInt(size));
        }
        
        @Benchmark
        public String treeMapGet() {
            return treeMap.get(random.nextInt(size));
        }
        
        @Benchmark
        public void hashMapPut() {
            hashMap.put(random.nextInt(size * 2), "new");
        }
        
        @Benchmark
        public void treeMapPut() {
            treeMap.put(random.nextInt(size * 2), "new");
        }
        
        /**
         * RESULTS (typical):
         * 
         * Benchmark              (size)  Mode  Cnt   Score   Error  Units
         * hashMapGet                100  avgt   20   8.5 ±   0.2   ns/op
         * hashMapGet               1000  avgt   20  10.2 ±   0.3   ns/op
         * hashMapGet              10000  avgt   20  12.1 ±   0.4   ns/op
         * treeMapGet                100  avgt   20  28.3 ±   0.8   ns/op
         * treeMapGet               1000  avgt   20  45.2 ±   1.2   ns/op
         * treeMapGet              10000  avgt   20  62.5 ±   1.8   ns/op
         * 
         * INSIGHTS:
         * - HashMap: ~constant (O(1))
         * - TreeMap: logarithmic (O(log n))
         * - HashMap 3-5x faster for lookups
         */
    }
    
    /**
     * Best practices
     */
    public static void jmhBestPractices() {
        /**
         * JMH BEST PRACTICES:
         * 
         * 1. WARMUP:
         *    @Warmup(iterations = 5, time = 1)
         *    Let JIT optimize code
         * 
         * 2. MEASUREMENT:
         *    @Measurement(iterations = 10, time = 1)
         *    More iterations = better statistics
         * 
         * 3. FORKS:
         *    @Fork(2)
         *    Separate JVM processes
         *    Avoid cross-contamination
         * 
         * 4. BLACKHOLE:
         *    blackhole.consume(result)
         *    Prevent dead code elimination
         * 
         * 5. STATE:
         *    @State(Scope.Benchmark)
         *    Shared across iterations
         * 
         * 6. PARAMS:
         *    @Param({"100", "1000", "10000"})
         *    Test multiple sizes
         * 
         * 7. MODE:
         *    Mode.AverageTime - average per operation
         *    Mode.Throughput - ops per second
         *    Mode.SampleTime - time distribution
         * 
         * 8. AVOID:
         *    - Loops in @Benchmark (use Blackhole)
         *    - State modification in benchmark
         *    - System.out in benchmark
         */
    }
}
```

---

## 6. Choosing Optimal Data Structure

### Comprehensive Decision Framework

```java
/**
 * CHOOSING OPTIMAL DATA STRUCTURE
 * 
 * Decision trees and real-world scenarios
 */

public class ChoosingDataStructure {
    
    /**
     * Master decision tree
     */
    public static void masterDecisionTree() {
        /**
         * DECISION TREE:
         * 
         * Need key-value mapping?
         * ├─ YES → MAP
         * │   Need sorted keys?
         * │   ├─ YES → TreeMap
         * │   └─ NO ↓
         * │       Need insertion order?
         * │       ├─ YES → LinkedHashMap
         * │       └─ NO → HashMap (default)
         * │
         * └─ NO ↓
         *     Need unique elements only?
         *     ├─ YES → SET
         *     │   Need sorted?
         *     │   ├─ YES → TreeSet
         *     │   └─ NO ↓
         *     │       Need order?
         *     │       ├─ YES → LinkedHashSet
         *     │       └─ NO → HashSet (default)
         *     │
         *     └─ NO ↓
         *         Need FIFO/LIFO/Priority?
         *         ├─ YES → QUEUE/DEQUE
         *         │   Need priority?
         *         │   ├─ YES → PriorityQueue
         *         │   └─ NO ↓
         *         │       Need thread-safe?
         *         │       ├─ YES → BlockingQueue variants
         *         │       └─ NO → ArrayDeque (default)
         *         │
         *         └─ NO → LIST
         *             Need random access?
         *             ├─ YES → ArrayList (default)
         *             └─ NO ↓
         *                 Frequent insert/delete at ends?
         *                 └─ YES → ArrayDeque
         */
    }
    
    /**
     * Performance-based selection
     */
    public static void performanceBasedSelection() {
        /**
         * OPERATION-BASED SELECTION:
         * 
         * PRIMARY OPERATION: Random access by index
         * ✅ ArrayList - O(1)
         * ❌ LinkedList - O(n)
         * 
         * PRIMARY OPERATION: Insert/delete at ends
         * ✅ ArrayDeque - O(1)
         * ✅ LinkedList - O(1) (but slower constant)
         * ❌ ArrayList - O(n) for beginning
         * 
         * PRIMARY OPERATION: Insert/delete in middle (with iterator)
         * ✅ LinkedList - O(1) at position
         * ❌ ArrayList - O(n) shift
         * (But rarely worth it - ArrayList usually still wins)
         * 
         * PRIMARY OPERATION: Membership test
         * ✅ HashSet - O(1)
         * ❌ ArrayList - O(n)
         * ❌ TreeSet - O(log n)
         * 
         * PRIMARY OPERATION: Sorted iteration
         * ✅ TreeSet - O(n) in order
         * ❌ HashSet - O(n) unsorted + O(n log n) sort
         * 
         * PRIMARY OPERATION: Range queries
         * ✅ TreeMap - O(log n) subMap
         * ❌ HashMap - O(n) filter
         * 
         * PRIMARY OPERATION: Concurrent access
         * ✅ ConcurrentHashMap - lock-free reads
         * ✅ CopyOnWriteArrayList - read-heavy
         * ❌ Collections.synchronizedList - slow
         */
    }
    
    /**
     * Real-world scenarios
     */
    public static void realWorldScenarios() {
        /**
         * SCENARIO 1: Shopping cart
         * 
         * Requirements:
         * - Add/remove items
         * - Display in order added
         * - Check if item exists
         * 
         * Solution: LinkedHashMap<ProductId, CartItem>
         * - O(1) add/remove
         * - O(1) lookup
         * - Maintains insertion order
         * 
         * 
         * SCENARIO 2: LRU cache
         * 
         * Requirements:
         * - Get/put O(1)
         * - Evict least recently used
         * 
         * Solution: LinkedHashMap with accessOrder=true
         * - Built-in LRU
         * - Override removeEldestEntry
         * 
         * 
         * SCENARIO 3: Task scheduler
         * 
         * Requirements:
         * - Execute tasks by priority
         * - Add tasks dynamically
         * 
         * Solution: PriorityQueue<Task>
         * - O(log n) add/remove
         * - Always get highest priority
         * 
         * 
         * SCENARIO 4: Autocomplete
         * 
         * Requirements:
         * - Prefix search
         * - Sorted suggestions
         * 
         * Solution: TreeSet<String>
         * - O(log n) insertion
         * - Sorted iteration
         * - subSet() for range
         * 
         * 
         * SCENARIO 5: Unique visitor tracking
         * 
         * Requirements:
         * - Fast membership test
         * - Don't care about order
         * - Very large dataset
         * 
         * Solution: HashSet<UserId>
         * - O(1) add/contains
         * - Minimal memory
         * - Fastest for large sets
         * 
         * 
         * SCENARIO 6: Event log processing
         * 
         * Requirements:
         * - Process events in order
         * - Unknown size
         * - Sequential access
         * 
         * Solution: ArrayList<Event>
         * - O(1) amortized add
         * - O(1) sequential access
         * - Minimal memory
         * 
         * 
         * SCENARIO 7: Graph adjacency list
         * 
         * Requirements:
         * - Fast neighbor lookup
         * - Add edges dynamically
         * 
         * Solution: Map<Vertex, Set<Vertex>>
         * HashMap<Vertex, HashSet<Vertex>>
         * - O(1) neighbor lookup
         * - O(1) add edge
         * 
         * 
         * SCENARIO 8: Leaderboard
         * 
         * Requirements:
         * - Sorted by score
         * - Update scores
         * - Get top K
         * 
         * Solution: TreeMap<Score, Player> (reversed)
         * - O(log n) update
         * - O(log n + k) top K
         * - Always sorted
         */
    }
    
    /**
     * Size considerations
     */
    public static void sizeConsiderations() {
        /**
         * SMALL COLLECTIONS (< 10 elements):
         * 
         * Don't overthink it!
         * - Difference negligible
         * - Choose for clarity
         * - ArrayList usually fine
         * 
         * 
         * MEDIUM COLLECTIONS (10 - 100K):
         * 
         * Choose based on operations:
         * - Random access → ArrayList
         * - Membership test → HashSet
         * - Sorted → TreeSet/TreeMap
         * 
         * 
         * LARGE COLLECTIONS (100K - 10M):
         * 
         * Performance matters:
         * - Cache locality important
         * - Prefer array-based (ArrayList, ArrayDeque)
         * - Avoid LinkedList
         * - Consider memory overhead
         * 
         * 
         * VERY LARGE (> 10M):
         * 
         * Specialized structures:
         * - Consider primitive arrays
         * - Database/external storage
         * - Memory-mapped files
         * - Custom data structures
         */
    }
    
    /**
     * Memory-constrained scenarios
     */
    public static void memoryConstrained() {
        /**
         * MEMORY OPTIMIZATION:
         * 
         * MOST EFFICIENT:
         * 1. Primitive arrays (int[], long[])
         *    - No object overhead
         *    - Dense packing
         *    - 4-8 bytes per element
         * 
         * 2. ArrayList
         *    - 8 bytes per element (reference)
         *    - Low overhead
         * 
         * 3. ArrayDeque
         *    - Similar to ArrayList
         *    - Slight overhead for circular
         * 
         * MODERATE:
         * 4. HashMap
         *    - ~40 bytes per entry
         *    - Load factor waste
         * 
         * 5. TreeMap
         *    - ~48 bytes per entry
         *    - No load factor
         * 
         * LEAST EFFICIENT:
         * 6. LinkedList
         *    - 40 bytes per element
         *    - 5x ArrayList
         * 
         * 
         * STRATEGIES:
         * - Use primitive arrays when possible
         * - Size collections appropriately
         * - Consider packed structures
         * - Use IntArrayList from libraries (Trove, FastUtil)
         */
    }
    
    /**
     * Concurrent scenarios
     */
    public static void concurrentScenarios() {
        /**
         * CONCURRENT COLLECTIONS:
         * 
         * READ-HEAVY (90%+ reads):
         * ✅ CopyOnWriteArrayList
         * - Lock-free reads
         * - Expensive writes (copy array)
         * - Perfect for listeners, config
         * 
         * WRITE-HEAVY:
         * ✅ ConcurrentHashMap
         * - Fine-grained locking
         * - Good read/write mix
         * - Default choice
         * 
         * PRODUCER-CONSUMER:
         * ✅ LinkedBlockingQueue
         * - Blocking operations
         * - Natural flow control
         * - Dual locks
         * 
         * HIGH THROUGHPUT:
         * ✅ LinkedTransferQueue
         * - Lock-free
         * - Fastest BlockingQueue
         * - Direct handoff
         * 
         * AVOID:
         * ❌ Collections.synchronizedList/Map
         * - Global lock
         * - Poor scalability
         * - Legacy approach
         */
    }
    
    /**
     * Anti-patterns
     */
    public static void antiPatterns() {
        /**
         * COMMON MISTAKES:
         * 
         * ❌ Using LinkedList as default list
         * Why: Slower, more memory, no benefits
         * Fix: Use ArrayList
         * 
         * ❌ Using ArrayList.contains() in loop
         * Why: O(n²) - quadratic time
         * Fix: Convert to HashSet first
         * 
         * ❌ Not sizing collections
         * Why: Multiple resizes, wasted time
         * Fix: new ArrayList<>(expectedSize)
         * 
         * ❌ Using Vector/Stack/Hashtable
         * Why: Legacy, synchronized, slow
         * Fix: ArrayList/ArrayDeque/HashMap
         * 
         * ❌ Frequent TreeSet updates
         * Why: O(log n) vs O(1) for HashSet
         * Fix: HashSet + sort when needed
         * 
         * ❌ HashMap for sorted iteration
         * Why: O(n log n) to sort
         * Fix: TreeMap if always need sorted
         * 
         * ❌ Large CopyOnWriteArrayList
         * Why: Expensive copies
         * Fix: ConcurrentHashMap.newKeySet()
         * 
         * ❌ get(index) with LinkedList
         * Why: O(n) per call
         * Fix: Iterator or ArrayList
         */
    }
    
    /**
     * Quick reference cheat sheet
     */
    public static void quickReference() {
        /**
         * QUICK REFERENCE:
         * 
         * ┌───────────────────────┬─────────────────┬──────────┐
         * │ Use Case              │ Best Choice     │ Why      │
         * ├───────────────────────┼─────────────────┼──────────┤
         * │ Random access         │ ArrayList       │ O(1)     │
         * │ Sequential access     │ ArrayList       │ Cache    │
         * │ Insert at ends        │ ArrayDeque      │ O(1)     │
         * │ Stack/Queue           │ ArrayDeque      │ Fast     │
         * │ Priority queue        │ PriorityQueue   │ Heap     │
         * │ Unique elements       │ HashSet         │ O(1)     │
         * │ Sorted set            │ TreeSet         │ Sorted   │
         * │ Key-value pairs       │ HashMap         │ O(1)     │
         * │ Sorted map            │ TreeMap         │ Sorted   │
         * │ Insertion order       │ LinkedHashMap   │ Order    │
         * │ LRU cache             │ LinkedHashMap   │ Built-in │
         * │ Concurrent reads      │ ConcurrentHash  │ Lock-free│
         * │ Producer-consumer     │ BlockingQueue   │ Blocking │
         * │ Read-mostly           │ CopyOnWrite     │ Snapshot │
         * └───────────────────────┴─────────────────┴──────────┘
         * 
         * DEFAULT CHOICES:
         * List: ArrayList
         * Set: HashSet
         * Map: HashMap
         * Queue: ArrayDeque
         * Concurrent Map: ConcurrentHashMap
         */
    }
}
```

---

## Summary

### Performance Cheat Sheet

**Time Complexity:**

```
┌──────────────┬──────────┬──────────┬───────────┬──────────┐
│ Collection   │ Add      │ Get      │ Contains  │ Remove   │
├──────────────┼──────────┼──────────┼───────────┼──────────┤
│ ArrayList    │ O(1)*    │ O(1)     │ O(n)      │ O(n)     │
│ LinkedList   │ O(1)     │ O(n)     │ O(n)      │ O(1)**   │
│ HashSet      │ O(1)     │ N/A      │ O(1)      │ O(1)     │
│ TreeSet      │ O(log n) │ N/A      │ O(log n)  │ O(log n) │
│ HashMap      │ O(1)     │ O(1)     │ O(1)      │ O(1)     │
│ TreeMap      │ O(log n) │ O(log n) │ O(log n)  │ O(log n) │
│ ArrayDeque   │ O(1)*    │ N/A      │ O(n)      │ O(1)     │
│ PriorityQueue│ O(log n) │ O(1)***  │ O(n)      │ O(log n) │
└──────────────┴──────────┴──────────┴───────────┴──────────┘

*   Amortized
**  At iterator position
*** Only peek/poll
```

**Space Complexity:**

```
┌──────────────┬──────────────┬──────────────┐
│ Collection   │ Overhead/Elem│ 1000 Elements│
├──────────────┼──────────────┼──────────────┤
│ ArrayList    │ 8 bytes      │ ~8 KB        │
│ LinkedList   │ 40 bytes     │ ~40 KB       │
│ HashMap      │ 40 bytes     │ ~64 KB*      │
│ TreeMap      │ 48 bytes     │ ~48 KB       │
│ ArrayDeque   │ 8 bytes      │ ~8 KB        │
└──────────────┴──────────────┴──────────────┘

* Includes load factor overhead
```

**Cache Locality:**

```
✅ Excellent:  ArrayList, ArrayDeque, primitive arrays
🟢 Good:       HashMap (moderate)
🟡 Fair:       TreeMap
❌ Poor:       LinkedList
```

### Key Takeaways

**1. Default choices (95% of cases):**

```java
List<E> list = new ArrayList<>();
Set<E> set = new HashSet<>();
Map<K,V> map = new HashMap<>();
Deque<E> queue = new ArrayDeque<>();
```

**2. Performance rules:**

```
- ArrayList beats LinkedList (99% of time)
- HashMap beats TreeMap (unless need sorted)
- ArrayDeque beats LinkedList (always)
- Cache locality matters (array > linked)
```

**3. Sizing matters:**

```java
// ❌ BAD
List<E> list = new ArrayList<>();  // Default capacity 10

// ✅ GOOD
List<E> list = new ArrayList<>(expectedSize);  // No resizes!
```

**4. Amortized analysis:**

```
ArrayList.add(): O(1) amortized
- Most adds: O(1)
- Rare resize: O(n)
- Average: O(1) ✅
```

**5. Use JMH for benchmarks:**

```
- Proper warmup
- Statistical analysis
- Dead code elimination prevention
- Production-realistic results
```

---

